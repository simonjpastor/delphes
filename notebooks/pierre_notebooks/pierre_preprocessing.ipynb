{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression des éléments indésirables de nos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lecture et stockage de la base de données\n",
    "tweet_df = pd.read_pickle('../../raw_data/final4_clean.csv')\n",
    "tweet_df.head()\n",
    "new_test_df = pd.read_pickle('../../raw_data/update_age_sex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(0, tweet_df.shape[0])\n",
    "tweet_df['index'] = y\n",
    "tweet_df.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the undesirable elements in the entire dataframe\n",
    "def rmurl_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the URLs, the #hashtag and the @user of a column made of strings.\n",
    "    Be careful to apply it BEFORE all the other preprocessing steps (if not it wont'\n",
    "    be recognized as a URL)\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].str.replace('http\\S+|www.\\S+|@\\S+|#\\S+', '', case=False)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase the tweet's column\n",
    "def lower_df(df, column_name):\n",
    "    '''\n",
    "    This function lowercases a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the numbers in the tweet's column\n",
    "def rmnumbers_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the digits of a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def remove_numbers(text):\n",
    "        return ''.join(word for word in text if not word.isdigit())\n",
    "    df[column_name] = df[column_name].apply(remove_numbers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the undesirable punctuations in the tweet's column\n",
    "def rmpunct_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the punctuations, all the \"rt\" and remove multiple spaces\n",
    "    of a column made of strings.\n",
    "    '''\n",
    "    punct = string.punctuation\n",
    "    df = df.copy()\n",
    "    def replace_punct(text):\n",
    "        for punctu in punct:\n",
    "            text = text.replace(punctu, ' ')\n",
    "        text = text.replace(' rt ','')\n",
    "        text = \" \".join(text.split())\n",
    "        return text\n",
    "    df[column_name] = df[column_name].apply(replace_punct)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stopwords in the tweet's column\n",
    "def rmstopwords_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the stopwords of a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    stop_words = stopwords.words('english')\n",
    "    def remove_stopwords(text):\n",
    "        for word in stop_words:\n",
    "            text = text.replace(f' {word} ', ' ')\n",
    "        return text\n",
    "    df[column_name] = df[column_name].apply(remove_stopwords)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize a column in a dataset\n",
    "def lemmatize_df(df, column_name):\n",
    "    '''\n",
    "    This function lemmatize the words of a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def lemmatize(text):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        retour = []\n",
    "        for word in text:\n",
    "            retour.append(lemmatizer.lemmatize(word))\n",
    "        text = ''.join(word for word in retour)\n",
    "        return text\n",
    "\n",
    "    df[column_name] = df[column_name].apply(lemmatize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erase all the words that are 1-letter or 2-letters long\n",
    "def erase_fewletter_df(df, column_name):\n",
    "    '''\n",
    "    One or two letters words are deleted from the dataset.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def tester(text):\n",
    "        text = ' '.join( [w for w in text.split() if len(w)>2] )\n",
    "        return text\n",
    "\n",
    "    df[column_name] = df[column_name].apply(tester)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the undesirable emojis in the entire dataframe\n",
    "def rmemojis_df(df):\n",
    "    '''\n",
    "    This function removes all the emojis of a column made of strings.\n",
    "    Be careful to translate in latin alphabet before applying this function : \n",
    "    it also removes cyrillic alphabet\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df = df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = rmurl_df(new_test_df, 'content')\n",
    "clean_df = lower_df(clean_df, 'content')\n",
    "clean_df = rmnumbers_df(clean_df, 'content')\n",
    "clean_df = rmpunct_df(clean_df, 'content')\n",
    "clean_df = rmstopwords_df(clean_df, 'content')\n",
    "clean_df = lemmatize_df(clean_df, 'content')\n",
    "clean_df = erase_fewletter_df(clean_df, 'content')\n",
    "clean_df = rmemojis_df(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>bardzo dzikuj niezalene wadzy wolne media daj ...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>komisja przyja arcywane projekty pilotaowe aut...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>komisja przyja projekty pilotaowe mojego wspau...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>tym dniu tym miejscu tej godzinie prosz jedno ...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>bg nie potrzebuje by przez nikogo broniony nie...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137295</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>tedenska akcija etrtka srede zbornik bela knji...</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137296</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>strong amp way forward european future read eu...</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137297</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>date noted worrying state danger ends special ...</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137298</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>vsi vedo nekaj noro strahu pred nasilnimi levi...</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137299</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>tota ekipa tak gre kranja najlepim navijakim p...</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137300 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mep_id                 name   country  \\\n",
       "0       197490  Magdalena ADAMOWICZ    Poland   \n",
       "1       197490  Magdalena ADAMOWICZ    Poland   \n",
       "2       197490  Magdalena ADAMOWICZ    Poland   \n",
       "3       197490  Magdalena ADAMOWICZ    Poland   \n",
       "4       197490  Magdalena ADAMOWICZ    Poland   \n",
       "...        ...                  ...       ...   \n",
       "137295   96933           Milan ZVER  Slovenia   \n",
       "137296   96933           Milan ZVER  Slovenia   \n",
       "137297   96933           Milan ZVER  Slovenia   \n",
       "137298   96933           Milan ZVER  Slovenia   \n",
       "137299   96933           Milan ZVER  Slovenia   \n",
       "\n",
       "                                                    group  \\\n",
       "0       Group of the European People's Party (Christia...   \n",
       "1       Group of the European People's Party (Christia...   \n",
       "2       Group of the European People's Party (Christia...   \n",
       "3       Group of the European People's Party (Christia...   \n",
       "4       Group of the European People's Party (Christia...   \n",
       "...                                                   ...   \n",
       "137295  Group of the European People's Party (Christia...   \n",
       "137296  Group of the European People's Party (Christia...   \n",
       "137297  Group of the European People's Party (Christia...   \n",
       "137298  Group of the European People's Party (Christia...   \n",
       "137299  Group of the European People's Party (Christia...   \n",
       "\n",
       "                            nat_group          twitter  \\\n",
       "0                         Independent  Adamowicz_Magda   \n",
       "1                         Independent  Adamowicz_Magda   \n",
       "2                         Independent  Adamowicz_Magda   \n",
       "3                         Independent  Adamowicz_Magda   \n",
       "4                         Independent  Adamowicz_Magda   \n",
       "...                               ...              ...   \n",
       "137295  Slovenska demokratska stranka        MilanZver   \n",
       "137296  Slovenska demokratska stranka        MilanZver   \n",
       "137297  Slovenska demokratska stranka        MilanZver   \n",
       "137298  Slovenska demokratska stranka        MilanZver   \n",
       "137299  Slovenska demokratska stranka        MilanZver   \n",
       "\n",
       "                                                  content age  sex  \n",
       "0       bardzo dzikuj niezalene wadzy wolne media daj ...  47  1.0  \n",
       "1       komisja przyja arcywane projekty pilotaowe aut...  47  1.0  \n",
       "2       komisja przyja projekty pilotaowe mojego wspau...  47  1.0  \n",
       "3       tym dniu tym miejscu tej godzinie prosz jedno ...  47  1.0  \n",
       "4       bg nie potrzebuje by przez nikogo broniony nie...  47  1.0  \n",
       "...                                                   ...  ..  ...  \n",
       "137295  tedenska akcija etrtka srede zbornik bela knji...  63  0.0  \n",
       "137296  strong amp way forward european future read eu...  63  0.0  \n",
       "137297  date noted worrying state danger ends special ...  63  0.0  \n",
       "137298  vsi vedo nekaj noro strahu pred nasilnimi levi...  63  0.0  \n",
       "137299  tota ekipa tak gre kranja najlepim navijakim p...  63  0.0  \n",
       "\n",
       "[137300 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbase_df = clean_df[clean_df['country'] == 'Ireland']\n",
    "testbase_deputy_df = tweet_df[tweet_df['country'] == 'Ireland']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(word2vec, sentence):\n",
    "    y = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv.vocab.keys():\n",
    "           y.append(word2vec[word])\n",
    "    return np.array(y)\n",
    "\n",
    "def embedding(word2vec, sentences):\n",
    "    \n",
    "    y = []\n",
    "    for sentence in sentences:\n",
    "        y.append(embed_sentence(word2vec, sentence))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction retourne automatiquement X_train, X_test, y_train, y_test de notre base de données twitter.\n",
    "def get_train_test_objects(df, column):\n",
    "    '''\n",
    "    Les étapes que cette fonction réalise sont en commentaires.\n",
    "    '''\n",
    "    # Copie de la base de données pour éviter les problèmes d'assignation abusive.\n",
    "    df = df.copy() \n",
    "    # Récupération de tous les tweets et du nom du député qui les a posté. Création de la cible y.\n",
    "    df = df[['name', 'content']]\n",
    "    y = pd.get_dummies(df['name'])\n",
    "    # Transformation des tweets en suite de mots (strings) dans une liste.\n",
    "    sentences = df['content']\n",
    "    sentences_inter = []\n",
    "    for sentence in sentences:\n",
    "        sentences_inter.append(sentence.split())\n",
    "    # Séparation des données d'entraînement et de test\n",
    "    sentences_train, sentences_test, y_train, y_test = train_test_split(sentences_inter, y, test_size = 0.3)\n",
    "    # Vectorisation des phrases\n",
    "    word2vec = Word2Vec(sentences=sentences_train)\n",
    "    # Création des données d'entrée.\n",
    "    X_train = embedding(word2vec,sentences_train)\n",
    "    X_test = embedding(word2vec,sentences_test)\n",
    "    X_train_pad = pad_sequences(X_train, padding='post',value=-1000, dtype='float32')\n",
    "    X_test_pad = pad_sequences(X_test, padding='post',value=-1000, dtype='float32')\n",
    "    # Création des données cibles.\n",
    "    y_train = y_train.values\n",
    "    y_test = y_test.values\n",
    "    # Sorties de la fonction\n",
    "    return X_train_pad, y_train, X_test_pad, y_test, word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, word2vec = get_train_test_objects(testbase_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 28, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking(mask_value = -1000))\n",
    "    model.add(layers.LSTM(13, activation='tanh'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du modèle et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 1470 samples, validate on 630 samples\n",
      "Epoch 1/1000\n",
      "1470/1470 [==============================] - 8s 6ms/sample - loss: 2.3025 - acc: 0.1061 - val_loss: 2.3024 - val_acc: 0.0889\n",
      "Epoch 2/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2993 - acc: 0.1034 - val_loss: 2.2971 - val_acc: 0.0905\n",
      "Epoch 3/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2879 - acc: 0.1252 - val_loss: 2.2920 - val_acc: 0.1540\n",
      "Epoch 4/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2735 - acc: 0.1381 - val_loss: 2.2675 - val_acc: 0.1238\n",
      "Epoch 5/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2617 - acc: 0.1435 - val_loss: 2.2535 - val_acc: 0.1381\n",
      "Epoch 6/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2527 - acc: 0.1469 - val_loss: 2.2486 - val_acc: 0.1381\n",
      "Epoch 7/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2444 - acc: 0.1401 - val_loss: 2.2491 - val_acc: 0.1413\n",
      "Epoch 8/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2409 - acc: 0.1422 - val_loss: 2.2418 - val_acc: 0.1397\n",
      "Epoch 9/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2373 - acc: 0.1367 - val_loss: 2.2498 - val_acc: 0.1492\n",
      "Epoch 10/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2351 - acc: 0.1367 - val_loss: 2.2388 - val_acc: 0.1397\n",
      "Epoch 11/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2348 - acc: 0.1510 - val_loss: 2.2424 - val_acc: 0.1333\n",
      "Epoch 12/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2326 - acc: 0.1435 - val_loss: 2.2383 - val_acc: 0.1381\n",
      "Epoch 13/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2317 - acc: 0.1456 - val_loss: 2.2433 - val_acc: 0.1444\n",
      "Epoch 14/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2304 - acc: 0.1408 - val_loss: 2.2375 - val_acc: 0.1397\n",
      "Epoch 15/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2246 - acc: 0.1429 - val_loss: 2.2425 - val_acc: 0.1476\n",
      "Epoch 16/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2234 - acc: 0.1456 - val_loss: 2.2426 - val_acc: 0.1397\n",
      "Epoch 17/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2233 - acc: 0.1510 - val_loss: 2.2407 - val_acc: 0.1683\n",
      "Epoch 18/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2219 - acc: 0.1544 - val_loss: 2.2361 - val_acc: 0.1794\n",
      "Epoch 19/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2170 - acc: 0.1592 - val_loss: 2.2387 - val_acc: 0.1698\n",
      "Epoch 20/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2149 - acc: 0.1748 - val_loss: 2.2356 - val_acc: 0.1651\n",
      "Epoch 21/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2125 - acc: 0.1639 - val_loss: 2.2295 - val_acc: 0.1825\n",
      "Epoch 22/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2073 - acc: 0.1796 - val_loss: 2.2441 - val_acc: 0.1730\n",
      "Epoch 23/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2040 - acc: 0.1776 - val_loss: 2.2267 - val_acc: 0.1841\n",
      "Epoch 24/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1966 - acc: 0.1830 - val_loss: 2.2256 - val_acc: 0.1778\n",
      "Epoch 25/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1950 - acc: 0.1857 - val_loss: 2.2199 - val_acc: 0.1873\n",
      "Epoch 26/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1923 - acc: 0.1952 - val_loss: 2.2202 - val_acc: 0.1921\n",
      "Epoch 27/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1872 - acc: 0.1986 - val_loss: 2.2193 - val_acc: 0.1825\n",
      "Epoch 28/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1819 - acc: 0.1837 - val_loss: 2.2140 - val_acc: 0.1825\n",
      "Epoch 29/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1855 - acc: 0.1959 - val_loss: 2.2511 - val_acc: 0.1698\n",
      "Epoch 30/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1851 - acc: 0.1966 - val_loss: 2.2228 - val_acc: 0.1825\n",
      "Epoch 31/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1804 - acc: 0.1932 - val_loss: 2.2159 - val_acc: 0.1698\n",
      "Epoch 32/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1770 - acc: 0.2000 - val_loss: 2.2383 - val_acc: 0.1810\n",
      "Epoch 33/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1773 - acc: 0.1932 - val_loss: 2.2254 - val_acc: 0.1730\n",
      "Epoch 34/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1733 - acc: 0.2007 - val_loss: 2.2121 - val_acc: 0.1937\n",
      "Epoch 35/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1739 - acc: 0.2068 - val_loss: 2.2100 - val_acc: 0.1810\n",
      "Epoch 36/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1722 - acc: 0.2007 - val_loss: 2.2146 - val_acc: 0.1667\n",
      "Epoch 37/1000\n",
      "1470/1470 [==============================] - 7s 4ms/sample - loss: 2.1732 - acc: 0.1912 - val_loss: 2.2520 - val_acc: 0.1667\n",
      "Epoch 38/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1686 - acc: 0.2007 - val_loss: 2.2258 - val_acc: 0.1730\n",
      "Epoch 39/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1743 - acc: 0.1952 - val_loss: 2.2158 - val_acc: 0.1921\n",
      "Epoch 40/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1699 - acc: 0.1980 - val_loss: 2.2287 - val_acc: 0.1889\n",
      "Epoch 41/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1649 - acc: 0.2061 - val_loss: 2.2385 - val_acc: 0.1778\n",
      "Epoch 42/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1620 - acc: 0.2088 - val_loss: 2.2101 - val_acc: 0.1905\n",
      "Epoch 43/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1694 - acc: 0.1959 - val_loss: 2.2159 - val_acc: 0.1905\n",
      "Epoch 44/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1583 - acc: 0.2054 - val_loss: 2.2170 - val_acc: 0.1857\n",
      "Epoch 45/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1663 - acc: 0.2075 - val_loss: 2.2271 - val_acc: 0.1873\n",
      "Epoch 46/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1620 - acc: 0.2095 - val_loss: 2.2196 - val_acc: 0.1683\n",
      "Epoch 47/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1588 - acc: 0.2068 - val_loss: 2.2298 - val_acc: 0.1889\n",
      "Epoch 48/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1577 - acc: 0.2075 - val_loss: 2.2267 - val_acc: 0.1746\n",
      "Epoch 49/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1589 - acc: 0.2082 - val_loss: 2.2181 - val_acc: 0.1730\n",
      "Epoch 50/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1545 - acc: 0.1986 - val_loss: 2.2315 - val_acc: 0.1841\n",
      "Epoch 51/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1601 - acc: 0.1966 - val_loss: 2.2635 - val_acc: 0.1714\n",
      "Epoch 52/1000\n",
      "1470/1470 [==============================] - 7s 4ms/sample - loss: 2.1547 - acc: 0.2095 - val_loss: 2.2350 - val_acc: 0.1810\n",
      "Epoch 53/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1504 - acc: 0.2102 - val_loss: 2.2528 - val_acc: 0.1730\n",
      "Epoch 54/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.1506 - acc: 0.2034 - val_loss: 2.2213 - val_acc: 0.1794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.1492 - acc: 0.2102 - val_loss: 2.2284 - val_acc: 0.1841\n",
      "Epoch 56/1000\n",
      "1470/1470 [==============================] - 8s 5ms/sample - loss: 2.1510 - acc: 0.2027 - val_loss: 2.2547 - val_acc: 0.1714\n",
      "Epoch 57/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1466 - acc: 0.2163 - val_loss: 2.2573 - val_acc: 0.1841\n",
      "Epoch 58/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1480 - acc: 0.2054 - val_loss: 2.2201 - val_acc: 0.1746\n",
      "Epoch 59/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1446 - acc: 0.2048 - val_loss: 2.2430 - val_acc: 0.1651\n",
      "Epoch 60/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1484 - acc: 0.2014 - val_loss: 2.2225 - val_acc: 0.1810\n",
      "Epoch 61/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1407 - acc: 0.2136 - val_loss: 2.2437 - val_acc: 0.1698 loss: 2.1440 - ac\n",
      "Epoch 62/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1394 - acc: 0.2095 - val_loss: 2.2272 - val_acc: 0.1794\n",
      "Epoch 63/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1430 - acc: 0.2150 - val_loss: 2.2277 - val_acc: 0.1730\n",
      "Epoch 64/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1439 - acc: 0.2136 - val_loss: 2.2355 - val_acc: 0.1714\n",
      "Epoch 65/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1363 - acc: 0.2116 - val_loss: 2.2576 - val_acc: 0.1698\n",
      "Epoch 66/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1376 - acc: 0.2170 - val_loss: 2.2373 - val_acc: 0.1825\n",
      "Epoch 67/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1382 - acc: 0.2136 - val_loss: 2.2333 - val_acc: 0.1714\n",
      "Epoch 68/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1387 - acc: 0.2177 - val_loss: 2.2258 - val_acc: 0.1873\n",
      "Epoch 69/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1347 - acc: 0.2095 - val_loss: 2.2333 - val_acc: 0.1857\n",
      "Epoch 70/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1312 - acc: 0.2143 - val_loss: 2.2615 - val_acc: 0.1651\n",
      "Epoch 71/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1352 - acc: 0.2265 - val_loss: 2.2460 - val_acc: 0.1841\n",
      "Epoch 72/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1325 - acc: 0.2224 - val_loss: 2.2919 - val_acc: 0.1667\n",
      "Epoch 73/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1311 - acc: 0.2190 - val_loss: 2.2287 - val_acc: 0.1762\n",
      "Epoch 74/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1332 - acc: 0.2170 - val_loss: 2.2411 - val_acc: 0.1762\n",
      "Epoch 75/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1297 - acc: 0.2190 - val_loss: 2.2426 - val_acc: 0.1762\n",
      "Epoch 76/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1267 - acc: 0.2231 - val_loss: 2.2611 - val_acc: 0.1778\n",
      "Epoch 77/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1261 - acc: 0.2265 - val_loss: 2.2601 - val_acc: 0.1698\n",
      "Epoch 78/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1315 - acc: 0.2184 - val_loss: 2.2298 - val_acc: 0.1714\n",
      "Epoch 79/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1276 - acc: 0.2170 - val_loss: 2.2288 - val_acc: 0.1762\n",
      "Epoch 80/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1217 - acc: 0.2184 - val_loss: 2.2468 - val_acc: 0.1746\n",
      "Epoch 81/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1326 - acc: 0.2177 - val_loss: 2.2464 - val_acc: 0.1667\n",
      "Epoch 82/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.1281 - acc: 0.2170 - val_loss: 2.2222 - val_acc: 0.1714\n",
      "Epoch 83/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.1267 - acc: 0.2150 - val_loss: 2.2472 - val_acc: 0.1778\n",
      "Epoch 84/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1198 - acc: 0.2245 - val_loss: 2.2861 - val_acc: 0.1698\n",
      "Epoch 85/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1245 - acc: 0.2224 - val_loss: 2.2741 - val_acc: 0.1746\n",
      "Epoch 86/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1237 - acc: 0.2238 - val_loss: 2.2397 - val_acc: 0.1730\n",
      "Epoch 87/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1191 - acc: 0.2238 - val_loss: 2.2484 - val_acc: 0.1810\n",
      "Epoch 88/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1151 - acc: 0.2252 - val_loss: 2.2423 - val_acc: 0.1714\n",
      "Epoch 89/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1154 - acc: 0.2238 - val_loss: 2.2625 - val_acc: 0.1714\n",
      "Epoch 90/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1193 - acc: 0.2245 - val_loss: 2.2401 - val_acc: 0.1762\n",
      "Epoch 91/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1162 - acc: 0.2259 - val_loss: 2.2680 - val_acc: 0.1651\n",
      "Epoch 92/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1139 - acc: 0.2306 - val_loss: 2.2426 - val_acc: 0.1746\n",
      "Epoch 93/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1166 - acc: 0.2265 - val_loss: 2.2569 - val_acc: 0.1825\n",
      "Epoch 94/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1121 - acc: 0.2177 - val_loss: 2.2539 - val_acc: 0.1746\n",
      "Epoch 95/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1180 - acc: 0.2218 - val_loss: 2.2389 - val_acc: 0.1810\n",
      "Epoch 96/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1081 - acc: 0.2320 - val_loss: 2.2250 - val_acc: 0.1857\n",
      "Epoch 97/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1110 - acc: 0.2245 - val_loss: 2.2789 - val_acc: 0.1778\n",
      "Epoch 98/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1100 - acc: 0.2259 - val_loss: 2.2576 - val_acc: 0.1698\n",
      "Epoch 99/1000\n",
      "1470/1470 [==============================] - 8s 5ms/sample - loss: 2.1056 - acc: 0.2293 - val_loss: 2.2329 - val_acc: 0.1921\n",
      "Epoch 100/1000\n",
      "1470/1470 [==============================] - 8s 5ms/sample - loss: 2.1045 - acc: 0.2422 - val_loss: 2.2640 - val_acc: 0.1762\n",
      "Epoch 101/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1044 - acc: 0.2259 - val_loss: 2.2314 - val_acc: 0.1841\n",
      "Epoch 102/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1072 - acc: 0.2238 - val_loss: 2.2376 - val_acc: 0.1778\n",
      "Epoch 103/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1096 - acc: 0.2286 - val_loss: 2.2572 - val_acc: 0.1714\n",
      "Epoch 104/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0990 - acc: 0.2279 - val_loss: 2.2469 - val_acc: 0.1825\n",
      "Epoch 105/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0986 - acc: 0.2354 - val_loss: 2.2916 - val_acc: 0.1746\n",
      "Epoch 106/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0999 - acc: 0.2395 - val_loss: 2.2576 - val_acc: 0.1794\n",
      "Epoch 107/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1003 - acc: 0.2333 - val_loss: 2.2614 - val_acc: 0.1730\n",
      "Epoch 108/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1023 - acc: 0.2354 - val_loss: 2.2968 - val_acc: 0.1730\n",
      "Epoch 109/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0990 - acc: 0.2299 - val_loss: 2.2453 - val_acc: 0.1810\n",
      "Epoch 110/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0977 - acc: 0.2333 - val_loss: 2.2457 - val_acc: 0.1746\n",
      "Epoch 111/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0970 - acc: 0.2333 - val_loss: 2.3022 - val_acc: 0.1698\n",
      "Epoch 112/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0912 - acc: 0.2286 - val_loss: 2.2835 - val_acc: 0.1714\n",
      "Epoch 113/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0893 - acc: 0.2347 - val_loss: 2.2942 - val_acc: 0.1698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0899 - acc: 0.2333 - val_loss: 2.2601 - val_acc: 0.1762\n",
      "Epoch 115/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0861 - acc: 0.2395 - val_loss: 2.2712 - val_acc: 0.1778\n",
      "Epoch 116/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0879 - acc: 0.2293 - val_loss: 2.3003 - val_acc: 0.1794\n",
      "Epoch 117/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.0894 - acc: 0.2340 - val_loss: 2.2726 - val_acc: 0.1794\n",
      "Epoch 118/1000\n",
      "1470/1470 [==============================] - 8s 5ms/sample - loss: 2.0880 - acc: 0.2333 - val_loss: 2.2890 - val_acc: 0.1873\n",
      "Epoch 119/1000\n",
      "1470/1470 [==============================] - 8s 5ms/sample - loss: 2.0847 - acc: 0.2320 - val_loss: 2.2643 - val_acc: 0.1714\n",
      "Epoch 120/1000\n",
      "1470/1470 [==============================] - 7s 4ms/sample - loss: 2.0907 - acc: 0.2442 - val_loss: 2.2782 - val_acc: 0.1683\n",
      "Epoch 121/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0851 - acc: 0.2361 - val_loss: 2.2970 - val_acc: 0.1746\n",
      "Epoch 122/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0778 - acc: 0.2354 - val_loss: 2.2872 - val_acc: 0.1778\n",
      "Epoch 123/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0854 - acc: 0.2367 - val_loss: 2.2734 - val_acc: 0.1730\n",
      "Epoch 124/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0805 - acc: 0.2442 - val_loss: 2.3038 - val_acc: 0.1667\n",
      "Epoch 125/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0815 - acc: 0.2374 - val_loss: 2.2732 - val_acc: 0.1778\n",
      "Epoch 126/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0770 - acc: 0.2231 - val_loss: 2.2946 - val_acc: 0.1556\n",
      "Epoch 127/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0827 - acc: 0.2374 - val_loss: 2.3058 - val_acc: 0.1651\n",
      "Epoch 128/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0748 - acc: 0.2469 - val_loss: 2.2772 - val_acc: 0.1841\n",
      "Epoch 129/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0775 - acc: 0.2354 - val_loss: 2.3022 - val_acc: 0.1683\n",
      "Epoch 130/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0751 - acc: 0.2531 - val_loss: 2.2461 - val_acc: 0.1968\n",
      "Epoch 131/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0806 - acc: 0.2313 - val_loss: 2.3212 - val_acc: 0.1714\n",
      "Epoch 132/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0792 - acc: 0.2259 - val_loss: 2.2792 - val_acc: 0.1841\n",
      "Epoch 133/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0662 - acc: 0.2401 - val_loss: 2.3151 - val_acc: 0.1698\n",
      "Epoch 134/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0704 - acc: 0.2571 - val_loss: 2.2953 - val_acc: 0.1603\n",
      "Epoch 135/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.0761 - acc: 0.2463 - val_loss: 2.3523 - val_acc: 0.1667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x215e7c38a08>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience = 100, monitor='val_loss', restore_best_weights=True)\n",
    "model = init_model()\n",
    "model.fit(X_train, y_train, batch_size = 8, epochs=1000, validation_split = 0.3, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 122us/sample - loss: 2.2132 - acc: 0.1800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.213210598627726, 0.18]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renvoie le député le plus proche de votre tweet\n",
    "def predict_deputy(df, model, tweet, by_tweet = False):\n",
    "    '''\n",
    "    La fonction prend la base de données originale (par député), un modèle entraîné et un texte en entrée.\n",
    "    Elle renvoie le député le plus proche du texte proposé.\n",
    "    Attention : le texte en entrée doit être une liste d'au moins deux éléments (strings).\n",
    "    Quand by_tweet = False, on ressort le député le plus proche de l'ENSEMBLE des tweets.\n",
    "    Quand by_tweet = True, on sort le député le plus proche POUR CHAQUE tweet.\n",
    "    '''\n",
    "    tweet_inter = []\n",
    "    for tw in tweet:\n",
    "        tweet_inter.append(tw.split())\n",
    "    X_example = embedding(word2vec,tweet_inter)\n",
    "    X_example_pad = pad_sequences(X_example, padding='post',value=-1000, dtype='float32')\n",
    "    prediction = model.predict(X_example_pad)\n",
    "    if not by_tweet:\n",
    "        deputy = list(df['name'])[prediction.sum(axis=0).argmax()]\n",
    "        return deputy\n",
    "    else:\n",
    "        deputies_by_tweet = []\n",
    "        for element in prediction:\n",
    "            deputies_by_tweet.append(list(df['name'])[element.argmax()])\n",
    "        return deputies_by_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_deputy(testbase_deputy_df,\n",
    "                            model, \n",
    "                            ['the northern ireland protocol must protected line real effort must made earnest week bridge gap talks come table many times good faith amp view securing future partnership respects standards union', \n",
    "                             'member special committee beating cancer look forward working members contributing important fight cancer',\n",
    "                             'this month shining light childrens cancer parliament buildings lit gold highlight survivors childrens cancer well diagnosed cancer'], \n",
    "                            by_tweet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Luke Ming FLANAGAN'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this month shining light childrens cancer parliament buildings lit gold highlight survivors childrens cancer well diagnosed cancer'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbase_df['content'][24724]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24722</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>the northern ireland protocol must protected l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24723</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>member special committee beating cancer look f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>this month shining light childrens cancer parl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24725</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>yesterday told europe need keep speed amp infr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24726</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>this letter sent taoiseach clear seeking clari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130490</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>brendan its favourite item desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130491</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>monday mornings mean tidy desk chaos ahead wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130492</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>fergal post kick new week thank folks like mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130493</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>it took rare vision unique leadership see beyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130494</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>took mins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mep_id           name  country  \\\n",
       "24722   124988  Deirdre CLUNE  Ireland   \n",
       "24723   124988  Deirdre CLUNE  Ireland   \n",
       "24724   124988  Deirdre CLUNE  Ireland   \n",
       "24725   124988  Deirdre CLUNE  Ireland   \n",
       "24726   124988  Deirdre CLUNE  Ireland   \n",
       "...        ...            ...      ...   \n",
       "130490  197863    Maria WALSH  Ireland   \n",
       "130491  197863    Maria WALSH  Ireland   \n",
       "130492  197863    Maria WALSH  Ireland   \n",
       "130493  197863    Maria WALSH  Ireland   \n",
       "130494  197863    Maria WALSH  Ireland   \n",
       "\n",
       "                                                    group        nat_group  \\\n",
       "24722   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24723   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24724   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24725   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24726   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "...                                                   ...              ...   \n",
       "130490  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130491  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130492  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130493  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130494  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "\n",
       "                twitter                                            content  \n",
       "24722   deirdreclunemep  the northern ireland protocol must protected l...  \n",
       "24723   deirdreclunemep  member special committee beating cancer look f...  \n",
       "24724   deirdreclunemep  this month shining light childrens cancer parl...  \n",
       "24725   deirdreclunemep  yesterday told europe need keep speed amp infr...  \n",
       "24726   deirdreclunemep  this letter sent taoiseach clear seeking clari...  \n",
       "...                 ...                                                ...  \n",
       "130490     mariawalsheu                    brendan its favourite item desk  \n",
       "130491     mariawalsheu  monday mornings mean tidy desk chaos ahead wee...  \n",
       "130492     mariawalsheu  fergal post kick new week thank folks like mak...  \n",
       "130493     mariawalsheu  it took rare vision unique leadership see beyo...  \n",
       "130494     mariawalsheu                                          took mins  \n",
       "\n",
       "[3000 rows x 7 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbase_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bac à sable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "danish_df = pd.read_pickle('../../delphes/data/six_merged')\n",
    "#inter_df = pd.merge(danish_df, clean_df.reset_index()[['index','age', 'sex']], on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>content_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>836</td>\n",
       "      <td>125045</td>\n",
       "      <td>Clara AGUILERA</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista Obrero Español</td>\n",
       "      <td>ClaraAguilera7</td>\n",
       "      <td>Clara Aguilera: \"El criterio científico debe p...</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.0403111, 0.0812186, -0.0355939, 0.0331782,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>837</td>\n",
       "      <td>125045</td>\n",
       "      <td>Clara AGUILERA</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista Obrero Español</td>\n",
       "      <td>ClaraAguilera7</td>\n",
       "      <td>🇪🇺🎊🎊🎊as @EUfoodforum we are super proud that o...</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.0436824, -0.0149531, -0.0435268, 0.025988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>838</td>\n",
       "      <td>125045</td>\n",
       "      <td>Clara AGUILERA</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista Obrero Español</td>\n",
       "      <td>ClaraAguilera7</td>\n",
       "      <td>Clara Aguilera: \"El criterio científico debe p...</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.0403111, 0.0812186, -0.0355939, 0.0331782,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>839</td>\n",
       "      <td>125045</td>\n",
       "      <td>Clara AGUILERA</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista Obrero Español</td>\n",
       "      <td>ClaraAguilera7</td>\n",
       "      <td>🗣️ @ClaraAguilera7: \"El criterio científico de...</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[False, [-0.0675644, 0.0040941, -0.0185521, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>840</td>\n",
       "      <td>125045</td>\n",
       "      <td>Clara AGUILERA</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista Obrero Español</td>\n",
       "      <td>ClaraAguilera7</td>\n",
       "      <td>Última hora: Bélgica sitúa a toda España en ro...</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[False, [0.0225546, 0.0994218, -0.0251348, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37387</th>\n",
       "      <td>136695</td>\n",
       "      <td>124739</td>\n",
       "      <td>Carlos ZORRINHO</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista</td>\n",
       "      <td>czorrinho</td>\n",
       "      <td>Dia 12.05.2020\\n18h\\n9Temas 9Debates 9Deputad@...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37388</th>\n",
       "      <td>136696</td>\n",
       "      <td>124739</td>\n",
       "      <td>Carlos ZORRINHO</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista</td>\n",
       "      <td>czorrinho</td>\n",
       "      <td>Uma entrevista notável ... recomendo. https://...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[-0.0529539, 0.00473264, -0.00307722, 0.00865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37389</th>\n",
       "      <td>136697</td>\n",
       "      <td>124739</td>\n",
       "      <td>Carlos ZORRINHO</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista</td>\n",
       "      <td>czorrinho</td>\n",
       "      <td>Comemorar a Europa dos Valores https://t.co/dz...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[-0.0290561, 0.00908396, 0.0969392, 0.0101425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37390</th>\n",
       "      <td>136698</td>\n",
       "      <td>124739</td>\n",
       "      <td>Carlos ZORRINHO</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista</td>\n",
       "      <td>czorrinho</td>\n",
       "      <td>#EuropeDay2020 #TheProgressives\\n@PedroMarques...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37391</th>\n",
       "      <td>136699</td>\n",
       "      <td>124739</td>\n",
       "      <td>Carlos ZORRINHO</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista</td>\n",
       "      <td>czorrinho</td>\n",
       "      <td>E também para os meus caros amig@s que continu...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[-0.0200214, -0.0697937, -0.0635534, 0.044433...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37392 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  mep_id             name   country  \\\n",
       "0         836  125045   Clara AGUILERA     Spain   \n",
       "1         837  125045   Clara AGUILERA     Spain   \n",
       "2         838  125045   Clara AGUILERA     Spain   \n",
       "3         839  125045   Clara AGUILERA     Spain   \n",
       "4         840  125045   Clara AGUILERA     Spain   \n",
       "...       ...     ...              ...       ...   \n",
       "37387  136695  124739  Carlos ZORRINHO  Portugal   \n",
       "37388  136696  124739  Carlos ZORRINHO  Portugal   \n",
       "37389  136697  124739  Carlos ZORRINHO  Portugal   \n",
       "37390  136698  124739  Carlos ZORRINHO  Portugal   \n",
       "37391  136699  124739  Carlos ZORRINHO  Portugal   \n",
       "\n",
       "                                                   group  \\\n",
       "0      Group of the Progressive Alliance of Socialist...   \n",
       "1      Group of the Progressive Alliance of Socialist...   \n",
       "2      Group of the Progressive Alliance of Socialist...   \n",
       "3      Group of the Progressive Alliance of Socialist...   \n",
       "4      Group of the Progressive Alliance of Socialist...   \n",
       "...                                                  ...   \n",
       "37387  Group of the Progressive Alliance of Socialist...   \n",
       "37388  Group of the Progressive Alliance of Socialist...   \n",
       "37389  Group of the Progressive Alliance of Socialist...   \n",
       "37390  Group of the Progressive Alliance of Socialist...   \n",
       "37391  Group of the Progressive Alliance of Socialist...   \n",
       "\n",
       "                               nat_group         twitter  \\\n",
       "0      Partido Socialista Obrero Español  ClaraAguilera7   \n",
       "1      Partido Socialista Obrero Español  ClaraAguilera7   \n",
       "2      Partido Socialista Obrero Español  ClaraAguilera7   \n",
       "3      Partido Socialista Obrero Español  ClaraAguilera7   \n",
       "4      Partido Socialista Obrero Español  ClaraAguilera7   \n",
       "...                                  ...             ...   \n",
       "37387                 Partido Socialista       czorrinho   \n",
       "37388                 Partido Socialista       czorrinho   \n",
       "37389                 Partido Socialista       czorrinho   \n",
       "37390                 Partido Socialista       czorrinho   \n",
       "37391                 Partido Socialista       czorrinho   \n",
       "\n",
       "                                                 content  age  sex  \\\n",
       "0      Clara Aguilera: \"El criterio científico debe p...   56  1.0   \n",
       "1      🇪🇺🎊🎊🎊as @EUfoodforum we are super proud that o...   56  1.0   \n",
       "2      Clara Aguilera: \"El criterio científico debe p...   56  1.0   \n",
       "3      🗣️ @ClaraAguilera7: \"El criterio científico de...   56  1.0   \n",
       "4      Última hora: Bélgica sitúa a toda España en ro...   56  1.0   \n",
       "...                                                  ...  ...  ...   \n",
       "37387  Dia 12.05.2020\\n18h\\n9Temas 9Debates 9Deputad@...   40  0.0   \n",
       "37388  Uma entrevista notável ... recomendo. https://...   40  0.0   \n",
       "37389  Comemorar a Europa dos Valores https://t.co/dz...   40  0.0   \n",
       "37390  #EuropeDay2020 #TheProgressives\\n@PedroMarques...   40  0.0   \n",
       "37391  E também para os meus caros amig@s que continu...   40  0.0   \n",
       "\n",
       "                                               content_y  \n",
       "0      [[0.0403111, 0.0812186, -0.0355939, 0.0331782,...  \n",
       "1      [[-0.0436824, -0.0149531, -0.0435268, 0.025988...  \n",
       "2      [[0.0403111, 0.0812186, -0.0355939, 0.0331782,...  \n",
       "3      [False, [-0.0675644, 0.0040941, -0.0185521, 0....  \n",
       "4      [False, [0.0225546, 0.0994218, -0.0251348, -0....  \n",
       "...                                                  ...  \n",
       "37387  [False, False, False, False, False, False, Fal...  \n",
       "37388  [[-0.0529539, 0.00473264, -0.00307722, 0.00865...  \n",
       "37389  [[-0.0290561, 0.00908396, 0.0969392, 0.0101425...  \n",
       "37390                                            [False]  \n",
       "37391  [[-0.0200214, -0.0697937, -0.0635534, 0.044433...  \n",
       "\n",
       "[37392 rows x 11 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "danish_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = danish_df[['sex','content_y']].dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sex</th>\n",
       "      <th>content_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.0403111, 0.0812186, -0.0355939, 0.0331782,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.0436824, -0.0149531, -0.0435268, 0.025988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.0403111, 0.0812186, -0.0355939, 0.0331782,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[False, [-0.0675644, 0.0040941, -0.0185521, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[False, [0.0225546, 0.0994218, -0.0251348, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37154</th>\n",
       "      <td>37387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37155</th>\n",
       "      <td>37388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[-0.0529539, 0.00473264, -0.00307722, 0.00865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37156</th>\n",
       "      <td>37389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[-0.0290561, 0.00908396, 0.0969392, 0.0101425...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37157</th>\n",
       "      <td>37390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37158</th>\n",
       "      <td>37391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[-0.0200214, -0.0697937, -0.0635534, 0.044433...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37159 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  sex                                          content_y\n",
       "0          0  1.0  [[0.0403111, 0.0812186, -0.0355939, 0.0331782,...\n",
       "1          1  1.0  [[-0.0436824, -0.0149531, -0.0435268, 0.025988...\n",
       "2          2  1.0  [[0.0403111, 0.0812186, -0.0355939, 0.0331782,...\n",
       "3          3  1.0  [False, [-0.0675644, 0.0040941, -0.0185521, 0....\n",
       "4          4  1.0  [False, [0.0225546, 0.0994218, -0.0251348, -0....\n",
       "...      ...  ...                                                ...\n",
       "37154  37387  0.0  [False, False, False, False, False, False, Fal...\n",
       "37155  37388  0.0  [[-0.0529539, 0.00473264, -0.00307722, 0.00865...\n",
       "37156  37389  0.0  [[-0.0290561, 0.00908396, 0.0969392, 0.0101425...\n",
       "37157  37390  0.0                                            [False]\n",
       "37158  37391  0.0  [[-0.0200214, -0.0697937, -0.0635534, 0.044433...\n",
       "\n",
       "[37159 rows x 3 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37159"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df['content_y'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(working_df['content_y'][0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_items = [x if type(x) == np.ndarray else np.array([-1000]*100) for x in working_df['content_y'][4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000]),\n",
       " array([ 0.0225546 ,  0.0994218 , -0.0251348 , -0.104368  , -0.00467696,\n",
       "         0.0161251 , -0.0264484 , -0.0260037 ,  0.024174  ,  0.0232939 ,\n",
       "         0.0372348 , -0.122873  ,  0.0492365 ,  0.0236814 ,  0.0835675 ,\n",
       "        -0.047992  ,  0.132447  , -0.0906287 ,  0.0271184 ,  0.0890322 ,\n",
       "        -0.0269458 ,  0.0283006 , -0.0540523 , -0.100378  , -0.00704953,\n",
       "        -0.0612816 ,  0.0352087 , -0.00066748, -0.00298344,  0.0613473 ,\n",
       "        -0.0643288 ,  0.0252034 , -0.124545  ,  0.0186718 , -0.0135    ,\n",
       "         0.00881149,  0.0563391 , -0.0905863 ,  0.0788115 ,  0.00785901,\n",
       "        -0.0115537 ,  0.00506054,  0.108951  , -0.0721079 ,  0.0446604 ,\n",
       "         0.0491114 ,  0.0158108 , -0.0164109 , -0.0241042 , -0.0128352 ,\n",
       "         0.00175071, -0.025039  ,  0.0560312 , -0.0371342 , -0.00176194,\n",
       "         0.0523126 ,  0.0708322 ,  0.0482872 ,  0.0211753 , -0.00973071,\n",
       "         0.0537007 , -0.0684061 ,  0.116367  , -0.0232576 ,  0.0487177 ,\n",
       "        -0.14324   , -0.0669451 ,  0.0996624 ,  0.011007  ,  0.0381004 ,\n",
       "        -0.054981  ,  0.0621127 , -0.0382988 , -0.00644564,  0.0319117 ,\n",
       "         0.0485568 ,  0.101161  ,  0.00733634,  0.0277776 , -0.0430642 ,\n",
       "         0.0684707 ,  0.0363233 , -0.0375437 , -0.0592871 ,  0.00465178,\n",
       "         0.0409787 ,  0.0730483 ,  0.0162216 ,  0.122133  , -0.0493023 ,\n",
       "        -0.0217519 ,  0.00754204,  0.0893684 , -0.0707009 , -0.0479521 ,\n",
       "        -0.00393191, -0.0322393 , -0.044655  ,  0.0129731 ,  0.0579054 ,\n",
       "         0.110325  ,  0.0516284 ,  0.0931996 ,  0.021065  , -0.0385815 ,\n",
       "        -0.0719151 ,  0.0572352 ,  0.0311454 , -0.0376927 , -0.00208735,\n",
       "         0.0909278 ,  0.0148941 , -0.0845019 , -0.104867  , -0.0372381 ,\n",
       "        -0.0286843 ,  0.0457961 , -0.0441288 , -0.0140102 , -0.0823896 ,\n",
       "         0.0772369 ,  0.0397889 ,  0.0236822 ,  0.0192007 ,  0.097159  ,\n",
       "        -0.0244408 ,  0.013645  ,  0.0286008 ,  0.0311503 ,  0.0219683 ,\n",
       "         0.031056  ,  0.210112  , -0.0567183 , -0.00567763,  0.0826426 ,\n",
       "        -0.0394264 ,  0.0327358 , -0.0201001 ,  0.0797272 ,  0.0130296 ,\n",
       "        -0.0195443 ,  0.0410237 , -0.00982299,  0.00497697, -0.0156946 ,\n",
       "         0.033477  ,  0.0557573 , -0.0982368 , -0.00699828,  0.0944497 ,\n",
       "         0.118595  , -0.0625005 ,  0.0356223 , -0.0220846 , -0.0407839 ,\n",
       "        -0.0436081 , -0.0615951 , -0.017774  ,  0.056289  ,  0.00788447,\n",
       "         0.00466338,  0.0284658 , -0.118264  , -0.0471782 ,  0.0268079 ,\n",
       "        -0.00424563, -0.0570085 ,  0.00325443,  0.0261203 , -0.0342677 ,\n",
       "         0.0691694 ,  0.0371285 , -0.0443407 ,  0.0354458 ,  0.077887  ,\n",
       "         0.0715736 , -0.0466944 ,  0.103068  , -0.00198068, -0.127114  ,\n",
       "         0.0151511 ,  0.00190604,  0.0330445 , -0.0147606 ,  0.0093508 ,\n",
       "        -0.0289856 , -0.0607729 , -0.0787083 ,  0.0301788 ,  0.0534178 ,\n",
       "         0.00167099, -0.054893  , -0.0195413 , -0.0643172 , -0.144207  ,\n",
       "        -0.100932  ,  0.030497  ,  0.0202506 ,  0.0102747 , -0.118751  ,\n",
       "         0.034499  , -0.011844  , -0.00427553, -0.0451325 ,  0.0754661 ,\n",
       "        -0.0144241 ,  0.0165503 ,  0.0412759 ,  0.106966  , -0.0752475 ,\n",
       "         0.10198   , -0.0178322 ,  0.0112525 , -0.0889024 , -0.0856721 ,\n",
       "         0.00149238, -0.0156456 , -0.150205  , -0.0128601 , -0.00426181,\n",
       "         0.042713  ,  0.055921  , -0.0399163 ,  0.0835596 ,  0.0865405 ,\n",
       "         0.049743  ,  0.0221557 , -0.0360137 ,  0.00207633, -0.00799375,\n",
       "        -0.0191114 ,  0.0125675 ,  0.0337148 ,  0.0531382 , -0.0540211 ,\n",
       "        -0.00335003, -0.0366231 , -0.00692722,  0.048901  , -0.0147777 ,\n",
       "         0.0871026 ,  0.0372355 ,  0.0226944 , -0.0297186 , -0.0029034 ,\n",
       "         0.155933  ,  0.0728993 ,  0.0246184 ,  0.0462829 , -0.0186529 ,\n",
       "        -0.0957666 , -0.0477359 , -0.0597167 ,  0.00340812,  0.010678  ,\n",
       "        -0.00864282,  0.0218747 , -0.164144  , -0.0153517 , -0.0223501 ,\n",
       "         0.0457968 , -0.036238  , -0.0347447 , -0.0467571 ,  0.00733184,\n",
       "        -0.0593848 , -0.0292882 ,  0.0206604 , -0.0846005 ,  0.00991046,\n",
       "        -0.0569075 , -0.0106149 ,  0.0361307 ,  0.0518171 , -0.0114868 ,\n",
       "        -0.0315112 ,  0.0162648 ,  0.120039  ,  0.0786684 , -0.0196774 ,\n",
       "         0.0458981 ,  0.0740933 ,  0.00107306,  0.0130856 ,  0.0216256 ,\n",
       "        -0.0748294 ,  0.0765372 , -0.0284273 , -0.0402584 ,  0.00550521,\n",
       "         0.0218428 ,  0.0403447 , -0.0476193 , -0.0684513 ,  0.0434636 ,\n",
       "        -0.0886592 , -0.0202307 , -0.0354462 ,  0.0940025 ,  0.0846841 ]),\n",
       " array([-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000]),\n",
       " array([ 1.72067e-02,  4.30627e-02,  4.27729e-02, -8.12772e-03,\n",
       "        -1.31360e-02,  6.02898e-02,  7.98290e-02,  3.66894e-02,\n",
       "         4.15387e-02,  4.47180e-02,  6.35714e-02, -6.23597e-02,\n",
       "        -2.88794e-03,  5.89459e-03,  2.68001e-02, -2.33788e-02,\n",
       "        -4.42640e-02,  4.60986e-02, -2.06992e-02,  1.01679e-01,\n",
       "        -1.37059e-01,  1.21881e-01, -1.19355e-01, -8.40438e-02,\n",
       "        -7.68192e-02,  4.38679e-02, -5.48462e-02, -6.28393e-03,\n",
       "        -2.30840e-02, -6.77815e-02, -1.26879e-02,  1.96358e-01,\n",
       "        -2.57071e-02, -5.17830e-03, -7.63321e-02, -5.04685e-02,\n",
       "        -1.36089e-02, -2.85289e-02,  9.37946e-03, -5.54118e-03,\n",
       "         9.72091e-02, -5.29799e-02, -4.33662e-02, -8.85333e-02,\n",
       "         4.92510e-05,  2.39740e-02,  5.10008e-02, -4.04235e-02,\n",
       "        -4.58731e-02,  5.71775e-02,  3.87837e-02,  5.21256e-02,\n",
       "         3.24677e-02,  1.12578e-01, -4.29641e-02, -7.98240e-03,\n",
       "         7.67132e-02, -7.33373e-03, -4.34309e-02,  1.45699e-02,\n",
       "         5.49481e-02, -2.38553e-02, -5.27658e-02, -5.98284e-03,\n",
       "        -3.62784e-02, -9.86148e-02, -3.72997e-02,  3.93499e-02,\n",
       "        -6.74121e-03,  1.08617e-01, -6.46872e-03,  3.06118e-02,\n",
       "         1.77682e-01, -4.55007e-02, -1.00218e-02, -1.00541e-01,\n",
       "         1.85314e-02, -3.13401e-02, -1.01378e-01, -9.05844e-03,\n",
       "        -4.33109e-03,  2.93256e-02,  2.13771e-02, -5.69239e-02,\n",
       "         9.74954e-03,  1.09954e-02, -9.12578e-02, -2.73917e-02,\n",
       "        -4.73506e-02,  1.00737e-02,  2.26672e-02, -5.73872e-02,\n",
       "         2.23327e-02, -5.86153e-03,  4.89151e-03,  5.55468e-02,\n",
       "         4.96313e-02, -1.07619e-02,  1.13876e-02, -8.23845e-02,\n",
       "        -3.92888e-02, -2.09367e-02, -8.33003e-02, -8.84251e-02,\n",
       "         1.77311e-02,  7.87899e-02, -5.62879e-02, -8.81491e-03,\n",
       "         1.33903e-02, -3.93380e-02, -1.10537e-02,  3.24499e-02,\n",
       "        -9.33061e-02, -9.61127e-02, -1.95718e-02, -1.58244e-01,\n",
       "         2.78591e-02,  8.45764e-02, -6.44001e-02,  4.27230e-02,\n",
       "         1.03928e-01,  4.29984e-02,  1.06066e-01,  9.33276e-02,\n",
       "         1.53091e-02, -2.10991e-02, -5.24554e-02,  2.32175e-02,\n",
       "         4.35954e-02, -4.84584e-02, -2.98821e-02,  7.55933e-03,\n",
       "         1.03378e-01, -1.84944e-02, -1.17294e-02, -2.86718e-02,\n",
       "         4.77883e-02,  5.80019e-02, -4.89888e-02,  1.07564e-01,\n",
       "        -9.51564e-02,  1.58089e-02, -4.24973e-02,  8.17289e-02,\n",
       "         8.04809e-02,  1.83573e-02,  3.76795e-03, -2.64146e-02,\n",
       "         4.29471e-02,  1.14394e-01, -2.41224e-02, -1.02052e-01,\n",
       "        -8.98384e-02, -1.74549e-02,  2.13801e-02,  1.28189e-04,\n",
       "         3.40616e-03, -2.46311e-02,  6.01028e-02,  4.50468e-02,\n",
       "         2.03424e-02, -6.88084e-04, -7.73333e-03,  4.57481e-02,\n",
       "         6.85501e-03, -7.26997e-02, -2.01265e-02,  1.80819e-02,\n",
       "         8.04908e-02,  1.00682e-01, -1.93567e-02, -8.44670e-03,\n",
       "         2.61767e-02, -6.09798e-02, -1.53757e-01,  5.08347e-02,\n",
       "        -7.63299e-03,  1.07358e-02, -7.41401e-03,  5.08097e-02,\n",
       "         4.84882e-02,  7.59824e-02, -6.75765e-02, -3.44262e-02,\n",
       "        -8.94420e-03, -3.78865e-02, -1.97859e-02, -6.34856e-03,\n",
       "         4.71389e-02,  4.58572e-02,  4.91879e-02,  9.51239e-02,\n",
       "         4.55636e-02,  5.85226e-02, -1.61208e-01, -3.32252e-02,\n",
       "         8.65054e-03, -1.13050e-01, -5.15994e-02,  1.92924e-02,\n",
       "         2.17999e-02,  1.53272e-02,  5.54226e-03,  3.88732e-02,\n",
       "        -9.42300e-02, -1.03925e-01,  2.25995e-03, -1.73953e-02,\n",
       "         2.94622e-02, -5.63740e-02,  1.12518e-01,  1.01667e-02,\n",
       "         8.58177e-02,  1.32304e-02,  6.06526e-02, -8.28385e-02,\n",
       "         6.43992e-02, -2.77481e-02, -8.89828e-02,  1.49935e-02,\n",
       "         6.91857e-02, -3.35200e-03, -4.88287e-02,  3.04709e-02,\n",
       "         9.66756e-02, -4.39006e-02, -8.17117e-02, -3.09904e-02,\n",
       "        -3.95307e-02, -2.75549e-02,  2.67623e-02, -2.22389e-02,\n",
       "        -7.49499e-02,  1.81394e-02,  5.55614e-03,  1.24446e-02,\n",
       "         9.96270e-03, -5.97677e-02,  6.13727e-02,  6.15030e-03,\n",
       "        -3.71874e-03,  6.34991e-02, -7.38913e-02,  7.21284e-02,\n",
       "        -5.65347e-02, -4.07752e-02, -1.16351e-01,  7.45118e-02,\n",
       "         2.57345e-02,  3.58955e-02,  1.04341e-01,  4.49995e-02,\n",
       "        -6.27610e-03, -5.31291e-02, -4.01412e-02,  2.65235e-02,\n",
       "         7.15556e-03, -1.48956e-02,  1.01104e-01, -5.75811e-02,\n",
       "        -4.00734e-02, -4.16853e-02, -7.76184e-02,  3.16886e-02,\n",
       "        -2.04024e-02, -3.57557e-02,  4.21223e-02,  8.12499e-02,\n",
       "         2.45048e-02, -4.30532e-03, -5.60074e-02, -6.02615e-02,\n",
       "        -5.19095e-02,  2.95227e-02, -1.08754e-01, -1.73181e-02,\n",
       "         9.12896e-02,  2.48764e-02, -1.59999e-02,  3.56136e-02,\n",
       "         4.19783e-03, -1.73241e-03, -7.17206e-02,  4.92290e-02,\n",
       "        -1.59345e-02,  6.64026e-02, -4.05421e-02, -1.74069e-02,\n",
       "        -2.78747e-02,  1.67617e-03, -3.26501e-02, -3.89455e-02,\n",
       "        -5.20976e-02,  5.99980e-02,  3.24024e-02, -1.17659e-01,\n",
       "        -5.67699e-02,  4.57236e-02, -2.29029e-03,  6.50198e-02]),\n",
       " array([ 0.00975112,  0.119637  , -0.0942776 , -0.0464149 , -0.0405434 ,\n",
       "         0.0475084 ,  0.0341872 ,  0.0266829 , -0.0355644 ,  0.148003  ,\n",
       "         0.0681747 , -0.0877465 , -0.0283309 , -0.056195  ,  0.0114812 ,\n",
       "         0.0438521 , -0.0808381 ,  0.00349589, -0.0155833 ,  0.0698691 ,\n",
       "        -0.00705903,  0.0350561 , -0.0915204 , -0.00819792,  0.00479954,\n",
       "        -0.0177702 , -0.00994384, -0.108691  ,  0.008076  , -0.0209999 ,\n",
       "         0.00426352,  0.0702555 , -0.0877146 ,  0.0910797 , -0.0147118 ,\n",
       "        -0.11022   ,  0.0349289 , -0.0851626 ,  0.00283883,  0.0750625 ,\n",
       "         0.0730617 , -0.0312385 , -0.0256113 , -0.0315099 ,  0.0347672 ,\n",
       "         0.0652587 ,  0.0988442 ,  0.0823979 ,  0.0689653 , -0.158082  ,\n",
       "        -0.00817641, -0.0464158 ,  0.0574543 , -0.0144348 , -0.0958095 ,\n",
       "         0.02447   ,  0.0374128 , -0.0076234 , -0.0600084 ,  0.023464  ,\n",
       "         0.01985   , -0.0847562 ,  0.0872168 ,  0.00823615,  0.0127491 ,\n",
       "         0.0181383 , -0.126212  , -0.0121579 , -0.0223335 ,  0.00148263,\n",
       "        -0.0563427 ,  0.0144894 ,  0.0832793 , -0.177106  , -0.0517708 ,\n",
       "        -0.0542267 ,  0.123522  ,  0.0595698 ,  0.00219836,  0.0156276 ,\n",
       "         0.0353615 ,  0.0186483 , -0.0429712 , -0.00473874, -0.034195  ,\n",
       "         0.028294  ,  0.046897  ,  0.0644226 ,  0.106598  , -0.00026571,\n",
       "        -0.00815025,  0.00438235,  0.109577  , -0.0406536 , -0.0719481 ,\n",
       "         0.0736738 ,  0.0275263 , -0.0491297 ,  0.00337114, -0.107607  ,\n",
       "        -0.0425055 ,  0.0382756 ,  0.0650691 , -0.00754835, -0.078798  ,\n",
       "         0.00483923, -0.0186827 ,  0.0460076 ,  0.0578245 ,  0.0159246 ,\n",
       "        -0.0178582 , -0.0492316 ,  0.00614735, -0.0202196 , -0.00607911,\n",
       "        -0.007078  ,  0.0671585 ,  0.0297627 , -0.0805695 , -0.0156748 ,\n",
       "        -0.00812021,  0.0745784 ,  0.0481133 ,  0.06913   ,  0.0675901 ,\n",
       "        -0.085362  ,  0.0251587 ,  0.0119791 ,  0.0171626 ,  0.0727988 ,\n",
       "        -0.0318013 , -0.0016124 , -0.0352005 ,  0.0177587 ,  0.0282304 ,\n",
       "         0.116075  , -0.032585  , -0.0285519 , -0.0775812 ,  0.0595998 ,\n",
       "        -0.0182417 ,  0.0426937 ,  0.00515793, -0.00357626,  0.0414304 ,\n",
       "         0.0729902 ,  0.0148321 , -0.0238366 ,  0.0554372 ,  0.0469339 ,\n",
       "         0.0147837 , -0.0850903 , -0.00783743, -0.0524577 , -0.0337407 ,\n",
       "        -0.114862  , -0.0686778 , -0.0705654 ,  0.0488455 , -0.0265024 ,\n",
       "        -0.0491378 ,  0.0351447 ,  0.00272222,  0.00390732,  0.118423  ,\n",
       "        -0.0300674 , -0.0802817 , -0.0535262 ,  0.0989052 ,  0.0356557 ,\n",
       "        -0.170423  ,  0.052     , -0.0317037 ,  0.0409809 ,  0.0316994 ,\n",
       "         0.123209  , -0.0334113 ,  0.018638  , -0.0682869 , -0.103262  ,\n",
       "         0.0487244 , -0.0872005 ,  0.0222187 ,  0.0167851 , -0.0115659 ,\n",
       "         0.0435872 , -0.0102539 , -0.0080929 ,  0.123839  ,  0.0290373 ,\n",
       "        -0.106611  , -0.0402306 ,  0.130107  ,  0.049695  , -0.0533811 ,\n",
       "         0.0382213 , -0.0161471 , -0.0145961 , -0.134773  ,  0.00497049,\n",
       "        -0.0465312 , -0.134493  , -0.0337239 ,  0.0264446 ,  0.0396196 ,\n",
       "        -0.0369539 , -0.030764  ,  0.0156583 ,  0.0837196 ,  0.0425554 ,\n",
       "         0.0781432 , -0.0137224 , -0.126679  ,  0.0223628 ,  0.00073405,\n",
       "        -0.0578896 , -0.0650061 , -0.0938807 ,  0.0639242 ,  0.098554  ,\n",
       "        -0.103743  ,  0.0103537 , -0.0303705 ,  0.0311502 ,  0.033287  ,\n",
       "         0.0248492 , -0.0539245 , -0.0914327 , -0.0064936 , -0.0358289 ,\n",
       "         0.0876889 ,  0.0103675 , -0.036118  , -0.00805633,  0.00622018,\n",
       "         0.0584753 , -0.00209006,  0.0444164 ,  0.0114529 , -0.00076925,\n",
       "        -0.00021932,  0.0145257 ,  0.0398693 ,  0.0228918 ,  0.0262819 ,\n",
       "         0.00346863,  0.0301739 , -0.0421571 ,  0.00913725,  0.029883  ,\n",
       "         0.0490262 ,  0.0254422 , -0.137204  ,  0.0251723 , -0.0342355 ,\n",
       "        -0.12476   , -0.0847641 , -0.00615219, -0.0313119 ,  0.00693453,\n",
       "         0.0421954 , -0.0459513 , -0.0218726 ,  0.0107243 , -0.0536707 ,\n",
       "         0.00755717,  0.0235506 ,  0.0299614 ,  0.0114588 ,  0.0290584 ,\n",
       "        -0.0248488 , -0.0276563 ,  0.0396026 ,  0.0581892 , -0.088952  ,\n",
       "         0.0239154 ,  0.0350618 , -0.0199812 ,  0.0510433 , -0.0699488 ,\n",
       "        -0.0057464 , -0.0381105 , -0.0695138 , -0.00149769,  0.0505493 ,\n",
       "        -0.0167692 ,  0.050989  ,  0.0461348 , -0.00064027,  0.00910974,\n",
       "        -0.0185248 , -0.0104393 ,  0.0772929 ,  0.044558  ,  0.105982  ,\n",
       "        -0.105275  , -0.0124132 ,  0.00745753, -0.020058  ,  0.0512259 ]),\n",
       " array([-1.38401e-01, -3.49725e-02, -1.79829e-02,  1.06555e-01,\n",
       "         2.16203e-02,  4.83644e-02, -3.91479e-02, -9.17431e-02,\n",
       "         7.77831e-02,  8.05893e-03, -2.61265e-03,  5.99328e-02,\n",
       "        -3.38428e-02,  4.29425e-03,  2.16573e-02, -6.46598e-02,\n",
       "        -1.17642e-01,  4.00470e-02,  1.12631e-03,  5.58282e-02,\n",
       "        -5.71611e-02,  6.01605e-02, -1.57280e-02,  4.60771e-02,\n",
       "         3.03237e-02,  8.37908e-02, -7.05603e-02,  4.21712e-02,\n",
       "         6.32379e-02,  5.43266e-02, -3.65059e-02,  1.22208e-01,\n",
       "        -3.88380e-02,  1.00046e-01, -8.18795e-03, -1.42690e-03,\n",
       "         2.67140e-02, -1.48132e-01, -6.55488e-02, -2.33711e-02,\n",
       "        -1.05101e-03,  8.07843e-03, -3.25292e-02,  1.28455e-02,\n",
       "        -6.38713e-02,  1.07433e-01,  5.25635e-02,  1.10296e-02,\n",
       "         4.06361e-02, -7.60709e-02, -2.42941e-02, -1.15135e-02,\n",
       "        -3.01740e-02, -1.60451e-02, -8.77717e-02, -2.45798e-02,\n",
       "        -3.85738e-02,  6.51620e-04, -1.78967e-02,  2.60523e-02,\n",
       "        -8.05665e-02, -4.75664e-02,  1.16986e-01, -6.70405e-02,\n",
       "         8.47417e-03,  2.81616e-03, -1.06963e-01,  5.71161e-02,\n",
       "        -1.72764e-02,  3.89281e-02, -6.35250e-02,  9.97100e-02,\n",
       "         2.57751e-02, -5.58730e-02, -5.66664e-02,  1.79359e-02,\n",
       "         1.23254e-01,  6.10760e-02, -5.55536e-02, -1.21157e-01,\n",
       "        -3.38795e-03, -2.85346e-03, -1.04927e-01,  1.40285e-03,\n",
       "        -5.37046e-02,  7.65522e-02, -5.84358e-02,  7.24672e-02,\n",
       "        -9.98502e-03, -5.99335e-02, -2.75294e-02,  7.07802e-02,\n",
       "         1.15862e-01, -8.48085e-02,  1.89868e-02, -1.32759e-01,\n",
       "         7.71784e-02, -2.74219e-02, -6.21388e-02,  1.45646e-03,\n",
       "        -8.20377e-03, -1.97848e-02,  4.55555e-02, -2.26251e-02,\n",
       "        -3.75401e-02, -4.91171e-02, -8.34405e-02, -2.94687e-02,\n",
       "        -7.19287e-02,  2.14147e-02, -8.65576e-02, -1.11126e-02,\n",
       "        -1.67500e-02,  6.55187e-02, -2.23159e-03, -3.94578e-02,\n",
       "         1.25354e-01,  1.51372e-02,  8.07212e-02,  3.91011e-02,\n",
       "         3.06152e-02,  5.76995e-02,  3.49856e-02,  1.63093e-02,\n",
       "         7.94489e-02, -2.37640e-03,  7.52647e-02, -7.83822e-03,\n",
       "        -3.01713e-03,  6.18395e-04,  2.17112e-02,  7.88708e-02,\n",
       "        -8.14344e-02,  1.88081e-02, -3.01143e-02, -3.20129e-02,\n",
       "        -8.77665e-02,  1.31570e-01,  4.86939e-02,  9.88983e-02,\n",
       "         1.35831e-02,  5.70134e-02,  1.51445e-02, -3.17590e-02,\n",
       "         1.83197e-02,  4.43272e-02, -1.49029e-02, -4.98971e-02,\n",
       "         6.05339e-02,  3.87830e-03, -1.60125e-02, -5.19252e-02,\n",
       "        -9.42536e-03,  1.62954e-02, -2.29100e-03,  2.88510e-02,\n",
       "         1.73504e-02, -6.93498e-02,  1.24975e-01, -5.45481e-02,\n",
       "        -1.07167e-01,  2.57290e-02, -1.16445e-01,  2.69054e-03,\n",
       "        -7.03087e-02,  1.15395e-04,  3.03411e-02,  4.73342e-02,\n",
       "         7.41218e-02, -3.03750e-02,  2.44999e-02, -6.88175e-02,\n",
       "        -5.73133e-02,  1.88000e-02, -7.12961e-02,  1.28005e-01,\n",
       "         2.30459e-02,  5.62099e-02, -8.81646e-02, -2.81321e-02,\n",
       "         8.73014e-02, -5.50862e-02, -1.14528e-02,  1.82729e-02,\n",
       "         1.36556e-03,  4.98671e-02,  3.55486e-02, -5.47219e-02,\n",
       "         3.20782e-02, -2.55533e-02, -2.09170e-02, -1.80724e-02,\n",
       "         5.28115e-02,  1.00122e-01, -6.83967e-02, -1.77205e-02,\n",
       "        -3.36542e-02, -1.03260e-02, -7.59829e-02, -2.64755e-02,\n",
       "         1.01207e-01, -2.90420e-02,  2.34978e-02,  1.84008e-03,\n",
       "         7.01234e-03,  2.31113e-02, -7.76982e-02,  3.29808e-02,\n",
       "         1.13240e-01,  3.35799e-02,  8.17686e-02,  1.22691e-03,\n",
       "         6.88394e-02, -2.41198e-02,  5.70566e-02,  7.55861e-03,\n",
       "         9.21441e-03, -1.05207e-01,  8.02267e-03, -3.56471e-02,\n",
       "        -1.56113e-02,  1.23348e-02, -5.01502e-02,  1.01279e-01,\n",
       "         3.70982e-02,  6.19354e-02,  2.80419e-03, -3.31456e-02,\n",
       "        -5.28384e-02, -3.40819e-02,  8.41586e-03,  8.02846e-02,\n",
       "         4.72315e-02, -5.65321e-03,  6.89136e-02,  1.00104e-01,\n",
       "         1.08364e-01, -1.41834e-02,  5.38268e-02, -1.03118e-02,\n",
       "        -2.31323e-02,  3.17024e-03,  1.01410e-02, -3.77518e-02,\n",
       "         2.70828e-02, -9.39987e-02,  8.57344e-02, -2.16949e-02,\n",
       "        -1.40832e-02,  1.18020e-02, -4.79588e-02, -6.03584e-02,\n",
       "        -1.51498e-02, -5.63783e-02,  8.63097e-03,  2.11474e-02,\n",
       "        -8.00551e-02, -1.89361e-02,  6.14204e-02, -1.43016e-02,\n",
       "        -6.79763e-03, -2.71017e-02,  7.91944e-02, -7.94941e-02,\n",
       "        -4.47458e-02,  6.30825e-03,  2.65464e-02, -5.93376e-02,\n",
       "        -1.11944e-01, -2.80747e-02, -4.29076e-02, -7.79945e-02,\n",
       "         1.30460e-01,  1.12525e-01, -8.35783e-03, -1.07949e-01,\n",
       "        -1.04140e-01,  9.19231e-02,  8.32868e-02, -8.82658e-03,\n",
       "         3.13452e-02,  4.00920e-02, -2.46295e-02,  2.98109e-02,\n",
       "         5.38805e-02,  5.67856e-02, -4.64067e-02, -5.19228e-02,\n",
       "        -1.84374e-02,  7.02040e-02,  9.28007e-03, -4.37193e-02,\n",
       "         5.99571e-02, -3.54604e-02,  3.43678e-02, -5.20849e-02,\n",
       "         6.08760e-02, -1.95428e-02, -1.82197e-02,  1.18783e-02]),\n",
       " array([-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000]),\n",
       " array([ 5.93703e-02, -8.23614e-03,  1.25724e-02,  1.04206e-02,\n",
       "        -1.06029e-01,  3.31596e-02,  3.92384e-02, -7.25999e-02,\n",
       "         4.18946e-02,  1.12320e-02,  1.18884e-01,  4.77529e-02,\n",
       "         9.99194e-02, -4.57685e-02, -4.29797e-02, -3.03740e-02,\n",
       "        -3.02159e-02, -4.99049e-02,  3.21392e-02,  7.20440e-02,\n",
       "        -3.14767e-02,  4.65233e-02, -8.85024e-02,  2.39733e-03,\n",
       "        -9.50015e-02, -8.39402e-02,  3.48846e-02, -3.01440e-02,\n",
       "         6.87039e-02,  3.53690e-02, -7.65971e-02,  2.60387e-02,\n",
       "        -4.66535e-02,  8.15324e-02,  1.19116e-02, -9.22773e-02,\n",
       "        -5.61304e-02,  5.20656e-02,  4.33121e-02, -3.37296e-02,\n",
       "         8.07516e-02, -2.45031e-02, -6.29561e-02,  2.56891e-02,\n",
       "         3.34454e-02, -3.06222e-02, -3.17929e-02, -2.79233e-02,\n",
       "         1.73655e-02,  2.19516e-02, -3.87564e-02, -3.50658e-02,\n",
       "        -2.64751e-02,  3.12516e-02, -9.49532e-02,  5.31793e-03,\n",
       "         5.47126e-03,  1.40046e-01, -2.88941e-02,  4.86202e-02,\n",
       "         3.16100e-02, -5.37357e-02,  1.19796e-01, -1.04224e-01,\n",
       "        -1.48216e-02, -3.85903e-02, -4.58301e-02,  3.98419e-02,\n",
       "        -5.44116e-02,  5.28281e-02, -3.71492e-02, -4.16987e-02,\n",
       "        -3.05256e-02, -7.15566e-02, -1.01811e-02, -9.85939e-03,\n",
       "         9.58943e-02,  5.80387e-02, -6.22956e-02, -7.98401e-02,\n",
       "        -6.75864e-02,  3.43650e-02, -9.98982e-03,  3.21380e-02,\n",
       "        -7.34427e-02, -9.60905e-02, -2.13422e-02, -5.65326e-03,\n",
       "        -6.09756e-02, -6.56718e-02, -5.56507e-02, -1.63566e-03,\n",
       "         1.32416e-01, -1.17633e-01,  4.88639e-02, -1.85981e-02,\n",
       "         1.16791e-02,  7.90807e-02, -3.86718e-02, -4.31223e-02,\n",
       "        -2.77305e-02, -7.69208e-02,  1.02612e-01,  2.70612e-02,\n",
       "        -9.48461e-02,  2.56878e-02, -4.35042e-02,  7.98789e-02,\n",
       "        -8.78595e-04,  5.83333e-02,  3.02717e-02,  4.03076e-02,\n",
       "        -9.42490e-02, -1.11875e-01, -1.97074e-02, -1.43211e-02,\n",
       "         6.76037e-02,  2.11212e-02,  6.47414e-02,  5.39242e-02,\n",
       "         1.60103e-01, -9.92821e-03, -1.16975e-01,  1.02688e-01,\n",
       "         4.22544e-03, -8.76037e-02,  7.13194e-02,  8.37858e-03,\n",
       "         1.73126e-02,  1.28038e-02, -2.11256e-02, -1.77963e-02,\n",
       "         2.06081e-03, -5.12115e-02, -1.15467e-01,  4.17123e-02,\n",
       "        -6.16765e-02,  4.09972e-02,  3.63565e-02,  3.73364e-02,\n",
       "        -2.64921e-02, -4.13151e-04,  2.80382e-02, -1.08209e-02,\n",
       "         6.81437e-02,  4.41157e-02,  7.40287e-02, -1.18755e-02,\n",
       "         4.99462e-03,  4.44295e-02,  6.82108e-03, -7.88854e-02,\n",
       "        -6.58730e-02,  2.17203e-02, -6.50937e-02, -7.00934e-02,\n",
       "         6.88244e-02, -3.65770e-02,  2.92733e-02, -1.15578e-02,\n",
       "        -1.15738e-01,  1.66322e-01, -1.10888e-01,  7.22851e-02,\n",
       "         1.17418e-01,  3.17706e-02, -5.27339e-02, -4.66545e-02,\n",
       "         5.51681e-02, -6.28608e-02, -6.76695e-02,  1.46766e-02,\n",
       "        -5.42282e-02, -4.42398e-02, -3.55522e-02,  4.68148e-02,\n",
       "         3.64113e-02,  9.78591e-02, -2.60077e-02, -7.68734e-03,\n",
       "         1.10006e-02, -7.33826e-04,  1.80670e-02,  2.45586e-02,\n",
       "        -5.75760e-02,  8.16615e-02,  3.27911e-03,  3.78793e-02,\n",
       "        -3.39295e-02, -5.49992e-02, -1.18500e-02, -4.18820e-02,\n",
       "         2.58741e-02,  6.36598e-02, -3.29093e-02, -5.51456e-02,\n",
       "         4.79695e-02,  2.01635e-02, -6.65540e-02, -1.79167e-01,\n",
       "         3.92647e-02,  4.65685e-02,  2.77729e-03,  1.16757e-01,\n",
       "         9.96997e-03, -4.10601e-02, -5.34282e-02,  9.96497e-02,\n",
       "         5.99499e-02,  6.91056e-02,  7.97024e-02, -3.42076e-02,\n",
       "         3.80957e-02, -1.65890e-02,  2.34134e-02, -1.37438e-02,\n",
       "        -2.77555e-02, -5.57454e-02, -1.08323e-01, -3.53732e-03,\n",
       "         2.50567e-02, -4.28714e-02, -4.50561e-02,  4.70258e-02,\n",
       "        -5.48192e-02,  3.73012e-02, -1.16715e-01, -3.15441e-02,\n",
       "         2.70062e-02,  1.78295e-02,  6.38043e-02,  3.81724e-02,\n",
       "        -6.03035e-02,  1.46881e-02,  3.27101e-03, -2.41275e-02,\n",
       "         3.46776e-02,  1.79342e-03, -1.50441e-03, -9.56516e-03,\n",
       "        -2.77920e-02, -3.89625e-03,  7.51280e-02,  4.72732e-02,\n",
       "         7.97865e-02,  4.71279e-02,  3.23393e-02,  1.69546e-02,\n",
       "        -2.48567e-04,  8.26828e-02,  3.69235e-02,  1.60436e-02,\n",
       "         1.23256e-02, -2.99948e-02, -1.66883e-01, -2.69289e-02,\n",
       "        -1.22087e-01, -1.95556e-02,  2.65346e-02,  6.88055e-02,\n",
       "         8.38076e-02,  3.13109e-02,  2.01557e-02, -1.70589e-02,\n",
       "         1.44787e-03, -2.47592e-02, -2.15433e-02, -3.43564e-02,\n",
       "        -7.20099e-05,  2.25618e-02, -4.10453e-02,  5.60966e-02,\n",
       "         1.73715e-02,  2.44119e-03, -7.35663e-02, -1.05415e-01,\n",
       "         7.41295e-02,  3.05693e-02,  3.43922e-03,  2.51228e-02,\n",
       "         3.18108e-03,  3.66205e-02,  9.14709e-03,  6.51331e-03,\n",
       "         6.48089e-02,  1.43353e-02, -2.35723e-02,  5.49330e-02,\n",
       "        -8.70140e-02, -1.33022e-02,  1.30418e-02, -1.62589e-01,\n",
       "         2.41024e-02,  5.34708e-02,  1.09282e-02,  1.76320e-02,\n",
       "        -8.34898e-03,  2.16667e-02, -8.19967e-02,  4.30980e-02]),\n",
       " array([-6.58524e-02,  1.53813e-02,  4.93777e-02,  4.01064e-03,\n",
       "         3.57711e-02, -7.43908e-03,  5.41863e-02,  5.72879e-02,\n",
       "         1.27381e-01,  6.10134e-02, -2.60044e-03,  6.46535e-02,\n",
       "        -2.98816e-02, -1.39900e-02,  1.11848e-01, -2.92377e-02,\n",
       "        -1.09217e-01, -2.61459e-02,  5.44800e-02,  9.41134e-02,\n",
       "        -1.65059e-02, -7.91122e-02, -1.17962e-01,  1.25429e-03,\n",
       "         1.09509e-02, -2.63540e-02,  2.90805e-02,  4.41979e-03,\n",
       "        -8.83295e-02,  9.67636e-02, -5.37199e-03,  8.97983e-02,\n",
       "         3.19110e-02,  2.91998e-02, -1.53218e-02, -4.88620e-02,\n",
       "        -4.45973e-02,  2.25520e-02,  3.93341e-02, -5.72057e-03,\n",
       "        -4.02739e-02,  2.54439e-02,  2.86473e-02,  1.59795e-03,\n",
       "        -4.63003e-02, -1.30082e-01,  1.77142e-02, -1.19244e-01,\n",
       "         2.04307e-02, -3.09300e-02, -6.02926e-02, -8.06901e-02,\n",
       "        -2.53716e-02, -6.17156e-02,  1.94795e-02,  7.24508e-02,\n",
       "         2.12538e-02,  5.39977e-02, -1.85470e-02,  1.95114e-02,\n",
       "        -3.00375e-02,  3.97912e-02,  3.21027e-02, -3.03793e-02,\n",
       "        -1.08634e-02,  2.89329e-02, -5.03952e-02,  4.46620e-02,\n",
       "         1.88176e-02,  1.30846e-03, -6.62500e-02, -4.03829e-02,\n",
       "         5.93835e-03, -6.86668e-02,  4.25248e-02, -6.51875e-02,\n",
       "        -3.70125e-02,  7.76523e-02, -6.35015e-02, -2.53663e-02,\n",
       "         2.08148e-03,  7.30056e-03, -8.10311e-02, -7.28222e-03,\n",
       "        -1.14444e-01,  2.02321e-02, -6.57281e-04,  3.01258e-02,\n",
       "         1.45890e-02, -5.73343e-02, -3.25221e-02, -4.88654e-02,\n",
       "        -5.62110e-02,  3.26838e-02,  9.16679e-02,  4.83194e-02,\n",
       "        -3.07636e-03,  6.80332e-02, -3.71926e-03,  1.80604e-02,\n",
       "        -3.73470e-02, -1.17835e-02, -7.36875e-02,  6.78779e-02,\n",
       "        -1.66957e-02, -5.28390e-02,  1.11879e-02,  5.95503e-02,\n",
       "        -5.24326e-02, -7.82784e-02, -1.34331e-02, -4.60277e-02,\n",
       "         1.45233e-02,  6.43213e-02, -1.06597e-02, -3.02445e-02,\n",
       "         9.05408e-02,  3.60395e-02, -1.34660e-02, -3.39236e-02,\n",
       "         1.54968e-02, -1.19918e-02, -1.01618e-01,  7.94099e-03,\n",
       "         6.29813e-02, -4.63004e-02,  3.18154e-02, -2.24549e-03,\n",
       "        -2.59972e-02, -3.75128e-02,  3.71426e-02,  7.75376e-02,\n",
       "        -3.47917e-02,  6.05965e-02, -3.88998e-03, -2.06077e-03,\n",
       "         4.20027e-02, -9.01460e-02, -5.97852e-02,  1.58564e-02,\n",
       "        -1.24877e-04,  6.55848e-02,  4.13325e-02, -3.41954e-02,\n",
       "        -8.82335e-02,  1.25589e-01, -3.40174e-02,  1.84242e-02,\n",
       "        -5.43518e-02,  3.82107e-02,  3.59829e-02, -1.38279e-01,\n",
       "        -4.75637e-02, -5.62532e-02,  4.73959e-03,  1.42281e-02,\n",
       "        -6.61428e-02,  1.16011e-01,  4.11368e-02,  1.86731e-02,\n",
       "         6.31601e-02, -3.82883e-02, -9.04752e-02, -2.09895e-02,\n",
       "         1.03757e-01,  4.23062e-02, -3.54333e-02, -6.65027e-02,\n",
       "         1.46539e-01, -4.72137e-02, -7.56515e-02, -1.06198e-01,\n",
       "        -6.95613e-02, -8.14862e-02,  5.21739e-02,  2.10216e-02,\n",
       "         1.33974e-01, -1.01227e-01, -6.94958e-03,  2.95684e-02,\n",
       "        -6.08785e-02, -4.10460e-02,  1.15561e-02, -5.44761e-02,\n",
       "        -4.93920e-03,  6.03382e-02, -5.57209e-02, -6.08626e-02,\n",
       "         9.61827e-02,  1.01242e-02,  7.91229e-02, -1.51438e-01,\n",
       "         7.43894e-02,  1.32897e-01, -5.79546e-02,  1.50488e-02,\n",
       "        -4.25154e-02,  6.84368e-02, -7.47262e-02, -2.13636e-02,\n",
       "         2.96055e-03, -6.12353e-02, -6.93034e-02,  1.44636e-01,\n",
       "         1.73144e-01, -4.83212e-02, -9.68876e-02,  2.69526e-02,\n",
       "         6.76415e-03,  7.77895e-02, -1.63984e-02,  2.43230e-02,\n",
       "         4.86616e-02, -7.44697e-02,  6.97447e-02,  1.45932e-02,\n",
       "         1.45663e-02, -3.25231e-02, -5.70040e-02, -9.64290e-02,\n",
       "        -4.16715e-02, -5.71289e-02,  5.66647e-03, -1.84126e-03,\n",
       "        -8.21699e-03,  3.32154e-02, -1.41186e-01,  8.67102e-02,\n",
       "        -1.26673e-02, -3.71795e-03,  3.32796e-02,  6.58239e-02,\n",
       "         2.76419e-02, -6.37541e-02, -1.42831e-02, -1.13985e-01,\n",
       "         3.27004e-02, -5.79284e-02, -6.90625e-03,  6.83557e-02,\n",
       "        -4.22837e-02, -2.74054e-02,  5.58163e-02, -4.62062e-02,\n",
       "         1.32540e-02,  4.49609e-02,  2.54566e-02,  4.52685e-02,\n",
       "        -1.04010e-04, -1.72727e-02,  1.20535e-01,  1.44341e-02,\n",
       "        -5.33656e-02, -7.68837e-02,  6.80652e-02, -3.85329e-02,\n",
       "         6.58212e-03, -9.71548e-02, -1.24147e-02,  3.18355e-02,\n",
       "         7.38530e-02,  6.03520e-02,  7.15152e-03, -6.52817e-02,\n",
       "         2.44485e-02, -3.80925e-02, -7.01802e-02,  1.56847e-02,\n",
       "         3.66577e-03, -5.84594e-02, -1.00418e-01, -3.39790e-02,\n",
       "         5.43776e-02, -1.84245e-02, -3.97752e-02, -5.31610e-02,\n",
       "         6.78679e-02,  7.59650e-04, -2.82986e-02, -2.71328e-02,\n",
       "        -1.28834e-02, -5.59351e-02,  9.81378e-03,  1.56126e-02,\n",
       "         1.02100e-01,  2.57261e-02, -1.06289e-02,  2.13540e-02,\n",
       "        -1.02686e-01, -1.07982e-02,  9.42563e-02, -2.70489e-02,\n",
       "         5.83348e-02,  3.83247e-02,  4.24728e-02, -1.76299e-02,\n",
       "         3.62053e-02,  3.08594e-02, -9.02432e-02, -3.91097e-02]),\n",
       " array([-0.0533268 , -0.00345447, -0.082572  ,  0.042806  , -0.0970861 ,\n",
       "         0.0314473 , -0.0602359 , -0.0157155 ,  0.0339033 , -0.0118346 ,\n",
       "        -0.0778733 , -0.0632568 , -0.00724983,  0.0199682 , -0.0178702 ,\n",
       "         0.00096184, -0.0613631 ,  0.0830507 , -0.0736416 ,  0.0428419 ,\n",
       "        -0.0666812 ,  0.0837438 , -0.0522706 ,  0.0166727 ,  0.0490998 ,\n",
       "         0.0479045 ,  0.0434454 , -0.0110503 , -0.0535237 , -0.0864783 ,\n",
       "         0.0633428 ,  0.0454654 ,  0.0372449 ,  0.0890384 ,  0.0468898 ,\n",
       "        -0.100985  ,  0.0300823 ,  0.0259244 , -0.0102534 , -0.0374292 ,\n",
       "         0.00067378, -0.0663084 , -0.00421074,  0.0151584 ,  0.0003506 ,\n",
       "         0.0953159 ,  0.0162991 , -0.0199858 ,  0.0468423 , -0.0339123 ,\n",
       "         0.00118608, -0.0793005 ,  0.0224375 , -0.0273839 , -0.0503839 ,\n",
       "        -0.00426385, -0.0395066 ,  0.0366475 , -0.168432  ,  0.0739138 ,\n",
       "        -0.0950452 , -0.00722213,  0.108241  , -0.0329192 ,  0.00683865,\n",
       "         0.0412628 , -0.0604221 ,  0.0753908 ,  0.0414082 ,  0.0883008 ,\n",
       "        -0.0483115 ,  0.00560675,  0.0342126 , -0.0933323 , -0.110791  ,\n",
       "        -0.00268315,  0.100229  ,  0.0951909 ,  0.041924  , -0.0314029 ,\n",
       "         0.0408502 , -0.00020725,  0.0768613 ,  0.0916375 , -0.0162487 ,\n",
       "         0.017431  ,  0.0209177 ,  0.0188832 , -0.0637623 , -0.0339288 ,\n",
       "        -0.088159  , -0.104869  ,  0.0610832 , -0.0731674 ,  0.0298454 ,\n",
       "         0.0497183 ,  0.120213  ,  0.00315876, -0.0386265 , -0.0743848 ,\n",
       "         0.0208446 , -0.0445494 ,  0.00099523, -0.0194368 ,  0.00259078,\n",
       "        -0.111434  , -0.00137972, -0.0908949 , -0.0419054 ,  0.044773  ,\n",
       "         0.0155264 ,  0.0968887 , -0.0945272 , -0.0269124 ,  0.0693801 ,\n",
       "        -0.0116661 ,  0.0955711 ,  0.0519359 ,  0.0843393 , -0.00795298,\n",
       "         0.054226  ,  0.0504909 , -0.0233599 ,  0.108223  ,  0.0485484 ,\n",
       "        -0.0402773 ,  0.0477049 ,  0.0960958 ,  0.043409  ,  0.0456268 ,\n",
       "         0.0106859 ,  0.0138188 , -0.00730384, -0.00123822,  0.0386038 ,\n",
       "        -0.0008644 ,  0.0461404 , -0.035907  , -0.0262354 , -0.0766806 ,\n",
       "         0.0647048 ,  0.00768905,  0.00994188,  0.0686436 ,  0.103746  ,\n",
       "        -0.00070749, -0.112333  , -0.0213265 , -0.00760648,  0.0574117 ,\n",
       "        -0.0141368 , -0.0929253 , -0.0644768 ,  0.04584   , -0.0800765 ,\n",
       "         0.0105837 ,  0.0856598 , -0.0115302 ,  0.0670805 ,  0.0131424 ,\n",
       "        -0.0702633 ,  0.0879842 , -0.0667501 ,  0.0495476 , -0.00944896,\n",
       "         0.0669107 , -0.0639616 , -0.0157883 ,  0.0616635 , -0.0145885 ,\n",
       "         0.029268  , -0.0257023 , -0.065909  , -0.0153987 , -0.0756775 ,\n",
       "         0.0178598 ,  0.0609885 ,  0.00868863,  0.02965   ,  0.0175705 ,\n",
       "        -0.0126735 , -0.0804289 ,  0.0398005 , -0.0433069 , -0.00464806,\n",
       "         0.00760722,  0.0307077 , -0.0347536 , -0.0164401 , -0.0771877 ,\n",
       "         0.0306113 , -0.0497656 ,  0.0131002 , -0.0192615 , -0.0679275 ,\n",
       "        -0.100436  ,  0.0199616 , -0.0641346 , -0.108404  , -0.0787347 ,\n",
       "         0.0341193 , -0.0327651 ,  0.00732632,  0.00483387,  0.0117669 ,\n",
       "        -0.0116555 , -0.129131  , -0.021274  ,  0.0410331 ,  0.0360452 ,\n",
       "         0.0447931 , -0.0661439 ,  0.107774  , -0.044286  ,  0.0507782 ,\n",
       "        -0.0426072 , -0.0541181 , -0.0906119 , -0.0572153 , -0.0338911 ,\n",
       "        -0.0139626 , -0.0120378 , -0.00488191, -0.0204145 ,  0.0967765 ,\n",
       "         0.066173  , -0.152179  ,  0.0538857 , -0.0218023 ,  0.00256605,\n",
       "         0.00920116,  0.0611846 , -0.0348637 , -0.00480338, -0.0482157 ,\n",
       "         0.0675962 ,  0.0646449 ,  0.0003809 ,  0.0078116 , -0.0432207 ,\n",
       "         0.0732794 ,  0.0546087 ,  0.0907056 , -0.0847681 ,  0.00234071,\n",
       "         0.0624548 ,  0.0453256 ,  0.047969  , -0.0545292 ,  0.0917515 ,\n",
       "        -0.0325946 , -0.0626759 , -0.135257  , -0.0964277 ,  0.0192728 ,\n",
       "        -0.0202697 ,  0.0371421 , -0.119398  ,  0.0267201 ,  0.0659734 ,\n",
       "         0.0761469 ,  0.0138588 ,  0.00255929, -0.0297569 , -0.0104742 ,\n",
       "        -0.0123972 , -0.0214731 ,  0.0767804 , -0.0758669 , -0.0200847 ,\n",
       "        -0.0427147 , -0.0160727 ,  0.153344  ,  0.111845  , -0.0105519 ,\n",
       "        -0.0383774 , -0.0515365 ,  0.0469161 ,  0.0121498 ,  0.049865  ,\n",
       "         0.0121616 ,  0.0333055 ,  0.0365909 ,  0.0372549 ,  0.0779886 ,\n",
       "         0.0624382 ,  0.0109423 ,  0.108182  , -0.127219  ,  0.0541884 ,\n",
       "         0.0234525 , -0.0388919 ,  0.0401184 ,  0.0521072 ,  0.0526293 ,\n",
       "        -0.0696561 , -0.00192079, -0.0100571 , -0.0798033 ,  0.0523781 ]),\n",
       " array([ 2.90578e-02, -3.71877e-02, -1.00636e-02,  2.38376e-02,\n",
       "         1.87113e-02,  7.51986e-04, -1.93272e-02, -5.25519e-02,\n",
       "         8.09585e-02,  1.00087e-02,  7.63572e-02, -5.70769e-02,\n",
       "        -4.27405e-03, -8.60639e-02,  8.88413e-03, -8.72011e-02,\n",
       "        -6.29341e-02, -3.32256e-02,  4.38589e-02,  1.22085e-01,\n",
       "        -9.08058e-02,  5.21355e-02, -7.20814e-02, -5.32411e-02,\n",
       "        -8.33182e-02, -5.88468e-03, -1.56866e-02, -6.49917e-03,\n",
       "         4.77774e-02,  4.39401e-02, -6.64511e-02,  1.05397e-01,\n",
       "        -6.49558e-02,  1.16866e-01,  1.62375e-02, -6.81262e-02,\n",
       "         8.36596e-03, -1.10370e-01,  6.85330e-03, -1.76864e-02,\n",
       "         1.29833e-01, -3.25216e-02, -6.30600e-02,  6.88370e-02,\n",
       "         1.41367e-02, -1.00482e-02,  3.73938e-02, -4.26741e-02,\n",
       "         2.03196e-02, -1.71579e-02,  5.16472e-02, -4.08775e-03,\n",
       "        -3.14539e-03,  5.97006e-03, -1.15664e-01,  2.93780e-02,\n",
       "        -2.15250e-02,  1.91025e-02,  3.36851e-03, -3.88444e-02,\n",
       "        -4.85260e-02, -6.48789e-02,  1.19158e-01, -6.07384e-02,\n",
       "         3.22967e-02, -1.10984e-01, -1.03291e-01,  5.12771e-02,\n",
       "         8.33329e-03,  6.42771e-02, -1.13933e-01,  5.41939e-02,\n",
       "         1.04422e-02, -8.83452e-02, -1.01103e-02, -6.50584e-02,\n",
       "         4.09775e-02,  5.86114e-02,  6.78329e-03, -5.08006e-02,\n",
       "        -1.59087e-04,  3.15761e-02, -1.03151e-01,  1.43929e-03,\n",
       "        -4.50276e-02, -3.48440e-02,  2.77389e-03,  1.10471e-01,\n",
       "        -4.73790e-02, -6.12059e-02, -1.26967e-02,  8.49038e-02,\n",
       "         9.35189e-02, -9.21154e-02, -1.68719e-02, -6.37996e-02,\n",
       "         4.88795e-02, -1.79994e-02, -8.17550e-02, -2.31563e-02,\n",
       "        -4.72326e-02, -5.91928e-02,  1.22489e-02, -7.36964e-02,\n",
       "        -1.11346e-01,  4.51661e-02, -6.92804e-02,  6.18542e-02,\n",
       "         5.00187e-02, -9.30989e-04, -8.10465e-02,  2.20529e-02,\n",
       "        -7.30808e-02, -2.06147e-02, -1.53985e-02, -8.77072e-03,\n",
       "        -2.01375e-02,  1.08755e-01,  9.49031e-02,  3.98802e-02,\n",
       "         1.50238e-01,  2.89008e-02,  1.88778e-02, -1.39002e-02,\n",
       "         5.25352e-02,  2.75991e-02,  1.54442e-02,  5.96255e-02,\n",
       "         3.60518e-02,  1.75940e-03, -2.99205e-02, -2.59511e-02,\n",
       "         4.81620e-02, -1.00644e-02, -4.41018e-02,  4.41891e-02,\n",
       "        -8.61036e-02,  1.32969e-01,  3.15838e-02,  1.16022e-01,\n",
       "        -1.13256e-02,  4.08223e-03, -1.55264e-02, -1.50372e-02,\n",
       "         2.33952e-02,  1.09882e-01,  2.58535e-02, -5.57111e-02,\n",
       "        -1.33074e-02,  5.97147e-02,  3.11294e-02, -8.18496e-02,\n",
       "        -6.44818e-02,  6.81778e-02, -3.06470e-02, -5.84204e-02,\n",
       "         2.64491e-02, -3.14901e-02,  1.01446e-01, -4.24587e-02,\n",
       "        -6.78678e-02,  7.50870e-02, -5.50280e-02, -4.92631e-02,\n",
       "         1.03725e-01, -3.42693e-02, -5.97704e-02,  1.40007e-03,\n",
       "         1.02954e-01, -2.36137e-02, -6.98158e-02, -1.77950e-02,\n",
       "        -3.69539e-02,  3.66825e-02, -3.62255e-02,  1.05765e-01,\n",
       "        -2.67677e-02,  7.21816e-02, -3.59582e-02, -2.26917e-02,\n",
       "        -2.88104e-02,  1.98283e-02,  1.90662e-02,  3.34903e-02,\n",
       "        -1.01899e-03,  8.38129e-02,  1.59749e-02, -6.74627e-02,\n",
       "         6.24270e-03,  2.95358e-02, -9.39992e-02, -5.56500e-02,\n",
       "         1.19252e-01,  8.55534e-02, -1.01917e-01,  4.04430e-03,\n",
       "         5.44419e-02, -4.70187e-02, -1.45885e-02,  3.66870e-03,\n",
       "         5.71794e-02, -3.41144e-02, -1.06537e-01,  5.07060e-02,\n",
       "         1.90548e-02,  3.80621e-02, -5.60323e-02,  1.97307e-03,\n",
       "         4.61074e-02,  8.69136e-03,  1.12726e-01,  4.86538e-02,\n",
       "        -2.39701e-02, -1.09570e-02, -2.88827e-02, -8.29060e-03,\n",
       "        -1.30508e-02, -1.66165e-01,  5.15696e-02, -2.23432e-02,\n",
       "        -7.28682e-02, -3.99206e-02,  1.14530e-02,  8.80151e-02,\n",
       "         8.85503e-03, -1.13839e-02, -4.91856e-02,  1.53482e-05,\n",
       "        -2.22851e-02, -4.44230e-02,  6.19848e-02,  1.26580e-01,\n",
       "        -2.52143e-02, -5.36082e-02,  1.14899e-02,  1.02842e-01,\n",
       "         6.97793e-03, -1.09101e-01,  7.92573e-02,  8.21106e-03,\n",
       "        -1.84409e-02, -3.48225e-02,  2.58601e-02,  2.93586e-02,\n",
       "         3.77961e-02, -1.06914e-03,  1.08895e-01, -2.44081e-03,\n",
       "         3.65513e-02,  2.30092e-02,  2.01986e-02, -1.04922e-02,\n",
       "         4.20484e-03,  2.52950e-02, -1.11952e-01,  3.90231e-02,\n",
       "        -3.38163e-02, -1.63516e-05,  3.05146e-02, -1.53001e-02,\n",
       "         8.19163e-03, -7.80837e-02,  6.06908e-02, -7.41793e-02,\n",
       "        -6.37811e-03,  5.83836e-02,  3.15896e-02,  1.77698e-02,\n",
       "         2.31281e-02, -7.85207e-02, -5.37538e-02, -7.83456e-02,\n",
       "         3.59191e-02,  9.05737e-02, -6.57812e-02, -7.13433e-02,\n",
       "         5.91482e-02,  7.51633e-02,  4.63691e-02,  4.20915e-02,\n",
       "        -4.53437e-02, -1.82548e-02, -7.81608e-03,  5.59563e-02,\n",
       "         3.01324e-02, -7.35466e-03,  2.20957e-02,  5.28162e-02,\n",
       "        -5.97827e-02, -1.97592e-03, -6.87768e-02, -4.78974e-02,\n",
       "         4.05210e-02,  7.24457e-02, -2.14109e-02, -9.95300e-02,\n",
       "        -3.51098e-02,  7.13416e-02, -7.93507e-02, -5.81184e-02]),\n",
       " array([-3.59352e-02, -4.69730e-02,  8.61357e-02, -6.49040e-03,\n",
       "        -1.13226e-01,  3.26833e-02,  4.88449e-02,  9.78813e-02,\n",
       "        -6.93891e-03, -3.40787e-02, -3.94519e-02, -4.03264e-02,\n",
       "         8.46213e-03, -1.14210e-01,  2.91024e-02, -8.23556e-02,\n",
       "        -9.49788e-02, -9.27839e-02, -1.36853e-02,  8.47781e-02,\n",
       "        -1.03569e-01,  4.91830e-03, -4.55833e-02,  3.82824e-03,\n",
       "        -6.65647e-02,  2.09058e-02, -6.13355e-02, -3.11986e-02,\n",
       "        -5.61663e-02, -2.55429e-02,  5.71126e-02,  2.17365e-02,\n",
       "        -4.44543e-02,  6.97347e-02, -3.16843e-03, -3.91499e-02,\n",
       "         6.25018e-02,  6.44182e-03,  1.06665e-01,  2.44984e-02,\n",
       "        -2.21957e-02, -6.17244e-02, -1.25697e-02, -7.24199e-02,\n",
       "         2.68551e-02,  7.20399e-02, -3.82408e-02, -5.32961e-02,\n",
       "         1.13171e-02, -6.17534e-03,  7.71253e-02,  2.43050e-02,\n",
       "        -1.32790e-02,  2.20407e-02, -9.65722e-02, -7.93943e-03,\n",
       "        -6.91696e-02,  1.04564e-01, -4.38718e-02,  1.06859e-01,\n",
       "        -6.61267e-02,  2.87931e-02, -2.25437e-02,  1.42616e-02,\n",
       "        -4.47603e-02, -8.15393e-02, -7.73664e-02,  1.10883e-01,\n",
       "        -1.22806e-01, -5.29167e-02, -1.61182e-02,  5.31222e-02,\n",
       "         7.69826e-02, -1.26412e-01, -2.73141e-02,  2.38774e-02,\n",
       "         1.65224e-02,  3.99108e-02, -5.28942e-02,  2.33884e-02,\n",
       "        -3.31467e-02,  6.74310e-02,  2.18314e-02, -5.65242e-02,\n",
       "         1.73369e-02,  8.25955e-02, -6.40319e-02,  9.95575e-02,\n",
       "         4.06457e-02, -9.52060e-02,  7.70662e-03, -9.93100e-02,\n",
       "        -9.34620e-03, -8.40741e-02, -2.82780e-02, -6.22217e-02,\n",
       "        -6.49358e-02,  1.21495e-01,  3.57515e-02, -3.09587e-02,\n",
       "         2.36219e-02, -1.03451e-02,  1.01765e-02, -6.26658e-02,\n",
       "        -4.47705e-02, -1.04263e-02,  1.72162e-02,  2.52527e-02,\n",
       "         4.82608e-02, -5.68519e-02,  2.79329e-02,  4.32706e-02,\n",
       "         9.98895e-03,  2.35505e-02,  5.98159e-02, -1.32880e-02,\n",
       "        -3.42223e-02, -2.15568e-02,  1.16906e-01,  4.22616e-02,\n",
       "         7.82758e-03,  2.46323e-02,  2.49888e-03, -2.46432e-02,\n",
       "        -1.41241e-03, -1.87101e-02, -2.19730e-02,  6.18655e-03,\n",
       "         8.71908e-02, -4.08716e-02, -4.22234e-02, -1.70921e-02,\n",
       "        -9.73845e-04, -4.21655e-02, -4.29358e-02,  1.40440e-02,\n",
       "        -6.22510e-02,  6.30526e-02,  3.52145e-02,  1.25863e-01,\n",
       "         1.12859e-02, -2.84550e-04, -3.72928e-02,  1.07516e-01,\n",
       "         9.03534e-02,  1.47667e-02,  2.75390e-02, -1.48255e-02,\n",
       "         5.80907e-02,  3.00683e-02,  3.81955e-02, -1.33781e-02,\n",
       "         5.18615e-02, -8.10399e-02, -2.96970e-02, -2.06323e-02,\n",
       "         1.44020e-01,  5.07340e-02,  6.66386e-02, -4.08619e-02,\n",
       "        -9.21151e-02,  9.16492e-02, -4.28421e-02,  1.59472e-03,\n",
       "         1.57710e-01, -6.67977e-02, -4.62723e-02, -6.35247e-02,\n",
       "         1.27451e-02,  1.12253e-01, -1.01499e-01, -1.00688e-01,\n",
       "        -6.92144e-02,  3.61563e-03, -4.41065e-02,  3.19168e-02,\n",
       "         7.93852e-02,  9.14709e-02,  3.50382e-02,  1.96404e-02,\n",
       "         5.84258e-02,  3.37563e-03, -3.37459e-02,  5.06172e-02,\n",
       "        -2.05248e-02,  4.63012e-02,  3.17623e-02, -5.05099e-02,\n",
       "         1.40249e-02, -3.36116e-02,  7.02840e-02, -4.54418e-02,\n",
       "         5.60520e-02, -1.28260e-02, -2.14455e-02, -3.43323e-03,\n",
       "        -5.75568e-02,  4.72627e-02, -6.44724e-02,  6.24419e-02,\n",
       "         7.08165e-03, -2.41812e-02,  3.27317e-02,  1.51413e-01,\n",
       "         7.10768e-02, -2.92015e-02,  4.04913e-02, -3.58173e-02,\n",
       "         1.26421e-01,  3.17073e-02,  1.08955e-01, -8.66396e-03,\n",
       "         3.49088e-03,  1.99060e-02, -3.35034e-02,  7.98373e-03,\n",
       "        -4.40945e-02,  3.46514e-02, -4.73916e-02,  4.52142e-03,\n",
       "         1.01036e-01,  7.56053e-02, -1.28562e-01,  4.49505e-02,\n",
       "         5.09712e-03,  1.11667e-02,  3.47288e-02, -2.47792e-02,\n",
       "         8.66377e-02,  2.34586e-02,  5.65687e-02,  1.02019e-02,\n",
       "        -7.16407e-02,  4.61008e-02, -2.85357e-02, -4.52607e-02,\n",
       "         7.91070e-02, -1.17674e-01,  9.60037e-02, -5.66618e-02,\n",
       "         4.51063e-02, -1.68368e-02, -1.00720e-02,  4.23383e-03,\n",
       "        -4.60076e-02,  4.36701e-02, -1.01880e-01, -1.97652e-02,\n",
       "        -5.59950e-02,  1.42563e-02,  8.15689e-02, -1.76705e-02,\n",
       "         7.38732e-02, -2.79360e-02,  1.16454e-02, -1.00715e-02,\n",
       "        -7.64633e-03, -6.84145e-02,  8.22793e-02,  4.79928e-02,\n",
       "        -4.43168e-02, -2.34791e-02,  7.26342e-02, -2.52810e-02,\n",
       "        -5.60747e-02, -1.66715e-02,  1.42117e-01,  8.32168e-03,\n",
       "        -3.43802e-02,  1.04171e-02,  1.02091e-02, -8.28146e-02,\n",
       "         3.92820e-02, -2.19382e-02, -8.29657e-02, -2.21623e-02,\n",
       "         1.13224e-02,  1.08361e-01,  2.36979e-02, -4.68587e-02,\n",
       "        -3.49839e-03,  9.90447e-02, -1.65648e-02,  6.35999e-02,\n",
       "        -5.26323e-02, -5.38296e-02, -5.89478e-02, -5.40718e-02,\n",
       "        -1.48590e-03, -8.07223e-04,  2.83856e-02, -6.94396e-02,\n",
       "        -7.48986e-02,  8.29633e-02, -4.24100e-02, -5.66555e-02,\n",
       "         8.82819e-03,  8.11575e-02,  1.17657e-04, -7.25680e-03]),\n",
       " array([ 1.12826e-02, -6.71803e-02, -9.81728e-03,  2.94519e-02,\n",
       "         2.14481e-04,  2.46093e-03, -4.10060e-03, -6.80936e-02,\n",
       "         1.81481e-02,  6.36653e-02,  1.53175e-01, -8.39842e-02,\n",
       "         1.08310e-01, -4.91142e-02, -8.63641e-02, -2.52936e-02,\n",
       "        -4.63349e-02, -1.77916e-02, -1.41944e-02,  6.71455e-02,\n",
       "        -7.43263e-02, -2.64280e-04, -1.19757e-01, -3.80226e-03,\n",
       "        -8.99903e-02,  7.37435e-03,  8.60215e-02,  2.74930e-03,\n",
       "         7.72617e-02, -3.35144e-02, -2.87343e-02,  1.24651e-01,\n",
       "        -8.55462e-02,  9.22579e-02,  2.28850e-02, -4.10335e-02,\n",
       "         1.29951e-03, -8.38041e-02,  7.31206e-02, -3.09161e-03,\n",
       "         5.76818e-02, -6.31184e-02, -6.00970e-02,  5.65826e-02,\n",
       "         2.97152e-02, -8.49665e-02,  3.47891e-03, -4.20404e-02,\n",
       "         3.38751e-02, -1.08848e-02,  8.97108e-03,  6.13928e-02,\n",
       "         2.61734e-02,  2.40385e-02, -7.74596e-02, -9.67332e-03,\n",
       "        -4.81988e-02,  6.94957e-02, -2.42491e-02,  2.47999e-02,\n",
       "        -8.58575e-02, -1.44792e-01,  1.09740e-01, -6.76860e-02,\n",
       "        -2.35472e-02, -8.85851e-02, -1.04747e-01,  1.40180e-02,\n",
       "        -1.09704e-01, -3.88153e-02, -7.89062e-02, -4.34260e-03,\n",
       "        -2.64663e-02, -7.40495e-02, -3.81357e-02, -4.68287e-02,\n",
       "         6.76015e-02,  5.56545e-02,  1.84169e-02,  2.74827e-02,\n",
       "         1.38082e-02,  1.03230e-01, -1.29362e-01, -5.22507e-02,\n",
       "        -1.35895e-02, -2.43786e-02, -4.81230e-03,  5.98608e-02,\n",
       "         3.37631e-02, -9.52838e-02, -3.65026e-02,  6.35903e-02,\n",
       "         6.61430e-02, -1.52296e-01,  6.16991e-03,  1.25276e-03,\n",
       "        -4.11868e-03,  6.44327e-03,  8.55733e-03, -3.10041e-05,\n",
       "         4.59427e-02, -4.37032e-02,  5.08919e-02, -8.34513e-02,\n",
       "        -8.52562e-02, -3.20481e-02, -6.05096e-02,  6.43475e-02,\n",
       "         7.19748e-02,  5.05118e-02, -5.52893e-03,  1.82213e-02,\n",
       "        -1.27666e-01, -5.29908e-02,  2.07376e-03,  2.56974e-02,\n",
       "         3.01015e-02,  7.39649e-02,  9.31386e-02,  7.98150e-02,\n",
       "         1.59111e-01,  1.24996e-03, -5.33906e-02,  5.06108e-02,\n",
       "         1.35983e-02, -5.93580e-03,  6.12139e-02,  7.96099e-02,\n",
       "         5.90979e-02,  4.20495e-02, -1.55070e-02,  4.61889e-02,\n",
       "        -1.33500e-02,  1.37127e-02,  2.54036e-02,  2.98324e-02,\n",
       "        -1.19349e-01,  6.00508e-02,  3.61411e-02,  5.65306e-02,\n",
       "        -1.19154e-02,  5.46535e-02,  2.38315e-02, -1.72430e-03,\n",
       "         6.86681e-02,  1.10954e-01,  4.64012e-02,  5.15392e-02,\n",
       "        -3.75640e-02,  4.62412e-02,  1.73509e-02, -1.13720e-01,\n",
       "        -4.66487e-02, -5.74488e-03, -8.42043e-02, -7.45145e-02,\n",
       "         4.72527e-03,  1.46411e-02,  1.05348e-01,  2.14894e-02,\n",
       "        -1.03001e-01,  1.21251e-01, -7.07625e-02, -1.68155e-02,\n",
       "         1.43133e-01, -2.75236e-02,  1.11813e-02, -8.61996e-03,\n",
       "         2.09205e-02, -9.95727e-02, -1.13507e-01,  5.01579e-02,\n",
       "        -8.23312e-02,  5.71243e-02,  9.87622e-03,  7.80674e-02,\n",
       "         7.59771e-03,  6.08560e-02,  1.72756e-02,  2.03919e-04,\n",
       "         3.00639e-02, -2.90721e-04, -3.45062e-02,  2.11086e-02,\n",
       "        -3.72537e-02,  8.50139e-02, -2.33816e-02, -2.47121e-02,\n",
       "         1.00987e-02, -6.28812e-03,  9.01034e-03, -1.28976e-01,\n",
       "         1.01373e-01,  4.49848e-02, -4.76972e-02,  2.80739e-02,\n",
       "         4.35052e-02,  5.48644e-03, -4.07198e-02,  6.07765e-03,\n",
       "        -2.00559e-02, -4.93866e-02, -5.48143e-02,  3.80163e-02,\n",
       "         7.13368e-02, -2.87536e-02, -1.86328e-02,  4.65693e-02,\n",
       "         3.28530e-02,  4.01075e-02,  7.76635e-02,  2.41589e-02,\n",
       "         6.62901e-02, -6.18614e-02, -3.72497e-02, -2.46812e-02,\n",
       "         8.94799e-03, -1.09984e-01,  1.57612e-02,  8.33403e-03,\n",
       "         4.64920e-02, -5.60192e-02, -5.69775e-02,  3.63386e-02,\n",
       "        -4.23757e-02, -2.85256e-02, -4.83648e-02, -3.00164e-02,\n",
       "         2.47378e-02, -2.93548e-02,  3.72093e-02,  4.52082e-02,\n",
       "        -3.93663e-02, -6.29473e-02, -3.40207e-02,  1.05428e-02,\n",
       "        -4.55001e-02, -4.69981e-02,  3.39448e-02, -2.21930e-02,\n",
       "         2.11406e-02,  2.12142e-02,  4.87659e-02,  4.48334e-02,\n",
       "         3.49881e-02,  5.92408e-02,  5.28185e-02,  9.79846e-03,\n",
       "         6.33920e-02,  7.38819e-03,  6.49850e-03, -5.39702e-02,\n",
       "        -4.11062e-02, -2.17593e-02, -9.44857e-02,  3.32950e-02,\n",
       "        -3.89706e-02,  9.81810e-03,  6.08419e-02,  1.86545e-02,\n",
       "         2.81497e-02, -2.77385e-02,  2.91926e-02,  7.73555e-03,\n",
       "        -5.59897e-02,  3.57279e-02,  6.20732e-03,  8.01326e-02,\n",
       "         8.64837e-02, -1.90868e-02, -9.49661e-03,  1.07991e-02,\n",
       "        -3.68730e-03,  2.12485e-02, -9.54814e-02, -7.96646e-02,\n",
       "         6.99310e-02,  8.90966e-02,  1.26530e-02,  4.41189e-02,\n",
       "        -5.33279e-02, -3.70968e-03,  8.21138e-02,  9.37674e-02,\n",
       "         7.53638e-02,  1.49149e-02, -1.26574e-02,  4.34230e-02,\n",
       "        -5.22856e-02,  9.87166e-03,  2.92157e-03, -1.31351e-01,\n",
       "        -5.62856e-03,  6.39164e-02,  1.49503e-02, -5.54039e-02,\n",
       "        -2.50436e-03,  9.61082e-02, -6.43627e-02, -6.99482e-02]),\n",
       " array([-0.0490828 , -0.0168721 , -0.025385  , -0.118687  ,  0.0112206 ,\n",
       "         0.053588  , -0.055481  , -0.0698541 , -0.0120935 ,  0.0907487 ,\n",
       "        -0.0709488 , -0.102824  ,  0.071137  ,  0.0521411 ,  0.0237766 ,\n",
       "        -0.0341842 , -0.126237  ,  0.0542868 ,  0.033767  ,  0.0601374 ,\n",
       "        -0.11158   ,  0.0420944 ,  0.0131437 ,  0.0183089 , -0.126633  ,\n",
       "        -0.014477  , -0.0428049 , -0.0669335 , -0.0101143 , -0.00128673,\n",
       "        -0.0537769 ,  0.0788461 , -0.0200916 , -0.00304824,  0.063957  ,\n",
       "         0.051089  ,  0.0278195 ,  0.00988327,  0.00179403,  0.00167522,\n",
       "         0.0786511 , -0.064154  ,  0.0422016 ,  0.0357715 , -0.0303569 ,\n",
       "        -0.0704284 , -0.00385623, -0.0761847 ,  0.0601804 ,  0.0491443 ,\n",
       "         0.0972421 ,  0.00482098,  0.0751921 , -0.0182466 ,  0.0538067 ,\n",
       "        -0.0821133 , -0.0112411 ,  0.106572  , -0.0652656 ,  0.0959218 ,\n",
       "        -0.0737079 , -0.0708164 ,  0.137739  ,  0.0235767 , -0.0183239 ,\n",
       "        -0.00342658, -0.054036  ,  0.0535638 , -0.0638711 , -0.00462921,\n",
       "        -0.0240517 ,  0.0169062 ,  0.0679609 , -0.0284986 , -0.0341075 ,\n",
       "         0.0075048 ,  0.156319  ,  0.0208101 , -0.0427242 , -0.00291803,\n",
       "        -0.050954  ,  0.0885031 ,  0.039856  ,  0.0341939 ,  0.0342353 ,\n",
       "        -0.128595  , -0.0208328 ,  0.0495674 , -0.0133232 , -0.0704804 ,\n",
       "         0.0436094 , -0.124743  ,  0.069418  , -0.0947867 ,  0.0112108 ,\n",
       "         0.00822998, -0.0949112 ,  0.0292222 , -0.106933  , -0.064756  ,\n",
       "        -0.0273172 , -0.0432188 , -0.0423387 , -0.0201764 ,  0.00986183,\n",
       "         0.0323615 , -0.0608589 ,  0.0211865 ,  0.0797113 ,  0.0184503 ,\n",
       "         0.0298119 ,  0.00852863,  0.0830873 ,  0.0645953 ,  0.0557208 ,\n",
       "        -0.00228071,  0.0573598 ,  0.0213033 ,  0.0584503 , -0.0628897 ,\n",
       "        -0.0584582 , -0.0527724 ,  0.0887675 ,  0.00193273,  0.0548048 ,\n",
       "         0.0251866 ,  0.063333  ,  0.062713  ,  0.063923  ,  0.0644538 ,\n",
       "         0.0956314 ,  0.0373978 ,  0.110409  ,  0.102515  , -0.0443384 ,\n",
       "        -0.0382327 , -0.044623  , -0.0644882 ,  0.0570991 ,  0.103894  ,\n",
       "        -0.0622636 ,  0.0551435 , -0.0706237 , -0.0511182 , -0.00244411,\n",
       "         0.0210232 , -0.0261978 , -0.0470052 ,  0.0285924 ,  0.0553968 ,\n",
       "         0.00398055, -0.184615  , -0.0632607 , -0.0145621 , -0.101602  ,\n",
       "         0.0217896 ,  0.00208245,  0.0155596 , -0.0164153 ,  0.0131413 ,\n",
       "         0.00596461,  0.0146344 , -0.0561177 ,  0.0867968 ,  0.00795793,\n",
       "        -0.0246726 , -0.0588901 , -0.043631  ,  0.04868   ,  0.0235733 ,\n",
       "        -0.0454439 , -0.00787978, -0.0461296 , -0.0935358 , -0.0269148 ,\n",
       "        -0.018611  , -0.0106148 , -0.0424996 , -0.0109539 , -0.0969907 ,\n",
       "        -0.0472562 ,  0.0114036 ,  0.0516347 , -0.0480396 ,  0.0540569 ,\n",
       "        -0.0268684 ,  0.0367589 , -0.054083  , -0.0284181 ,  0.0329358 ,\n",
       "        -0.0150742 ,  0.00534046,  0.0848749 ,  0.0615985 , -0.0246004 ,\n",
       "        -0.0636634 ,  0.0231206 ,  0.00122665, -0.0963232 ,  0.0767428 ,\n",
       "         0.0353473 , -0.0114762 ,  0.0985734 , -0.00257251,  0.0240586 ,\n",
       "        -0.114109  ,  0.0820023 , -0.0763667 ,  0.100555  ,  0.0395573 ,\n",
       "         0.0307002 ,  0.00091349,  0.0668802 , -0.0125183 ,  0.0486657 ,\n",
       "        -0.102827  ,  0.0268668 , -0.0744355 ,  0.0182734 , -0.0352949 ,\n",
       "         0.0195498 , -0.0171749 , -0.0150492 ,  0.139391  ,  0.0591092 ,\n",
       "        -0.0570373 ,  0.0613994 , -0.0658079 ,  0.111601  , -0.0715991 ,\n",
       "         0.144047  , -0.0451896 , -0.0126485 , -0.0238938 , -0.0490584 ,\n",
       "         0.0163236 ,  0.00545631,  0.0488938 ,  0.089124  , -0.0647034 ,\n",
       "        -0.0539362 , -0.0483325 , -0.00077776, -0.00099629, -0.0815946 ,\n",
       "        -0.0293817 ,  0.0620689 , -0.0787301 , -0.0222459 , -0.0994722 ,\n",
       "        -0.0672047 ,  0.0595865 ,  0.00371957, -0.0675762 , -0.0558282 ,\n",
       "        -0.015536  , -0.0912747 , -0.0684251 ,  0.0903657 ,  0.0461391 ,\n",
       "        -0.0654319 ,  0.0321511 ,  0.00057128, -0.0317104 , -0.0133638 ,\n",
       "        -0.0019351 , -0.0315218 , -0.016206  ,  0.0218664 , -0.104179  ,\n",
       "         0.0639728 ,  0.0340964 ,  0.0360764 , -0.0209066 , -0.0643666 ,\n",
       "        -0.0864591 ,  0.0446154 ,  0.0108969 , -0.00837691,  0.00178012,\n",
       "        -0.0458194 , -0.022647  , -0.0086597 , -0.0282141 ,  0.0135631 ,\n",
       "        -0.00337915, -0.010715  ,  0.0420764 , -0.0356555 ,  0.0695648 ,\n",
       "        -0.0144391 , -0.0176607 , -0.0114049 ,  0.0134323 ,  0.0260635 ,\n",
       "        -0.0524084 ,  0.032902  ,  0.0348854 ,  0.0956005 , -0.0190175 ]),\n",
       " array([ 0.00975112,  0.119637  , -0.0942776 , -0.0464149 , -0.0405434 ,\n",
       "         0.0475084 ,  0.0341872 ,  0.0266829 , -0.0355644 ,  0.148003  ,\n",
       "         0.0681747 , -0.0877465 , -0.0283309 , -0.056195  ,  0.0114812 ,\n",
       "         0.0438521 , -0.0808381 ,  0.00349589, -0.0155833 ,  0.0698691 ,\n",
       "        -0.00705903,  0.0350561 , -0.0915204 , -0.00819792,  0.00479954,\n",
       "        -0.0177702 , -0.00994384, -0.108691  ,  0.008076  , -0.0209999 ,\n",
       "         0.00426352,  0.0702555 , -0.0877146 ,  0.0910797 , -0.0147118 ,\n",
       "        -0.11022   ,  0.0349289 , -0.0851626 ,  0.00283883,  0.0750625 ,\n",
       "         0.0730617 , -0.0312385 , -0.0256113 , -0.0315099 ,  0.0347672 ,\n",
       "         0.0652587 ,  0.0988442 ,  0.0823979 ,  0.0689653 , -0.158082  ,\n",
       "        -0.00817641, -0.0464158 ,  0.0574543 , -0.0144348 , -0.0958095 ,\n",
       "         0.02447   ,  0.0374128 , -0.0076234 , -0.0600084 ,  0.023464  ,\n",
       "         0.01985   , -0.0847562 ,  0.0872168 ,  0.00823615,  0.0127491 ,\n",
       "         0.0181383 , -0.126212  , -0.0121579 , -0.0223335 ,  0.00148263,\n",
       "        -0.0563427 ,  0.0144894 ,  0.0832793 , -0.177106  , -0.0517708 ,\n",
       "        -0.0542267 ,  0.123522  ,  0.0595698 ,  0.00219836,  0.0156276 ,\n",
       "         0.0353615 ,  0.0186483 , -0.0429712 , -0.00473874, -0.034195  ,\n",
       "         0.028294  ,  0.046897  ,  0.0644226 ,  0.106598  , -0.00026571,\n",
       "        -0.00815025,  0.00438235,  0.109577  , -0.0406536 , -0.0719481 ,\n",
       "         0.0736738 ,  0.0275263 , -0.0491297 ,  0.00337114, -0.107607  ,\n",
       "        -0.0425055 ,  0.0382756 ,  0.0650691 , -0.00754835, -0.078798  ,\n",
       "         0.00483923, -0.0186827 ,  0.0460076 ,  0.0578245 ,  0.0159246 ,\n",
       "        -0.0178582 , -0.0492316 ,  0.00614735, -0.0202196 , -0.00607911,\n",
       "        -0.007078  ,  0.0671585 ,  0.0297627 , -0.0805695 , -0.0156748 ,\n",
       "        -0.00812021,  0.0745784 ,  0.0481133 ,  0.06913   ,  0.0675901 ,\n",
       "        -0.085362  ,  0.0251587 ,  0.0119791 ,  0.0171626 ,  0.0727988 ,\n",
       "        -0.0318013 , -0.0016124 , -0.0352005 ,  0.0177587 ,  0.0282304 ,\n",
       "         0.116075  , -0.032585  , -0.0285519 , -0.0775812 ,  0.0595998 ,\n",
       "        -0.0182417 ,  0.0426937 ,  0.00515793, -0.00357626,  0.0414304 ,\n",
       "         0.0729902 ,  0.0148321 , -0.0238366 ,  0.0554372 ,  0.0469339 ,\n",
       "         0.0147837 , -0.0850903 , -0.00783743, -0.0524577 , -0.0337407 ,\n",
       "        -0.114862  , -0.0686778 , -0.0705654 ,  0.0488455 , -0.0265024 ,\n",
       "        -0.0491378 ,  0.0351447 ,  0.00272222,  0.00390732,  0.118423  ,\n",
       "        -0.0300674 , -0.0802817 , -0.0535262 ,  0.0989052 ,  0.0356557 ,\n",
       "        -0.170423  ,  0.052     , -0.0317037 ,  0.0409809 ,  0.0316994 ,\n",
       "         0.123209  , -0.0334113 ,  0.018638  , -0.0682869 , -0.103262  ,\n",
       "         0.0487244 , -0.0872005 ,  0.0222187 ,  0.0167851 , -0.0115659 ,\n",
       "         0.0435872 , -0.0102539 , -0.0080929 ,  0.123839  ,  0.0290373 ,\n",
       "        -0.106611  , -0.0402306 ,  0.130107  ,  0.049695  , -0.0533811 ,\n",
       "         0.0382213 , -0.0161471 , -0.0145961 , -0.134773  ,  0.00497049,\n",
       "        -0.0465312 , -0.134493  , -0.0337239 ,  0.0264446 ,  0.0396196 ,\n",
       "        -0.0369539 , -0.030764  ,  0.0156583 ,  0.0837196 ,  0.0425554 ,\n",
       "         0.0781432 , -0.0137224 , -0.126679  ,  0.0223628 ,  0.00073405,\n",
       "        -0.0578896 , -0.0650061 , -0.0938807 ,  0.0639242 ,  0.098554  ,\n",
       "        -0.103743  ,  0.0103537 , -0.0303705 ,  0.0311502 ,  0.033287  ,\n",
       "         0.0248492 , -0.0539245 , -0.0914327 , -0.0064936 , -0.0358289 ,\n",
       "         0.0876889 ,  0.0103675 , -0.036118  , -0.00805633,  0.00622018,\n",
       "         0.0584753 , -0.00209006,  0.0444164 ,  0.0114529 , -0.00076925,\n",
       "        -0.00021932,  0.0145257 ,  0.0398693 ,  0.0228918 ,  0.0262819 ,\n",
       "         0.00346863,  0.0301739 , -0.0421571 ,  0.00913725,  0.029883  ,\n",
       "         0.0490262 ,  0.0254422 , -0.137204  ,  0.0251723 , -0.0342355 ,\n",
       "        -0.12476   , -0.0847641 , -0.00615219, -0.0313119 ,  0.00693453,\n",
       "         0.0421954 , -0.0459513 , -0.0218726 ,  0.0107243 , -0.0536707 ,\n",
       "         0.00755717,  0.0235506 ,  0.0299614 ,  0.0114588 ,  0.0290584 ,\n",
       "        -0.0248488 , -0.0276563 ,  0.0396026 ,  0.0581892 , -0.088952  ,\n",
       "         0.0239154 ,  0.0350618 , -0.0199812 ,  0.0510433 , -0.0699488 ,\n",
       "        -0.0057464 , -0.0381105 , -0.0695138 , -0.00149769,  0.0505493 ,\n",
       "        -0.0167692 ,  0.050989  ,  0.0461348 , -0.00064027,  0.00910974,\n",
       "        -0.0185248 , -0.0104393 ,  0.0772929 ,  0.044558  ,  0.105982  ,\n",
       "        -0.105275  , -0.0124132 ,  0.00745753, -0.020058  ,  0.0512259 ]),\n",
       " array([-9.06021e-03,  2.19206e-02,  1.71226e-04,  6.35915e-02,\n",
       "        -3.09449e-02,  5.34364e-02,  6.78284e-02, -1.19880e-01,\n",
       "        -4.05741e-02,  1.30062e-01,  9.73831e-02,  3.00879e-02,\n",
       "         1.72106e-02, -3.89240e-02, -1.01683e-02, -3.83037e-02,\n",
       "        -2.80978e-03,  2.17784e-02,  1.22318e-01,  1.27648e-01,\n",
       "         1.07403e-02, -3.34992e-02, -9.58839e-02, -1.10397e-01,\n",
       "        -1.15140e-01, -1.14937e-01, -3.46937e-02, -7.05012e-02,\n",
       "        -1.52417e-02,  1.31463e-02, -3.91669e-03,  5.64123e-02,\n",
       "        -8.92559e-03,  3.74852e-02, -2.97163e-02,  5.25584e-02,\n",
       "        -9.10802e-02, -2.92634e-03, -3.21753e-02, -5.99262e-02,\n",
       "         1.49057e-02, -3.91511e-02, -3.95685e-02, -1.11797e-02,\n",
       "        -5.23943e-02, -1.54083e-02, -3.81021e-02, -1.45939e-02,\n",
       "         1.03969e-01,  3.73619e-02,  4.05910e-02, -4.93954e-04,\n",
       "         5.16097e-04, -4.90076e-02, -6.65782e-02,  5.82858e-03,\n",
       "        -6.14145e-02,  5.07034e-02,  5.10804e-02, -3.44083e-03,\n",
       "         3.23635e-02, -1.08436e-02,  3.51103e-02, -1.02121e-02,\n",
       "        -1.99760e-02, -5.75473e-02, -9.30197e-03, -4.18467e-02,\n",
       "        -1.03144e-01,  8.44954e-02, -6.54222e-02,  5.74709e-02,\n",
       "         3.29258e-02, -4.15073e-02, -8.20942e-03, -4.76774e-02,\n",
       "         1.45513e-01,  5.26321e-02,  9.54648e-02,  2.54090e-02,\n",
       "         5.38404e-02,  9.04154e-02, -5.23393e-02, -1.55477e-02,\n",
       "        -3.94861e-02, -3.83135e-02, -1.97616e-02,  3.80612e-02,\n",
       "         3.60173e-02, -4.84085e-02, -3.28703e-02, -3.90308e-02,\n",
       "         5.70585e-02, -5.20592e-02, -3.05342e-02, -7.80399e-02,\n",
       "        -1.15668e-02,  8.76308e-02, -9.68238e-03,  2.99046e-02,\n",
       "         9.64210e-02, -2.16525e-02,  1.17948e-01, -5.61196e-02,\n",
       "        -4.33555e-02, -1.33833e-01, -1.22385e-01,  1.34725e-02,\n",
       "        -7.01697e-02,  3.76458e-02,  8.28378e-03, -4.30056e-02,\n",
       "        -7.50496e-02, -4.16544e-02, -1.62679e-02,  4.53740e-02,\n",
       "         8.82058e-02,  7.65244e-02,  3.71021e-02,  5.15771e-02,\n",
       "         9.15737e-02,  8.60221e-02, -1.38972e-01,  1.13175e-01,\n",
       "        -1.78356e-02,  4.73423e-02,  9.55938e-02,  1.66348e-02,\n",
       "         8.11440e-02,  1.21426e-01,  3.81668e-02, -8.75260e-03,\n",
       "        -7.04524e-02,  6.75543e-02, -4.93994e-02, -7.71813e-03,\n",
       "        -5.90582e-02,  8.03060e-03, -5.36759e-02,  6.28207e-03,\n",
       "         6.34313e-03, -1.70400e-02, -1.45224e-02, -4.30397e-02,\n",
       "         4.77743e-02,  5.31806e-02,  3.75766e-02, -8.11197e-04,\n",
       "        -4.83023e-02,  9.42574e-02,  6.45220e-02, -1.45055e-01,\n",
       "        -2.48004e-02, -5.79202e-03, -2.30050e-02, -3.55978e-02,\n",
       "        -3.83722e-02,  1.88296e-03,  4.90181e-02, -4.44613e-02,\n",
       "        -5.42034e-02, -2.34239e-02, -8.24798e-02,  6.07147e-02,\n",
       "         1.05220e-01, -3.89694e-02, -2.80490e-02, -2.60986e-02,\n",
       "         1.48011e-01,  2.30375e-02, -6.19716e-02,  2.30129e-02,\n",
       "        -9.20836e-02,  6.36781e-02,  6.35508e-03,  9.32452e-03,\n",
       "        -6.12214e-02,  1.05349e-02, -8.18576e-02,  2.37068e-02,\n",
       "         7.83913e-02, -1.48387e-01, -3.59554e-03,  2.39618e-02,\n",
       "        -5.40291e-02,  3.99570e-02,  3.14598e-02, -2.48719e-02,\n",
       "         7.10846e-03,  2.98102e-02,  1.93803e-02, -5.75205e-02,\n",
       "         5.98817e-03,  3.04741e-02,  3.90132e-03, -1.88258e-02,\n",
       "        -1.54446e-02,  6.05011e-02,  3.65530e-02, -6.44855e-02,\n",
       "        -3.23443e-02, -2.34842e-02, -4.92631e-02,  6.93600e-03,\n",
       "        -4.81358e-03,  2.36225e-02, -8.83920e-02,  3.59766e-02,\n",
       "         1.06654e-01,  5.33042e-02,  5.33267e-02, -2.71412e-02,\n",
       "        -2.83723e-02,  1.15677e-01, -2.47769e-02, -2.59733e-05,\n",
       "         1.02374e-01, -8.36034e-03, -3.06329e-02,  1.59338e-02,\n",
       "        -1.07780e-02, -9.88202e-03,  3.25942e-02,  6.58399e-02,\n",
       "        -7.32659e-02, -6.29385e-02, -1.03082e-01, -9.75201e-02,\n",
       "         2.55511e-02, -5.98810e-02,  8.82001e-02, -1.03834e-01,\n",
       "         4.00776e-02,  1.31133e-01, -1.90370e-02,  5.92643e-02,\n",
       "         2.26406e-02, -1.13053e-02,  1.14630e-02, -6.07700e-02,\n",
       "         1.03055e-02, -8.07435e-02,  1.37088e-01, -1.05873e-02,\n",
       "         4.02736e-02, -1.14310e-02,  2.26634e-03,  2.37891e-02,\n",
       "        -5.73528e-03, -1.03575e-03, -1.52775e-02,  6.69653e-02,\n",
       "        -1.10208e-01,  1.25702e-02, -5.50391e-02,  4.80958e-02,\n",
       "        -3.27489e-02,  4.55961e-02, -1.64069e-01,  6.32344e-02,\n",
       "         1.26162e-02,  1.51574e-02,  8.66591e-03,  8.84088e-02,\n",
       "        -1.85329e-02, -2.07923e-02,  2.52179e-02, -6.29383e-02,\n",
       "        -2.07504e-02, -3.11073e-04, -4.31147e-02, -3.15228e-02,\n",
       "         9.75526e-02,  6.66725e-02, -3.51261e-03, -2.67080e-02,\n",
       "         4.69346e-02,  6.54788e-02,  5.55827e-02, -1.91637e-02,\n",
       "        -3.10607e-02, -3.32189e-02,  5.96778e-03, -2.10863e-02,\n",
       "         5.99353e-02, -3.55689e-02,  1.31866e-02,  9.96668e-03,\n",
       "        -2.13288e-02,  7.71556e-04, -9.30245e-02, -1.83336e-02,\n",
       "         1.26435e-02,  2.60339e-02, -4.62703e-02, -8.56205e-03,\n",
       "        -6.34259e-02,  8.41515e-03, -1.43566e-03,  1.41915e-02]),\n",
       " array([-9.68493e-02, -4.49945e-02, -5.87112e-02,  1.85129e-02,\n",
       "         1.47838e-02, -3.22395e-02, -6.21140e-02, -1.37997e-02,\n",
       "         3.04937e-02, -6.38133e-03,  4.16653e-02, -8.26573e-02,\n",
       "         8.08594e-02,  3.15960e-03, -1.36079e-01, -1.01358e-02,\n",
       "        -6.45654e-02, -7.46663e-02,  1.51552e-02,  2.38711e-01,\n",
       "        -4.75533e-02, -8.74960e-03, -8.07829e-02, -6.53335e-02,\n",
       "         3.97047e-03, -7.22381e-02,  2.92467e-03,  2.36931e-03,\n",
       "         7.03840e-03,  4.79725e-02, -4.55786e-02,  6.75106e-02,\n",
       "        -7.73178e-02,  7.90711e-02,  5.51830e-02, -3.48423e-02,\n",
       "        -3.96140e-02,  9.46961e-03,  2.87685e-02, -1.50334e-02,\n",
       "         1.22671e-01, -2.04204e-02,  4.27460e-03,  4.71267e-02,\n",
       "        -2.03661e-02, -7.89906e-02, -7.13119e-02, -4.49373e-02,\n",
       "        -5.62868e-04,  5.35755e-03,  6.03399e-03,  2.19017e-02,\n",
       "         6.16985e-02, -3.51574e-02, -1.06235e-02,  7.41883e-02,\n",
       "        -2.14128e-02,  9.83039e-02, -3.26728e-02,  5.14915e-02,\n",
       "        -6.91058e-02, -5.17779e-02,  7.62652e-02, -4.07107e-02,\n",
       "        -2.81749e-02, -5.86983e-02, -6.92020e-02, -1.03555e-01,\n",
       "        -1.18680e-02, -7.05784e-02, -8.74455e-02, -4.78102e-02,\n",
       "         9.29786e-02, -1.51669e-02, -4.53432e-03, -3.06106e-02,\n",
       "        -2.05388e-03,  1.10312e-01,  4.59908e-02, -2.92515e-02,\n",
       "         3.49661e-02,  7.21988e-02, -6.46014e-02, -4.55770e-02,\n",
       "        -9.16620e-02,  8.48046e-03, -6.20004e-02,  1.16442e-01,\n",
       "        -8.85238e-03, -2.62161e-02, -2.71805e-02, -3.75707e-02,\n",
       "         8.72701e-02, -3.97760e-02,  1.04133e-02, -1.02932e-02,\n",
       "         5.87622e-02,  2.13098e-02, -3.11896e-02,  3.00585e-02,\n",
       "         2.86419e-02, -5.17391e-02,  4.40347e-02, -4.03582e-02,\n",
       "        -5.51775e-02, -6.84137e-04, -1.27054e-02,  6.78926e-02,\n",
       "         1.69049e-02,  4.47835e-03,  8.59771e-02,  5.90681e-02,\n",
       "        -1.04045e-01, -1.08322e-01,  6.07063e-02,  4.30922e-02,\n",
       "         8.49103e-02,  7.76125e-02,  8.67187e-02,  1.73676e-02,\n",
       "         1.27368e-01, -1.47886e-02, -3.19666e-02,  5.69820e-02,\n",
       "        -5.77491e-02, -3.93040e-03,  4.15103e-02, -1.25701e-04,\n",
       "         9.63716e-02, -1.36705e-02, -8.37288e-02,  5.56702e-02,\n",
       "         2.29674e-02, -2.78512e-02,  2.27995e-02, -2.68187e-02,\n",
       "        -6.71366e-02,  1.68717e-02, -4.17256e-02, -2.31668e-02,\n",
       "         3.71517e-02, -4.07007e-02,  5.29106e-02,  3.86742e-02,\n",
       "        -4.95679e-02,  1.20341e-01,  1.17234e-01,  3.32642e-03,\n",
       "        -2.35823e-02,  1.62135e-02,  3.94389e-02, -5.96167e-02,\n",
       "         1.10071e-02,  1.11240e-01, -3.14481e-02, -8.86072e-02,\n",
       "         1.47995e-02, -5.04589e-03, -9.79687e-03,  1.24651e-02,\n",
       "        -3.21273e-02,  8.05496e-02,  2.19809e-02, -5.25378e-03,\n",
       "         1.21811e-01, -4.82674e-02, -1.71615e-02, -1.17723e-02,\n",
       "         6.74073e-02, -4.82257e-02, -9.94882e-02,  9.55341e-03,\n",
       "         1.02700e-02,  9.14499e-03, -1.04062e-01,  4.16491e-02,\n",
       "         1.51629e-01,  3.89059e-02,  1.61824e-03, -5.56266e-02,\n",
       "        -5.84264e-02, -2.24894e-02, -6.97514e-02,  3.69407e-02,\n",
       "        -8.68294e-02,  6.61319e-02,  2.23258e-02, -9.53630e-02,\n",
       "         1.44491e-02, -6.94805e-03,  1.18605e-02, -8.68554e-02,\n",
       "         3.97544e-02,  9.77698e-02, -1.59310e-04,  2.86706e-02,\n",
       "        -5.09183e-02,  4.40781e-02, -9.30341e-03, -4.82990e-02,\n",
       "         5.90908e-02, -1.45040e-01, -2.88518e-02,  3.25826e-02,\n",
       "         2.15458e-02, -4.16776e-02,  5.12992e-03,  1.96815e-02,\n",
       "         3.46135e-02,  4.12763e-02,  9.42340e-02,  6.13269e-02,\n",
       "         7.24447e-02, -1.56330e-02, -2.16599e-03, -1.33814e-01,\n",
       "         5.63507e-02, -8.73857e-02, -1.47921e-02,  2.70185e-02,\n",
       "         6.61427e-02, -3.75789e-02, -2.51961e-02,  2.86398e-02,\n",
       "        -7.73290e-02, -2.14134e-02, -3.18562e-02, -2.34317e-02,\n",
       "        -6.28405e-04, -5.35188e-02, -6.32338e-02,  7.63958e-02,\n",
       "        -8.16102e-02,  5.70528e-02, -2.95677e-02,  3.91335e-02,\n",
       "        -9.97282e-03, -1.11716e-02, -4.61242e-02, -5.38165e-02,\n",
       "        -5.29860e-02, -7.49983e-02, -3.56754e-02, -4.92169e-02,\n",
       "         5.58287e-02,  5.12682e-02,  2.01806e-02,  8.31031e-03,\n",
       "         8.50414e-02, -3.01955e-02,  3.76474e-03,  6.13784e-02,\n",
       "        -1.93142e-02, -2.19081e-02, -1.24682e-03,  9.38863e-02,\n",
       "        -8.98601e-02, -5.76641e-02,  4.88985e-02, -4.87905e-02,\n",
       "         1.30229e-02,  1.73565e-02,  1.06518e-02, -3.00640e-02,\n",
       "        -5.97241e-02, -1.93300e-02, -4.32506e-02,  7.13613e-02,\n",
       "         7.05156e-02, -1.00299e-01, -5.67775e-02, -3.66090e-02,\n",
       "         3.41678e-03,  4.14066e-02,  9.02743e-03,  1.24439e-01,\n",
       "         6.47489e-02,  9.03562e-02,  2.55020e-02, -1.15863e-02,\n",
       "         5.59263e-02, -3.01994e-02,  2.97352e-02,  3.96460e-02,\n",
       "         6.87864e-02, -4.40372e-02, -1.46065e-02,  4.47275e-02,\n",
       "        -1.23809e-02,  1.06011e-02,  3.79768e-02, -1.21224e-01,\n",
       "         1.15727e-02,  6.53361e-02, -9.66798e-03,  1.91997e-02,\n",
       "        -3.73811e-02,  1.25466e-01, -7.21938e-02, -5.68300e-02]),\n",
       " array([ 0.00188815, -0.00104701, -0.0115182 , -0.0598254 , -0.0701129 ,\n",
       "        -0.0520086 ,  0.0572807 , -0.0480093 ,  0.0432589 ,  0.0146968 ,\n",
       "        -0.101904  , -0.0695836 ,  0.0157293 ,  0.00360114,  0.0669575 ,\n",
       "         0.00149288, -0.0224993 ,  0.00501282,  0.0909897 ,  0.0292056 ,\n",
       "        -0.0183505 ,  0.0149885 , -0.0306571 , -0.0701191 ,  0.0131253 ,\n",
       "        -0.0193112 , -0.0495521 , -0.0850053 ,  0.0728758 , -0.00024434,\n",
       "         0.0101746 ,  0.0672978 ,  0.0406208 , -0.0835494 , -0.0652353 ,\n",
       "        -0.0783391 ,  0.0729708 , -0.0184173 ,  0.0323808 ,  0.0350838 ,\n",
       "        -0.0134335 ,  0.0166105 , -0.0371075 , -0.0685382 ,  0.0167439 ,\n",
       "        -0.0582374 , -0.0231774 , -0.0304228 ,  0.0138991 , -0.00883037,\n",
       "         0.0322992 ,  0.0194401 ,  0.0990207 , -0.090946  , -0.0298483 ,\n",
       "        -0.0449079 ,  0.0312869 ,  0.0794418 ,  0.0229934 ,  0.0761303 ,\n",
       "         0.0328933 ,  0.0239592 ,  0.0644727 , -0.0060518 ,  0.0286314 ,\n",
       "        -0.0497567 , -0.0651771 ,  0.0532762 ,  0.0168416 ,  0.108128  ,\n",
       "        -0.00095516, -0.0055289 ,  0.0386647 , -0.00910397, -0.0582713 ,\n",
       "        -0.0481185 ,  0.111947  ,  0.0251631 ,  0.0217894 , -0.00896308,\n",
       "         0.0648906 ,  0.0405522 ,  0.0311831 ,  0.0947604 , -0.0259673 ,\n",
       "         0.0213212 , -0.0140689 ,  0.0562448 , -0.00375887, -0.00213894,\n",
       "        -0.0350949 , -0.0641764 ,  0.0263586 , -0.0436227 , -0.0438728 ,\n",
       "         0.0533542 , -0.0309379 ,  0.0258789 ,  0.144561  , -0.0127271 ,\n",
       "         0.00912992,  0.0948653 ,  0.0458632 ,  0.0910781 ,  0.00702087,\n",
       "        -0.0320248 , -0.0918861 ,  0.116572  , -0.0450872 ,  0.0160839 ,\n",
       "         0.00654516, -0.00929161, -0.129115  , -0.0677899 ,  0.030959  ,\n",
       "        -0.0885768 ,  0.112169  , -0.0248888 , -0.066803  , -0.0269468 ,\n",
       "         0.0586086 , -0.0223812 ,  0.0219894 ,  0.0207043 ,  0.0291549 ,\n",
       "        -0.0661165 ,  0.126412  ,  0.0389038 , -0.00597418,  0.05174   ,\n",
       "        -0.0111734 ,  0.0863504 , -0.0843388 ,  0.0361891 ,  0.0814088 ,\n",
       "        -0.070087  , -0.0665938 , -0.0176773 , -0.0358761 ,  0.0477301 ,\n",
       "        -0.0204991 ,  0.00780334,  0.0324788 ,  0.0180151 , -0.0313786 ,\n",
       "         0.0441395 ,  0.0497811 , -0.130871  , -0.0687159 ,  0.0454981 ,\n",
       "         0.0260934 , -0.123871  , -0.0227617 , -0.039038  ,  0.0390007 ,\n",
       "         0.0442794 , -0.036149  ,  0.0477078 ,  0.0833025 , -0.0397745 ,\n",
       "         0.0517444 ,  0.024924  , -0.141505  , -0.0346679 ,  0.0383998 ,\n",
       "         0.0299246 ,  0.0194462 ,  0.00167121,  0.0486377 , -0.020161  ,\n",
       "        -0.0053205 ,  0.0689579 , -0.0565127 , -0.0424162 ,  0.117826  ,\n",
       "         0.046221  , -0.0579938 , -0.00577082, -0.0364312 , -0.0434591 ,\n",
       "         0.0221123 , -0.0960546 , -0.0416812 , -0.0544725 , -0.0620051 ,\n",
       "         0.00434459, -0.0225051 , -0.108651  ,  0.0173369 ,  0.0190844 ,\n",
       "         0.0725027 , -0.0212742 ,  0.092143  ,  0.058859  , -0.12481   ,\n",
       "         0.0647558 ,  0.0253407 ,  0.0361625 , -0.00030253, -0.121434  ,\n",
       "         0.0673855 ,  0.0435428 , -0.0106612 ,  0.00382549,  0.0574668 ,\n",
       "        -0.0331602 ,  0.102345  ,  0.0680041 ,  0.103918  , -0.00812533,\n",
       "         0.197103  ,  0.0151481 , -0.00904054, -0.0920326 , -0.072125  ,\n",
       "         0.038148  ,  0.0417386 , -0.178881  ,  0.0869565 , -0.0436571 ,\n",
       "         0.00566957, -0.0400862 , -0.0563391 ,  0.0563747 ,  0.0860371 ,\n",
       "        -0.0120389 , -0.0412227 ,  0.0197029 ,  0.0464097 ,  0.0459909 ,\n",
       "         0.00949767,  0.0259898 ,  0.0564943 ,  0.0643326 ,  0.0114383 ,\n",
       "        -0.0639547 ,  0.0100413 ,  0.0496864 ,  0.111597  , -0.0371946 ,\n",
       "         0.0203354 , -0.0231263 ,  0.032601  , -0.100892  , -0.0493195 ,\n",
       "         0.0691317 ,  0.0790382 ,  0.03146   ,  0.068418  , -0.0713063 ,\n",
       "         0.00121554,  0.0512545 , -0.0307928 , -0.0769688 , -0.0452436 ,\n",
       "        -0.0194355 , -0.0357562 , -0.157562  ,  0.0116976 ,  0.00803967,\n",
       "         0.144365  ,  0.00315934,  0.0401312 , -0.0228958 ,  0.037528  ,\n",
       "        -0.0135067 ,  0.0284812 , -0.0501094 , -0.0149389 , -0.0339004 ,\n",
       "        -0.0310929 , -0.0529602 , -0.00303124,  0.00124136, -0.0983865 ,\n",
       "        -0.0290779 , -0.00829387,  0.115885  ,  0.0807123 , -0.055451  ,\n",
       "        -0.0435015 ,  0.052506  ,  0.0862586 , -0.0107448 ,  0.0935416 ,\n",
       "        -0.0462447 ,  0.0180629 ,  0.0158557 , -0.0273221 ,  0.0589331 ,\n",
       "         0.0348625 ,  0.063056  ,  0.0141107 , -0.0214418 , -0.00201234,\n",
       "         0.0255884 , -0.0110669 , -0.06751   ,  0.0842762 , -0.00718137]),\n",
       " array([ 0.00975112,  0.119637  , -0.0942776 , -0.0464149 , -0.0405434 ,\n",
       "         0.0475084 ,  0.0341872 ,  0.0266829 , -0.0355644 ,  0.148003  ,\n",
       "         0.0681747 , -0.0877465 , -0.0283309 , -0.056195  ,  0.0114812 ,\n",
       "         0.0438521 , -0.0808381 ,  0.00349589, -0.0155833 ,  0.0698691 ,\n",
       "        -0.00705903,  0.0350561 , -0.0915204 , -0.00819792,  0.00479954,\n",
       "        -0.0177702 , -0.00994384, -0.108691  ,  0.008076  , -0.0209999 ,\n",
       "         0.00426352,  0.0702555 , -0.0877146 ,  0.0910797 , -0.0147118 ,\n",
       "        -0.11022   ,  0.0349289 , -0.0851626 ,  0.00283883,  0.0750625 ,\n",
       "         0.0730617 , -0.0312385 , -0.0256113 , -0.0315099 ,  0.0347672 ,\n",
       "         0.0652587 ,  0.0988442 ,  0.0823979 ,  0.0689653 , -0.158082  ,\n",
       "        -0.00817641, -0.0464158 ,  0.0574543 , -0.0144348 , -0.0958095 ,\n",
       "         0.02447   ,  0.0374128 , -0.0076234 , -0.0600084 ,  0.023464  ,\n",
       "         0.01985   , -0.0847562 ,  0.0872168 ,  0.00823615,  0.0127491 ,\n",
       "         0.0181383 , -0.126212  , -0.0121579 , -0.0223335 ,  0.00148263,\n",
       "        -0.0563427 ,  0.0144894 ,  0.0832793 , -0.177106  , -0.0517708 ,\n",
       "        -0.0542267 ,  0.123522  ,  0.0595698 ,  0.00219836,  0.0156276 ,\n",
       "         0.0353615 ,  0.0186483 , -0.0429712 , -0.00473874, -0.034195  ,\n",
       "         0.028294  ,  0.046897  ,  0.0644226 ,  0.106598  , -0.00026571,\n",
       "        -0.00815025,  0.00438235,  0.109577  , -0.0406536 , -0.0719481 ,\n",
       "         0.0736738 ,  0.0275263 , -0.0491297 ,  0.00337114, -0.107607  ,\n",
       "        -0.0425055 ,  0.0382756 ,  0.0650691 , -0.00754835, -0.078798  ,\n",
       "         0.00483923, -0.0186827 ,  0.0460076 ,  0.0578245 ,  0.0159246 ,\n",
       "        -0.0178582 , -0.0492316 ,  0.00614735, -0.0202196 , -0.00607911,\n",
       "        -0.007078  ,  0.0671585 ,  0.0297627 , -0.0805695 , -0.0156748 ,\n",
       "        -0.00812021,  0.0745784 ,  0.0481133 ,  0.06913   ,  0.0675901 ,\n",
       "        -0.085362  ,  0.0251587 ,  0.0119791 ,  0.0171626 ,  0.0727988 ,\n",
       "        -0.0318013 , -0.0016124 , -0.0352005 ,  0.0177587 ,  0.0282304 ,\n",
       "         0.116075  , -0.032585  , -0.0285519 , -0.0775812 ,  0.0595998 ,\n",
       "        -0.0182417 ,  0.0426937 ,  0.00515793, -0.00357626,  0.0414304 ,\n",
       "         0.0729902 ,  0.0148321 , -0.0238366 ,  0.0554372 ,  0.0469339 ,\n",
       "         0.0147837 , -0.0850903 , -0.00783743, -0.0524577 , -0.0337407 ,\n",
       "        -0.114862  , -0.0686778 , -0.0705654 ,  0.0488455 , -0.0265024 ,\n",
       "        -0.0491378 ,  0.0351447 ,  0.00272222,  0.00390732,  0.118423  ,\n",
       "        -0.0300674 , -0.0802817 , -0.0535262 ,  0.0989052 ,  0.0356557 ,\n",
       "        -0.170423  ,  0.052     , -0.0317037 ,  0.0409809 ,  0.0316994 ,\n",
       "         0.123209  , -0.0334113 ,  0.018638  , -0.0682869 , -0.103262  ,\n",
       "         0.0487244 , -0.0872005 ,  0.0222187 ,  0.0167851 , -0.0115659 ,\n",
       "         0.0435872 , -0.0102539 , -0.0080929 ,  0.123839  ,  0.0290373 ,\n",
       "        -0.106611  , -0.0402306 ,  0.130107  ,  0.049695  , -0.0533811 ,\n",
       "         0.0382213 , -0.0161471 , -0.0145961 , -0.134773  ,  0.00497049,\n",
       "        -0.0465312 , -0.134493  , -0.0337239 ,  0.0264446 ,  0.0396196 ,\n",
       "        -0.0369539 , -0.030764  ,  0.0156583 ,  0.0837196 ,  0.0425554 ,\n",
       "         0.0781432 , -0.0137224 , -0.126679  ,  0.0223628 ,  0.00073405,\n",
       "        -0.0578896 , -0.0650061 , -0.0938807 ,  0.0639242 ,  0.098554  ,\n",
       "        -0.103743  ,  0.0103537 , -0.0303705 ,  0.0311502 ,  0.033287  ,\n",
       "         0.0248492 , -0.0539245 , -0.0914327 , -0.0064936 , -0.0358289 ,\n",
       "         0.0876889 ,  0.0103675 , -0.036118  , -0.00805633,  0.00622018,\n",
       "         0.0584753 , -0.00209006,  0.0444164 ,  0.0114529 , -0.00076925,\n",
       "        -0.00021932,  0.0145257 ,  0.0398693 ,  0.0228918 ,  0.0262819 ,\n",
       "         0.00346863,  0.0301739 , -0.0421571 ,  0.00913725,  0.029883  ,\n",
       "         0.0490262 ,  0.0254422 , -0.137204  ,  0.0251723 , -0.0342355 ,\n",
       "        -0.12476   , -0.0847641 , -0.00615219, -0.0313119 ,  0.00693453,\n",
       "         0.0421954 , -0.0459513 , -0.0218726 ,  0.0107243 , -0.0536707 ,\n",
       "         0.00755717,  0.0235506 ,  0.0299614 ,  0.0114588 ,  0.0290584 ,\n",
       "        -0.0248488 , -0.0276563 ,  0.0396026 ,  0.0581892 , -0.088952  ,\n",
       "         0.0239154 ,  0.0350618 , -0.0199812 ,  0.0510433 , -0.0699488 ,\n",
       "        -0.0057464 , -0.0381105 , -0.0695138 , -0.00149769,  0.0505493 ,\n",
       "        -0.0167692 ,  0.050989  ,  0.0461348 , -0.00064027,  0.00910974,\n",
       "        -0.0185248 , -0.0104393 ,  0.0772929 ,  0.044558  ,  0.105982  ,\n",
       "        -0.105275  , -0.0124132 ,  0.00745753, -0.020058  ,  0.0512259 ]),\n",
       " array([ 5.06639e-02,  3.51545e-02, -1.72116e-02,  4.90008e-02,\n",
       "        -5.61541e-02, -1.95074e-03, -2.26514e-02, -8.54570e-02,\n",
       "         1.18764e-01,  7.50615e-02,  2.44487e-02, -4.96470e-02,\n",
       "         1.78333e-02, -3.05367e-02, -4.41866e-02, -1.10240e-01,\n",
       "        -3.66929e-03, -1.01048e-02,  4.64581e-02,  9.54881e-03,\n",
       "        -9.03416e-02, -2.46514e-02, -5.31538e-02, -1.16700e-01,\n",
       "        -3.24617e-02, -5.70935e-02,  4.91086e-02, -6.10294e-02,\n",
       "        -4.83233e-02,  3.78509e-02, -2.80704e-02,  4.79077e-02,\n",
       "        -4.80485e-02,  1.74171e-01,  3.03310e-03, -8.32110e-03,\n",
       "        -2.08241e-02,  3.01372e-02, -6.14373e-02, -1.59208e-02,\n",
       "         9.87305e-02, -5.43245e-02,  1.13139e-02,  1.62914e-03,\n",
       "         1.09684e-01,  1.44995e-02, -2.71101e-02,  6.86425e-02,\n",
       "         3.31672e-02,  7.71765e-03, -5.28601e-02,  1.58113e-02,\n",
       "        -4.52209e-02,  8.12087e-03, -6.15416e-02, -1.60739e-03,\n",
       "        -3.28031e-02,  6.00029e-02, -1.32618e-01,  1.84791e-02,\n",
       "        -6.13270e-02, -9.81455e-02,  1.63738e-01, -2.68178e-02,\n",
       "         7.13800e-03,  8.44223e-02, -1.10156e-01, -8.13834e-02,\n",
       "        -2.62382e-02,  7.28268e-02, -6.46987e-02, -4.39197e-02,\n",
       "         5.28250e-02, -6.28713e-02, -5.95652e-02, -1.08243e-02,\n",
       "         2.02630e-02,  8.85479e-02, -2.82036e-02,  2.67400e-02,\n",
       "        -9.39535e-02,  7.41650e-02, -4.00800e-02,  6.20551e-02,\n",
       "        -5.44354e-02,  7.24982e-03,  1.57011e-02,  6.35107e-02,\n",
       "         3.76603e-02, -2.37490e-02,  7.57646e-02, -5.60904e-02,\n",
       "         1.17774e-01, -1.43053e-01, -3.98919e-02,  2.24638e-02,\n",
       "         2.88057e-03,  1.56023e-02,  3.97524e-02,  2.92548e-02,\n",
       "        -1.28463e-03, -2.60976e-02, -1.66314e-02, -6.80013e-02,\n",
       "        -5.29937e-02, -8.01559e-02, -4.21559e-02,  5.07077e-02,\n",
       "        -1.69675e-02,  3.24617e-02,  2.03459e-02, -2.01030e-02,\n",
       "        -7.51108e-04, -8.54002e-02, -7.74710e-03,  1.13282e-01,\n",
       "         1.31092e-02, -3.20639e-03,  4.02273e-02, -5.28829e-05,\n",
       "         1.08341e-01,  1.38829e-01, -1.00378e-02,  8.64733e-02,\n",
       "         6.72027e-02,  2.09736e-02,  1.28579e-01,  3.60784e-02,\n",
       "         3.74157e-02,  4.06414e-02, -5.55545e-02,  9.06850e-03,\n",
       "         1.15776e-02, -9.64091e-02,  1.39126e-02, -2.84838e-02,\n",
       "        -1.43360e-01,  6.09753e-02, -1.50370e-02,  7.67117e-02,\n",
       "         5.25658e-02,  6.76763e-02,  2.17504e-02,  5.93470e-02,\n",
       "        -5.95657e-02,  3.58530e-02,  2.06852e-03, -4.51787e-02,\n",
       "        -6.12259e-03,  6.59637e-02, -7.29639e-03, -7.53552e-02,\n",
       "        -1.64408e-02,  2.14520e-02, -7.59684e-03, -5.85019e-02,\n",
       "         2.44365e-03, -2.94765e-02,  9.62679e-02, -5.59233e-02,\n",
       "        -1.09607e-01,  1.49053e-02, -5.74633e-02,  3.04183e-02,\n",
       "         5.81765e-02,  6.43265e-02, -4.91318e-02, -1.08690e-01,\n",
       "         8.93755e-02,  3.35349e-02, -4.08477e-02,  5.38290e-02,\n",
       "        -4.37978e-02,  8.57264e-03, -1.30830e-02,  1.04625e-01,\n",
       "        -4.60908e-02,  2.83378e-02, -6.89865e-02, -2.19377e-04,\n",
       "         1.53397e-02,  5.52688e-03, -1.52708e-03,  2.07117e-02,\n",
       "         1.34272e-02, -1.13965e-02,  3.52270e-03, -4.23256e-02,\n",
       "         7.81302e-02,  1.29738e-02, -6.30284e-02, -1.27704e-01,\n",
       "         1.81310e-02,  3.95726e-02, -2.24731e-02,  9.89337e-03,\n",
       "         4.23292e-02,  3.52878e-02, -2.08285e-02, -5.30357e-04,\n",
       "         3.37618e-02,  8.41326e-03, -6.44665e-03,  7.08737e-02,\n",
       "         7.27029e-02, -3.24000e-02,  1.01043e-01, -5.25747e-02,\n",
       "         1.05499e-01,  8.71627e-02,  7.35984e-02,  1.44997e-02,\n",
       "         1.98570e-02, -1.63303e-01,  4.17292e-03, -8.53099e-02,\n",
       "        -5.63976e-02, -8.03943e-02, -1.80613e-02,  3.13514e-02,\n",
       "        -2.48563e-02,  3.73000e-02, -2.05695e-02,  5.76105e-03,\n",
       "        -1.26634e-02,  7.71866e-02, -3.23741e-02, -3.55345e-02,\n",
       "        -5.35878e-03, -2.33479e-04, -7.63921e-02, -3.68241e-03,\n",
       "         6.19323e-02, -9.86021e-02, -4.96702e-02, -2.24195e-02,\n",
       "        -5.64212e-02, -4.22981e-02,  1.13693e-01,  8.35384e-02,\n",
       "        -3.44819e-03, -1.82955e-02,  7.83823e-02, -4.71734e-03,\n",
       "         3.33519e-02,  6.67594e-02,  6.42443e-02, -5.03742e-02,\n",
       "        -1.57173e-02,  3.62424e-03,  3.86348e-03,  6.95063e-02,\n",
       "         8.29881e-03, -1.03556e-01,  2.32788e-02,  7.56806e-02,\n",
       "         6.59514e-03, -6.93405e-02, -8.28003e-02, -1.67787e-02,\n",
       "         2.62263e-02,  3.12799e-02, -4.97463e-02,  7.93526e-02,\n",
       "        -2.26655e-02, -5.53956e-02,  1.31497e-02,  1.74196e-02,\n",
       "         1.87578e-02, -3.75544e-02,  9.93731e-03,  5.60459e-03,\n",
       "        -1.40699e-02, -2.96563e-02, -2.27298e-02, -4.78809e-03,\n",
       "        -1.25713e-02,  7.13526e-02, -7.36246e-02,  4.20485e-02,\n",
       "         6.45219e-02, -2.92198e-02,  1.06517e-01,  4.67114e-02,\n",
       "         4.31401e-02,  7.45433e-03,  6.98040e-03,  1.03313e-02,\n",
       "        -1.36248e-01,  4.15097e-02, -3.17651e-03, -2.62903e-02,\n",
       "        -1.25590e-03,  5.45185e-02,  9.63007e-02, -2.23261e-02,\n",
       "         4.30278e-02,  1.48748e-01,  2.67267e-02, -2.41632e-02]),\n",
       " array([ 4.78627e-02,  1.94022e-02, -2.33248e-02, -1.33099e-01,\n",
       "        -6.59414e-02, -5.43959e-02,  6.83811e-03, -1.40807e-01,\n",
       "        -6.83645e-02,  5.91574e-02,  1.71525e-03, -3.74853e-02,\n",
       "        -1.26069e-04,  1.17607e-01,  3.14170e-02, -1.31589e-01,\n",
       "         5.15761e-03, -1.64882e-02,  2.43436e-02,  7.47747e-02,\n",
       "         3.06345e-02,  8.59808e-03, -3.89529e-02, -1.89738e-02,\n",
       "        -2.33225e-02, -5.76033e-02,  4.74074e-02,  1.63454e-02,\n",
       "        -5.90607e-02,  1.64582e-02,  3.15508e-02,  1.68591e-01,\n",
       "        -1.26759e-02, -3.63190e-02,  3.54532e-03, -3.60413e-02,\n",
       "         6.75287e-02, -5.77554e-03,  9.54045e-02,  6.05530e-02,\n",
       "        -1.86587e-02,  9.49619e-03,  3.90011e-02,  9.29618e-03,\n",
       "         2.74507e-04, -8.58308e-02,  1.35497e-03, -8.96954e-03,\n",
       "         1.19915e-02, -4.36220e-02, -4.91049e-02, -3.09188e-02,\n",
       "         4.94465e-02, -8.52805e-02, -3.12226e-02, -3.17981e-02,\n",
       "         3.83168e-02,  7.79180e-02, -3.39698e-02,  6.85059e-02,\n",
       "         5.69661e-02, -5.13655e-02,  4.19482e-02,  2.63324e-02,\n",
       "        -6.71683e-02,  3.26922e-02, -6.45380e-02, -9.72287e-02,\n",
       "        -4.26325e-03, -2.03926e-02, -3.63622e-02,  8.34459e-02,\n",
       "         1.23842e-01,  4.63085e-02, -4.27139e-02,  6.72240e-02,\n",
       "         1.24279e-01, -1.62218e-02, -6.19764e-02, -2.82799e-02,\n",
       "        -2.20936e-03,  3.42590e-02, -4.44542e-02,  4.19729e-02,\n",
       "        -3.00611e-02, -8.40272e-03,  8.77069e-02,  6.17791e-02,\n",
       "        -8.57760e-02, -2.08368e-02, -5.09060e-03,  1.04714e-01,\n",
       "        -2.70759e-02,  5.88580e-02, -5.11408e-02,  5.77955e-02,\n",
       "         2.63201e-02,  1.89451e-02,  2.55303e-02,  5.27526e-03,\n",
       "        -1.01518e-03, -4.86695e-03, -4.26362e-02,  3.68550e-02,\n",
       "        -2.15045e-02,  3.89479e-02, -3.46077e-02, -7.07931e-03,\n",
       "         4.65075e-02, -5.71414e-02,  4.36464e-02, -4.41618e-05,\n",
       "        -7.57334e-02, -5.40316e-02, -2.40519e-02, -2.74457e-02,\n",
       "        -4.46610e-02,  4.46356e-02, -1.34147e-02, -2.44920e-02,\n",
       "         3.03152e-02,  2.09944e-02,  3.10671e-02,  1.20099e-01,\n",
       "        -5.75026e-04, -5.48622e-02, -5.56953e-02, -2.94598e-03,\n",
       "        -3.86093e-02,  2.08030e-02, -4.85520e-02,  1.08892e-01,\n",
       "        -1.73684e-02, -3.75490e-03,  3.27494e-02, -6.30273e-02,\n",
       "        -4.60377e-02, -1.94672e-01,  9.14960e-02,  7.50673e-02,\n",
       "        -3.75720e-02,  7.46189e-02,  8.40401e-02,  6.61386e-02,\n",
       "        -4.69834e-02,  1.10982e-01,  6.49803e-02, -3.80962e-02,\n",
       "         3.64149e-02, -2.78070e-02,  4.35768e-02, -7.47086e-02,\n",
       "        -4.70215e-02, -1.07044e-01,  6.42052e-02,  5.86640e-03,\n",
       "         4.66043e-03,  4.37357e-02,  6.28814e-02,  1.86893e-02,\n",
       "        -5.00497e-02, -1.24760e-02,  9.90040e-02,  1.26102e-02,\n",
       "         9.64710e-03, -7.10604e-02,  8.87307e-02,  5.63983e-02,\n",
       "         4.90836e-02, -1.73196e-02, -4.45042e-02,  8.16791e-02,\n",
       "        -8.76722e-02, -4.53680e-02,  3.74663e-02,  2.04804e-02,\n",
       "        -1.10706e-02, -4.32136e-02, -1.31715e-02, -9.18041e-02,\n",
       "         3.86821e-03, -1.18821e-01, -1.49393e-02,  2.66541e-02,\n",
       "        -4.86147e-02,  4.75858e-02,  4.65572e-02, -7.74699e-02,\n",
       "         7.62017e-03,  5.88842e-02, -1.07330e-01, -2.08916e-03,\n",
       "         4.27310e-02, -3.91773e-02, -1.35622e-01, -4.89744e-02,\n",
       "         8.65475e-03,  2.61530e-02,  1.09516e-02, -7.67293e-02,\n",
       "         2.06612e-02,  2.46164e-03, -1.05216e-01, -2.07072e-02,\n",
       "         1.05435e-01, -1.22440e-01,  8.82022e-02,  3.03077e-02,\n",
       "         1.53063e-01, -4.25644e-02,  1.60127e-02, -7.08606e-03,\n",
       "        -1.04443e-01, -9.57010e-03, -9.33299e-02,  7.41222e-03,\n",
       "        -3.59001e-02,  6.86580e-02, -4.86396e-02, -7.69935e-02,\n",
       "        -8.85098e-02,  5.69158e-03, -8.09832e-02,  4.98515e-02,\n",
       "         7.19155e-02, -3.24455e-03, -6.79428e-02, -2.69772e-02,\n",
       "        -1.21764e-02,  1.33622e-01, -4.47043e-02, -7.16766e-02,\n",
       "         1.45101e-02,  4.29876e-03,  7.41813e-02,  1.36215e-02,\n",
       "        -7.59653e-03, -7.14959e-02, -6.78324e-02, -1.17474e-02,\n",
       "         2.74147e-02,  1.47473e-02,  1.68290e-02, -9.95183e-02,\n",
       "         1.36177e-02, -4.44837e-02, -1.75279e-02, -6.62628e-02,\n",
       "        -1.00670e-02, -7.77296e-02,  2.68762e-02, -1.16562e-02,\n",
       "        -4.70949e-02,  3.96896e-04, -6.99313e-02,  5.17821e-02,\n",
       "         8.00482e-02, -8.44181e-02, -7.66315e-03,  2.19247e-02,\n",
       "         2.97520e-02,  5.76723e-02,  6.55019e-03,  5.82557e-02,\n",
       "        -4.01539e-02,  3.00521e-02,  2.70761e-02,  4.21953e-02,\n",
       "        -6.92921e-02,  5.08463e-03, -8.45244e-02, -3.09581e-02,\n",
       "         5.77949e-02,  4.11358e-02, -4.53721e-02, -8.15806e-02,\n",
       "         4.60865e-02,  1.45945e-02,  3.24460e-02,  2.56202e-02,\n",
       "        -6.61238e-02,  9.22449e-02, -5.22861e-04, -1.31709e-02,\n",
       "         3.84974e-02, -9.86469e-03,  6.45534e-02,  1.36779e-01,\n",
       "         4.02557e-02,  5.97308e-02, -5.76539e-02, -2.45949e-02,\n",
       "         5.49837e-02,  2.90052e-03, -9.29521e-02, -6.63644e-02,\n",
       "        -3.33562e-02, -6.31796e-04,  6.68047e-02,  4.42303e-02]),\n",
       " array([-6.12397e-02,  3.46981e-03, -7.64603e-02,  4.91042e-02,\n",
       "        -7.04850e-02,  3.55625e-03, -2.18637e-02, -1.06008e-01,\n",
       "         4.18920e-02,  3.22929e-02,  1.04301e-02, -4.03740e-02,\n",
       "        -3.21916e-02, -7.03977e-02, -8.37410e-03, -7.47457e-02,\n",
       "        -6.42461e-02,  5.40774e-02,  5.70819e-02,  1.19072e-02,\n",
       "        -9.62864e-03,  4.15430e-02, -4.57741e-03, -1.74413e-02,\n",
       "         6.05420e-03, -2.07086e-02, -7.56842e-04, -4.12157e-02,\n",
       "        -3.88803e-02,  6.52263e-02, -5.25473e-02,  4.43837e-02,\n",
       "        -4.76431e-03,  2.12280e-01, -4.53020e-02, -3.25556e-02,\n",
       "         4.12459e-02,  1.44429e-02, -7.51288e-02, -3.73435e-02,\n",
       "         2.40621e-02, -6.21414e-02, -2.15216e-02,  1.96820e-02,\n",
       "         5.74932e-02,  5.59556e-02,  4.26815e-02,  9.67375e-02,\n",
       "         3.88550e-02,  1.58406e-02, -3.22860e-02, -2.39797e-02,\n",
       "        -3.92149e-02, -6.36145e-02, -1.38231e-02, -6.94111e-03,\n",
       "        -7.20570e-02, -2.73016e-03, -1.09634e-01,  4.30454e-02,\n",
       "        -4.69756e-02,  3.05726e-02,  1.49743e-01, -5.37793e-02,\n",
       "         6.88387e-02,  1.13410e-01, -8.37313e-02, -3.54288e-03,\n",
       "         2.71814e-03,  8.17990e-02, -2.75889e-02, -5.27840e-02,\n",
       "         8.73788e-02, -9.98178e-02, -7.78694e-02, -2.63295e-02,\n",
       "         5.53648e-02,  9.99623e-02,  2.22116e-02, -2.80952e-02,\n",
       "        -5.80927e-02,  4.34273e-02, -8.95494e-02,  5.63697e-02,\n",
       "         2.18235e-02,  6.31031e-02,  4.35955e-02,  5.78221e-02,\n",
       "        -1.48737e-02,  2.37832e-02,  6.66272e-02, -4.75917e-03,\n",
       "         1.11173e-01, -9.65742e-02,  1.13975e-02,  1.67096e-02,\n",
       "         5.87504e-02,  3.78214e-03,  5.46940e-02,  1.88671e-02,\n",
       "         4.11643e-02, -4.00019e-02, -3.45567e-02, -7.81747e-02,\n",
       "        -8.05413e-02, -1.78053e-01, -1.00972e-01, -9.17555e-02,\n",
       "        -1.04880e-01,  5.14438e-02,  2.81933e-03,  1.82898e-02,\n",
       "        -2.22361e-02, -1.94194e-02, -1.07878e-02,  3.05450e-02,\n",
       "         1.25100e-01, -2.40067e-02,  1.53940e-04, -2.61465e-02,\n",
       "         8.03628e-02,  5.70613e-02, -6.74735e-02,  7.21579e-02,\n",
       "        -5.81374e-03,  1.99007e-02,  1.68466e-01,  2.99832e-03,\n",
       "         5.68942e-02,  7.66381e-02,  4.45666e-02,  3.82370e-02,\n",
       "        -1.11740e-02, -8.80965e-02,  4.97729e-02, -1.46604e-02,\n",
       "        -1.15158e-01,  1.90036e-02,  3.04072e-02,  6.49703e-02,\n",
       "         4.37025e-02,  3.88053e-02,  5.89422e-02, -2.12063e-02,\n",
       "        -4.16331e-02,  2.49725e-02, -5.82677e-02,  2.53572e-02,\n",
       "         6.13200e-02,  1.19394e-02, -5.27798e-02, -6.35324e-02,\n",
       "         2.88467e-02, -3.39057e-03, -6.01059e-03, -1.95996e-02,\n",
       "         6.41502e-03,  5.33391e-03,  8.84526e-02, -1.08013e-02,\n",
       "        -5.66191e-02,  1.03226e-02, -8.65905e-02,  3.72689e-02,\n",
       "        -1.29472e-02,  8.46220e-02,  1.06331e-02, -4.78748e-02,\n",
       "         1.19283e-01,  1.00593e-02,  2.72755e-03,  2.63797e-02,\n",
       "        -4.68448e-02,  6.17010e-02, -5.60327e-02,  1.19687e-01,\n",
       "        -9.62425e-03,  3.53185e-03, -2.22863e-02,  6.51363e-03,\n",
       "         3.23621e-02, -9.52764e-03, -5.02307e-02,  7.98034e-02,\n",
       "         2.08846e-03, -4.15436e-02,  8.10685e-03, -4.44589e-02,\n",
       "         4.43981e-02, -4.35216e-02,  1.58937e-03, -6.70697e-02,\n",
       "         3.97000e-02,  6.54061e-02, -6.52010e-02, -2.11168e-02,\n",
       "         1.59863e-02,  5.05605e-03, -7.05339e-02, -1.62171e-02,\n",
       "         7.61338e-02,  5.53869e-02,  3.24302e-02,  3.72336e-03,\n",
       "         9.87594e-03,  2.36435e-03,  3.12691e-02, -7.91619e-02,\n",
       "         1.52360e-01,  4.10492e-03,  8.07990e-02, -4.39103e-02,\n",
       "         5.78747e-02, -1.38671e-01,  8.60468e-02, -8.56607e-02,\n",
       "        -6.58962e-02, -6.49632e-02, -5.25596e-02,  7.83016e-02,\n",
       "        -3.84108e-02,  7.18918e-02, -5.10645e-02,  2.32292e-02,\n",
       "         1.97401e-04,  1.26950e-01,  6.75484e-03, -5.20481e-02,\n",
       "        -1.88592e-02, -3.57111e-03, -1.19281e-02,  6.33002e-02,\n",
       "         6.52198e-02, -3.81000e-02,  2.63588e-02, -1.48531e-02,\n",
       "        -5.36481e-02, -5.09464e-02,  1.01337e-01,  4.10296e-02,\n",
       "        -4.81609e-02, -1.63182e-02,  5.81358e-02, -2.91860e-02,\n",
       "        -2.43891e-03,  1.40473e-03,  6.44598e-02,  2.83255e-02,\n",
       "        -8.25466e-03,  8.23674e-02, -1.43977e-02, -1.62593e-02,\n",
       "        -7.14029e-02, -1.53584e-01,  1.24829e-02,  8.10526e-02,\n",
       "        -1.32480e-02, -2.19202e-02, -3.33890e-02, -5.17274e-02,\n",
       "         2.71507e-02,  2.93288e-03, -3.50671e-02,  7.90755e-02,\n",
       "        -1.17760e-03, -1.05809e-02,  6.67572e-04, -3.49603e-02,\n",
       "        -2.16520e-02, -5.60609e-02, -5.98333e-02,  1.79138e-02,\n",
       "         1.19164e-02,  2.25472e-02, -2.79691e-02, -3.09232e-02,\n",
       "        -3.95385e-02,  1.51340e-02, -4.39960e-02,  6.71833e-02,\n",
       "         7.66361e-02,  5.51129e-02,  9.75112e-02,  1.48166e-03,\n",
       "         3.31221e-02,  9.64643e-03,  1.86310e-02,  6.33286e-02,\n",
       "        -1.36109e-01,  8.20169e-02,  9.21054e-03,  1.60656e-02,\n",
       "         5.10844e-02,  9.76559e-02,  9.16371e-02, -4.55483e-02,\n",
       "         2.94492e-02,  6.14011e-02,  1.01276e-01, -3.13911e-02]),\n",
       " array([ 5.06639e-02,  3.51545e-02, -1.72116e-02,  4.90008e-02,\n",
       "        -5.61541e-02, -1.95074e-03, -2.26514e-02, -8.54570e-02,\n",
       "         1.18764e-01,  7.50615e-02,  2.44487e-02, -4.96470e-02,\n",
       "         1.78333e-02, -3.05367e-02, -4.41866e-02, -1.10240e-01,\n",
       "        -3.66929e-03, -1.01048e-02,  4.64581e-02,  9.54881e-03,\n",
       "        -9.03416e-02, -2.46514e-02, -5.31538e-02, -1.16700e-01,\n",
       "        -3.24617e-02, -5.70935e-02,  4.91086e-02, -6.10294e-02,\n",
       "        -4.83233e-02,  3.78509e-02, -2.80704e-02,  4.79077e-02,\n",
       "        -4.80485e-02,  1.74171e-01,  3.03310e-03, -8.32110e-03,\n",
       "        -2.08241e-02,  3.01372e-02, -6.14373e-02, -1.59208e-02,\n",
       "         9.87305e-02, -5.43245e-02,  1.13139e-02,  1.62914e-03,\n",
       "         1.09684e-01,  1.44995e-02, -2.71101e-02,  6.86425e-02,\n",
       "         3.31672e-02,  7.71765e-03, -5.28601e-02,  1.58113e-02,\n",
       "        -4.52209e-02,  8.12087e-03, -6.15416e-02, -1.60739e-03,\n",
       "        -3.28031e-02,  6.00029e-02, -1.32618e-01,  1.84791e-02,\n",
       "        -6.13270e-02, -9.81455e-02,  1.63738e-01, -2.68178e-02,\n",
       "         7.13800e-03,  8.44223e-02, -1.10156e-01, -8.13834e-02,\n",
       "        -2.62382e-02,  7.28268e-02, -6.46987e-02, -4.39197e-02,\n",
       "         5.28250e-02, -6.28713e-02, -5.95652e-02, -1.08243e-02,\n",
       "         2.02630e-02,  8.85479e-02, -2.82036e-02,  2.67400e-02,\n",
       "        -9.39535e-02,  7.41650e-02, -4.00800e-02,  6.20551e-02,\n",
       "        -5.44354e-02,  7.24982e-03,  1.57011e-02,  6.35107e-02,\n",
       "         3.76603e-02, -2.37490e-02,  7.57646e-02, -5.60904e-02,\n",
       "         1.17774e-01, -1.43053e-01, -3.98919e-02,  2.24638e-02,\n",
       "         2.88057e-03,  1.56023e-02,  3.97524e-02,  2.92548e-02,\n",
       "        -1.28463e-03, -2.60976e-02, -1.66314e-02, -6.80013e-02,\n",
       "        -5.29937e-02, -8.01559e-02, -4.21559e-02,  5.07077e-02,\n",
       "        -1.69675e-02,  3.24617e-02,  2.03459e-02, -2.01030e-02,\n",
       "        -7.51108e-04, -8.54002e-02, -7.74710e-03,  1.13282e-01,\n",
       "         1.31092e-02, -3.20639e-03,  4.02273e-02, -5.28829e-05,\n",
       "         1.08341e-01,  1.38829e-01, -1.00378e-02,  8.64733e-02,\n",
       "         6.72027e-02,  2.09736e-02,  1.28579e-01,  3.60784e-02,\n",
       "         3.74157e-02,  4.06414e-02, -5.55545e-02,  9.06850e-03,\n",
       "         1.15776e-02, -9.64091e-02,  1.39126e-02, -2.84838e-02,\n",
       "        -1.43360e-01,  6.09753e-02, -1.50370e-02,  7.67117e-02,\n",
       "         5.25658e-02,  6.76763e-02,  2.17504e-02,  5.93470e-02,\n",
       "        -5.95657e-02,  3.58530e-02,  2.06852e-03, -4.51787e-02,\n",
       "        -6.12259e-03,  6.59637e-02, -7.29639e-03, -7.53552e-02,\n",
       "        -1.64408e-02,  2.14520e-02, -7.59684e-03, -5.85019e-02,\n",
       "         2.44365e-03, -2.94765e-02,  9.62679e-02, -5.59233e-02,\n",
       "        -1.09607e-01,  1.49053e-02, -5.74633e-02,  3.04183e-02,\n",
       "         5.81765e-02,  6.43265e-02, -4.91318e-02, -1.08690e-01,\n",
       "         8.93755e-02,  3.35349e-02, -4.08477e-02,  5.38290e-02,\n",
       "        -4.37978e-02,  8.57264e-03, -1.30830e-02,  1.04625e-01,\n",
       "        -4.60908e-02,  2.83378e-02, -6.89865e-02, -2.19377e-04,\n",
       "         1.53397e-02,  5.52688e-03, -1.52708e-03,  2.07117e-02,\n",
       "         1.34272e-02, -1.13965e-02,  3.52270e-03, -4.23256e-02,\n",
       "         7.81302e-02,  1.29738e-02, -6.30284e-02, -1.27704e-01,\n",
       "         1.81310e-02,  3.95726e-02, -2.24731e-02,  9.89337e-03,\n",
       "         4.23292e-02,  3.52878e-02, -2.08285e-02, -5.30357e-04,\n",
       "         3.37618e-02,  8.41326e-03, -6.44665e-03,  7.08737e-02,\n",
       "         7.27029e-02, -3.24000e-02,  1.01043e-01, -5.25747e-02,\n",
       "         1.05499e-01,  8.71627e-02,  7.35984e-02,  1.44997e-02,\n",
       "         1.98570e-02, -1.63303e-01,  4.17292e-03, -8.53099e-02,\n",
       "        -5.63976e-02, -8.03943e-02, -1.80613e-02,  3.13514e-02,\n",
       "        -2.48563e-02,  3.73000e-02, -2.05695e-02,  5.76105e-03,\n",
       "        -1.26634e-02,  7.71866e-02, -3.23741e-02, -3.55345e-02,\n",
       "        -5.35878e-03, -2.33479e-04, -7.63921e-02, -3.68241e-03,\n",
       "         6.19323e-02, -9.86021e-02, -4.96702e-02, -2.24195e-02,\n",
       "        -5.64212e-02, -4.22981e-02,  1.13693e-01,  8.35384e-02,\n",
       "        -3.44819e-03, -1.82955e-02,  7.83823e-02, -4.71734e-03,\n",
       "         3.33519e-02,  6.67594e-02,  6.42443e-02, -5.03742e-02,\n",
       "        -1.57173e-02,  3.62424e-03,  3.86348e-03,  6.95063e-02,\n",
       "         8.29881e-03, -1.03556e-01,  2.32788e-02,  7.56806e-02,\n",
       "         6.59514e-03, -6.93405e-02, -8.28003e-02, -1.67787e-02,\n",
       "         2.62263e-02,  3.12799e-02, -4.97463e-02,  7.93526e-02,\n",
       "        -2.26655e-02, -5.53956e-02,  1.31497e-02,  1.74196e-02,\n",
       "         1.87578e-02, -3.75544e-02,  9.93731e-03,  5.60459e-03,\n",
       "        -1.40699e-02, -2.96563e-02, -2.27298e-02, -4.78809e-03,\n",
       "        -1.25713e-02,  7.13526e-02, -7.36246e-02,  4.20485e-02,\n",
       "         6.45219e-02, -2.92198e-02,  1.06517e-01,  4.67114e-02,\n",
       "         4.31401e-02,  7.45433e-03,  6.98040e-03,  1.03313e-02,\n",
       "        -1.36248e-01,  4.15097e-02, -3.17651e-03, -2.62903e-02,\n",
       "        -1.25590e-03,  5.45185e-02,  9.63007e-02, -2.23261e-02,\n",
       "         4.30278e-02,  1.48748e-01,  2.67267e-02, -2.41632e-02]),\n",
       " array([-1.45149e-02, -1.02484e-03,  1.66544e-02,  5.45401e-02,\n",
       "        -6.59519e-02,  2.20652e-02,  8.04801e-02, -7.96661e-02,\n",
       "         1.57467e-01,  2.71761e-02, -7.48160e-02,  3.39822e-02,\n",
       "         8.48446e-02,  5.43711e-02,  4.40767e-02, -5.00020e-02,\n",
       "        -1.94037e-02, -2.29295e-02,  9.81181e-02,  5.23720e-02,\n",
       "         7.98471e-02,  4.44829e-02, -4.56021e-02,  5.56758e-02,\n",
       "        -1.00021e-01, -2.70402e-02,  1.69570e-02, -5.78499e-02,\n",
       "         1.67950e-02,  9.10012e-02, -1.88776e-02, -8.71465e-03,\n",
       "        -5.98318e-02,  8.06487e-02, -1.34024e-02, -2.88645e-04,\n",
       "         7.65601e-02,  7.85991e-03,  2.33129e-03, -9.07627e-02,\n",
       "         1.54979e-02, -2.83320e-02,  4.06172e-02,  9.56886e-03,\n",
       "         8.19235e-03,  6.54062e-02,  6.28040e-03,  5.03551e-02,\n",
       "         7.61949e-02,  4.89428e-02, -1.03856e-01, -9.16371e-02,\n",
       "        -7.99343e-03, -2.52539e-02, -6.63044e-02,  3.44696e-02,\n",
       "        -1.39236e-01,  7.72840e-02, -1.50780e-01,  1.48778e-01,\n",
       "        -7.36412e-02, -9.17797e-02,  2.62485e-03,  2.82596e-02,\n",
       "        -6.03459e-02,  1.33308e-02, -1.36396e-01, -4.97034e-02,\n",
       "         2.24234e-02,  2.25778e-02, -8.59265e-02,  6.07608e-02,\n",
       "         4.93334e-02, -6.27134e-03,  2.83230e-02,  2.32769e-02,\n",
       "        -1.10320e-02, -5.59546e-02, -3.19613e-02, -7.06064e-02,\n",
       "        -2.62261e-02,  8.43764e-02, -1.70376e-02, -1.49871e-02,\n",
       "        -4.06517e-02,  9.34445e-04, -5.95511e-02,  5.76042e-02,\n",
       "         2.14187e-02,  5.66595e-02,  2.02109e-02, -1.17467e-01,\n",
       "         1.41329e-01, -3.60299e-02, -4.37796e-03,  2.42763e-04,\n",
       "         7.23186e-02,  1.39115e-01,  1.47979e-02, -3.19381e-02,\n",
       "        -9.21281e-03,  9.74826e-03,  6.11477e-02, -6.05432e-02,\n",
       "        -1.34419e-02, -2.35638e-02,  1.05027e-02,  3.07388e-02,\n",
       "        -3.48267e-02, -5.81678e-02,  2.31954e-02,  1.62780e-02,\n",
       "         2.59365e-02,  4.08984e-02,  4.14497e-02,  1.89808e-02,\n",
       "         2.81041e-02,  2.25050e-02, -2.15431e-02,  1.34188e-02,\n",
       "         9.29458e-02,  3.31671e-02, -1.01033e-01, -1.13857e-03,\n",
       "         2.06263e-02,  1.24724e-02,  4.86118e-02,  6.71889e-02,\n",
       "         4.07508e-02,  5.60038e-02, -6.88548e-02, -1.18180e-02,\n",
       "         5.65603e-02,  4.14788e-02, -7.71282e-02, -2.92178e-02,\n",
       "        -6.49089e-02,  1.25462e-01, -1.26339e-01,  5.92824e-02,\n",
       "         2.73104e-02,  1.55280e-01, -1.67160e-03,  1.08814e-02,\n",
       "        -2.87983e-02,  6.37293e-02, -1.14477e-02,  3.55594e-02,\n",
       "         1.20575e-02,  6.04203e-02,  8.48220e-03, -7.58882e-02,\n",
       "        -4.95817e-02, -5.64681e-02,  6.17376e-02, -3.74693e-02,\n",
       "         1.10050e-02, -4.41903e-03,  1.51311e-01, -3.16726e-02,\n",
       "         3.32260e-02,  1.30231e-01, -7.87400e-02, -1.81794e-02,\n",
       "         9.54101e-02, -4.97050e-02, -8.12485e-02, -6.67753e-02,\n",
       "         8.45913e-02,  7.69229e-03,  3.74035e-02, -4.92837e-02,\n",
       "        -5.27530e-02,  5.33360e-02,  2.07233e-02,  1.14456e-01,\n",
       "         3.61022e-02, -1.93527e-02, -3.66755e-02, -7.39308e-02,\n",
       "         4.57123e-02,  4.55896e-02,  8.09685e-02,  4.56105e-02,\n",
       "         4.11090e-02, -1.64197e-02,  2.75248e-02,  3.49009e-02,\n",
       "         2.78560e-02, -4.74268e-02,  1.35502e-02, -1.15499e-01,\n",
       "        -8.41894e-03,  4.78448e-02, -2.13594e-02, -2.56751e-03,\n",
       "         3.44335e-02, -1.30060e-02, -4.49897e-02,  2.13935e-02,\n",
       "        -4.70295e-02, -5.94120e-02,  9.91991e-03,  5.37030e-02,\n",
       "        -1.22312e-02, -1.17353e-01,  2.43422e-02,  8.06247e-02,\n",
       "         1.06162e-02,  3.87850e-02,  4.44531e-02,  1.17590e-02,\n",
       "         5.60597e-02,  9.84971e-03,  4.82152e-03, -4.67562e-02,\n",
       "        -1.50936e-02, -1.00321e-01, -3.25221e-03, -1.15457e-01,\n",
       "         1.70986e-02,  2.57401e-02, -9.35990e-03,  3.52242e-03,\n",
       "         9.55270e-02, -2.53567e-02,  4.04730e-02,  1.85210e-02,\n",
       "         6.75292e-02, -1.07852e-02, -4.57778e-02, -5.25566e-03,\n",
       "        -7.50793e-02,  1.43048e-02, -5.03429e-02, -7.97208e-03,\n",
       "        -1.70874e-02, -1.83257e-02,  3.08286e-02,  2.35908e-02,\n",
       "        -1.49029e-02, -2.38039e-02, -2.43170e-02, -6.22756e-02,\n",
       "        -4.57801e-02,  8.95844e-04,  3.42121e-02, -1.63239e-02,\n",
       "        -1.25472e-01, -1.66726e-02,  4.64639e-02, -1.08679e-01,\n",
       "         3.95257e-03, -2.78912e-02, -4.57646e-02,  4.41037e-02,\n",
       "        -1.72766e-03, -1.14058e-01,  1.32231e-01, -1.61015e-02,\n",
       "        -5.41933e-02,  8.55130e-03,  2.95111e-02, -4.76199e-02,\n",
       "        -2.78625e-02, -3.65077e-03, -1.77172e-02, -2.63726e-02,\n",
       "        -2.07855e-02,  7.18116e-02, -9.95113e-02, -2.20499e-02,\n",
       "         5.91532e-02, -1.24723e-02, -9.26359e-03,  4.12587e-02,\n",
       "        -8.56169e-02,  3.58751e-02, -1.17259e-02, -3.52120e-02,\n",
       "         3.13515e-02,  4.68045e-02,  1.60298e-03,  4.15578e-02,\n",
       "         3.48901e-02, -2.06222e-02, -8.50170e-03, -4.78051e-02,\n",
       "        -1.64668e-01, -8.97333e-03, -9.18687e-02,  3.02070e-02,\n",
       "         2.15352e-02,  3.41029e-02,  1.38671e-02, -5.92730e-05,\n",
       "        -5.45802e-02,  1.46233e-01, -7.58124e-03,  8.97579e-02]),\n",
       " array([-7.79861e-02,  5.62002e-02, -9.71401e-02,  9.58111e-02,\n",
       "        -2.89896e-02,  1.45427e-02,  1.70061e-02, -5.86086e-02,\n",
       "         2.83498e-02,  1.06415e-01, -5.53694e-02, -1.94813e-03,\n",
       "        -1.15082e-02, -2.92685e-02,  3.93780e-03, -3.73420e-02,\n",
       "         4.56125e-03, -4.17890e-02,  5.60937e-02,  4.69255e-02,\n",
       "        -9.13729e-03,  5.03681e-02, -8.13857e-02, -8.64576e-02,\n",
       "        -2.07285e-02,  3.79294e-02,  4.53725e-02,  6.33542e-03,\n",
       "        -1.87458e-02,  3.27134e-03,  3.23657e-02,  8.15668e-03,\n",
       "        -9.49695e-02,  1.13810e-01,  5.55207e-02, -4.31335e-02,\n",
       "        -1.54663e-05, -6.75404e-02, -2.42444e-02, -2.85526e-02,\n",
       "         9.43362e-03, -6.89981e-03,  1.66153e-02, -4.63186e-02,\n",
       "         4.46358e-02,  1.58789e-02, -1.44248e-02, -1.74158e-02,\n",
       "        -7.47614e-03,  3.17949e-02, -7.13151e-03, -5.84201e-02,\n",
       "        -1.14309e-02, -2.14194e-03, -1.12280e-01,  6.12300e-02,\n",
       "        -8.24661e-02,  3.99843e-02, -2.72330e-02,  7.64572e-02,\n",
       "        -1.40576e-02, -4.00754e-02,  1.40307e-01, -2.88416e-02,\n",
       "         2.55960e-02, -1.72521e-01, -3.52256e-02,  5.15859e-02,\n",
       "        -4.40070e-05, -6.57019e-02, -8.52368e-02, -4.69866e-03,\n",
       "         4.01250e-02, -9.14225e-02, -3.61024e-02, -2.58251e-02,\n",
       "         1.09517e-01,  8.62608e-02, -8.24553e-03, -1.66521e-02,\n",
       "        -3.61474e-03, -1.68239e-02, -9.32827e-02,  1.39092e-01,\n",
       "        -1.00156e-01,  6.63562e-02, -4.59072e-02,  5.07040e-02,\n",
       "        -6.90417e-03, -5.87215e-02,  1.86099e-02, -2.90164e-02,\n",
       "         1.33590e-01, -5.24948e-02, -2.19642e-02, -3.32867e-03,\n",
       "         7.95541e-02,  3.51353e-02, -6.96477e-02, -5.98430e-03,\n",
       "        -2.66399e-02, -4.79162e-02,  8.41928e-02, -6.31016e-02,\n",
       "        -8.68744e-02, -6.38961e-02, -6.25791e-02, -4.05733e-02,\n",
       "         5.34910e-02,  5.15218e-02, -6.64324e-02, -2.36603e-02,\n",
       "        -7.90118e-02,  4.48312e-02,  3.51970e-02, -8.65198e-02,\n",
       "         9.17913e-02,  1.70669e-02, -4.92874e-03,  2.44914e-02,\n",
       "         3.33950e-02,  7.77811e-02, -7.56919e-03,  1.69449e-01,\n",
       "         2.31342e-02, -1.28908e-02,  1.04059e-01,  6.82447e-02,\n",
       "         1.83012e-03,  5.92796e-02, -1.91490e-02,  1.01126e-02,\n",
       "        -5.67803e-03, -4.96949e-02, -7.25160e-04,  2.46958e-02,\n",
       "        -5.02863e-02, -3.82723e-03,  4.36871e-02,  3.66315e-02,\n",
       "         6.27649e-02,  6.32623e-02,  6.12826e-02,  5.92330e-03,\n",
       "         6.35951e-03,  3.85186e-02, -5.17281e-03, -2.98599e-02,\n",
       "        -2.65386e-03, -2.56916e-02, -4.00155e-02, -6.24956e-02,\n",
       "        -4.96724e-02, -1.58152e-02, -1.23355e-01, -7.48534e-02,\n",
       "        -1.00706e-02,  1.60754e-02,  5.85005e-02,  2.10211e-02,\n",
       "        -1.40451e-01,  4.97936e-02, -8.46201e-02,  1.83006e-02,\n",
       "         6.54350e-02,  1.34306e-02, -1.37118e-02, -3.63482e-02,\n",
       "         7.45670e-02, -3.59028e-03, -1.14035e-02, -8.31078e-02,\n",
       "        -7.97626e-02, -1.92161e-02, -8.85300e-02,  5.76611e-02,\n",
       "         1.49030e-03,  9.62130e-02, -1.61124e-02, -1.10346e-02,\n",
       "         3.58864e-02, -2.55794e-02, -1.94805e-02,  8.86011e-02,\n",
       "        -2.30095e-02,  3.34365e-02,  7.17982e-03, -2.12396e-02,\n",
       "         1.08764e-01, -9.67721e-02, -3.61476e-03, -1.10495e-01,\n",
       "         1.14925e-01,  5.17796e-02, -5.51306e-02, -2.07196e-02,\n",
       "         4.03894e-02,  2.83077e-02, -1.01052e-01, -1.74902e-02,\n",
       "         6.44571e-02, -7.16935e-03,  4.51776e-02,  6.36702e-02,\n",
       "        -1.46765e-02, -3.59880e-02,  2.70456e-04, -1.57972e-02,\n",
       "         3.12791e-02,  6.90376e-02,  1.15332e-01,  1.66758e-02,\n",
       "         6.82377e-02, -3.89868e-02,  9.62961e-02, -8.81751e-02,\n",
       "        -2.27500e-02, -1.33085e-01,  1.92521e-02,  2.45998e-02,\n",
       "        -1.04819e-01, -4.64295e-02,  4.10936e-02,  3.35072e-02,\n",
       "        -4.14949e-02,  7.29692e-02, -8.82659e-02, -1.19149e-02,\n",
       "        -4.99857e-02,  2.93377e-02,  6.15505e-02,  2.38430e-02,\n",
       "         5.24166e-04, -4.61290e-03,  6.69583e-03,  6.29295e-02,\n",
       "         3.22005e-02, -2.19506e-02,  6.83101e-02,  8.03716e-03,\n",
       "        -2.66812e-02, -7.88751e-02,  5.23538e-02, -3.90189e-02,\n",
       "        -1.58019e-02,  9.50034e-02,  8.11645e-02,  1.97635e-02,\n",
       "        -3.80693e-02,  7.98781e-03,  4.50445e-02,  2.43707e-02,\n",
       "        -5.49182e-02, -8.20355e-02, -2.52825e-02,  1.78598e-02,\n",
       "         2.99414e-02, -9.76698e-03, -1.72116e-02, -4.55680e-02,\n",
       "         7.48529e-03, -4.55389e-03, -1.88243e-02, -1.49911e-01,\n",
       "        -5.81523e-02, -8.31710e-02, -7.82598e-02,  2.66712e-02,\n",
       "        -3.91344e-02, -1.66636e-02, -1.05156e-01,  1.38302e-02,\n",
       "         1.19813e-01,  5.61659e-02, -1.04100e-01, -2.68826e-02,\n",
       "         7.36408e-02,  4.82920e-02,  3.89078e-02, -2.96122e-02,\n",
       "         2.80777e-02, -6.02691e-02, -7.92899e-03, -7.98268e-02,\n",
       "        -1.07382e-02, -2.96062e-02, -2.16863e-02,  1.18015e-01,\n",
       "        -3.47410e-02,  6.73221e-02,  7.81357e-02,  7.37526e-02,\n",
       "         5.12087e-02, -3.01762e-02, -1.38025e-04, -5.77903e-02,\n",
       "        -2.45552e-02,  1.08747e-01,  2.63406e-02, -3.66666e-02]),\n",
       " array([-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000]),\n",
       " array([-4.76275e-02,  1.52930e-02, -7.20562e-02,  3.43132e-02,\n",
       "         2.64238e-02, -5.72672e-02, -1.86296e-02, -6.06774e-02,\n",
       "         4.36499e-02,  8.10681e-02,  8.30189e-02,  1.11014e-01,\n",
       "        -7.59932e-02,  1.47395e-02,  3.31617e-02, -4.92764e-02,\n",
       "         1.76887e-02, -5.63145e-02,  6.73713e-02, -2.26583e-02,\n",
       "         3.40394e-02,  1.89890e-02, -8.44151e-02,  2.04331e-02,\n",
       "        -7.98518e-02, -1.89941e-04,  2.33052e-02,  5.37036e-02,\n",
       "        -5.04000e-02,  5.05641e-02,  5.08684e-02,  1.46257e-02,\n",
       "        -5.18763e-02,  7.31642e-02,  3.03229e-02, -2.52469e-02,\n",
       "        -4.37542e-02, -1.50480e-02,  8.77192e-02, -5.21505e-03,\n",
       "         7.03394e-02, -6.63338e-02, -3.36324e-02, -2.16498e-03,\n",
       "        -9.44184e-03, -4.92117e-02, -7.66679e-03,  1.94474e-02,\n",
       "         8.18215e-02, -3.81533e-02, -3.30941e-02,  6.83968e-03,\n",
       "        -1.39430e-02,  5.50888e-02, -3.95280e-02, -7.25445e-03,\n",
       "         3.27242e-02,  9.52931e-02, -1.96388e-02,  1.30921e-01,\n",
       "        -2.22426e-02, -4.79497e-02,  7.20281e-02,  6.06254e-02,\n",
       "         6.39470e-02,  8.37730e-02, -9.88109e-03, -1.25330e-02,\n",
       "        -3.49013e-02, -4.37991e-02,  1.05438e-02,  5.25871e-02,\n",
       "        -5.25357e-02, -5.18008e-02, -9.27087e-02,  2.82922e-02,\n",
       "        -5.68183e-03,  1.43438e-02,  7.74868e-02, -1.02011e-01,\n",
       "         2.01401e-02, -8.05841e-02, -3.01672e-02,  9.40913e-02,\n",
       "        -9.97251e-02, -4.08886e-02, -8.12277e-02,  1.08341e-01,\n",
       "        -4.78650e-02,  4.46639e-02, -6.01430e-02, -4.79478e-02,\n",
       "        -3.49952e-02, -6.82947e-02,  2.91615e-02,  3.82580e-02,\n",
       "         5.75031e-02, -4.79802e-02,  9.36936e-02,  1.79722e-02,\n",
       "         2.60703e-02,  5.11896e-02, -4.64824e-03, -4.05111e-02,\n",
       "        -6.65712e-02, -2.46431e-05, -2.58399e-02,  3.39064e-02,\n",
       "        -4.70687e-02,  1.63032e-02,  3.87676e-02,  5.43268e-02,\n",
       "         4.55366e-02,  8.24277e-03,  1.16575e-01,  5.79831e-02,\n",
       "         9.95281e-04,  8.50691e-02,  1.39606e-02,  4.76305e-02,\n",
       "         5.43172e-02,  4.43730e-02,  2.00538e-02,  1.52662e-03,\n",
       "         4.50391e-02,  1.84774e-02,  5.35687e-02,  1.21640e-02,\n",
       "         5.69029e-02,  4.48686e-02, -3.82131e-02, -1.23433e-02,\n",
       "        -2.33673e-02, -2.03949e-02, -1.40231e-02, -3.22497e-02,\n",
       "        -3.33869e-02,  5.45677e-02,  8.42175e-02,  4.62839e-02,\n",
       "         3.27319e-02,  3.18545e-02, -4.03616e-03, -1.29110e-02,\n",
       "         7.79521e-02,  4.89449e-02, -6.40844e-02, -3.67416e-03,\n",
       "        -3.51120e-02,  7.57879e-02,  4.35912e-02, -4.19333e-02,\n",
       "         3.82787e-03,  6.66215e-02,  1.03921e-02, -2.97068e-02,\n",
       "        -7.38362e-02,  8.87766e-03,  7.14671e-02, -1.37145e-03,\n",
       "        -1.14903e-02,  1.62239e-01,  3.88279e-02,  4.06200e-02,\n",
       "         4.80163e-02,  3.19223e-02, -9.09064e-02, -8.23108e-03,\n",
       "         4.91875e-02,  5.95819e-02, -1.10063e-01,  1.28370e-02,\n",
       "        -6.66931e-02,  1.00633e-01, -3.93374e-02,  8.74029e-02,\n",
       "        -3.59972e-02, -6.62451e-02, -8.32130e-02, -4.87935e-02,\n",
       "         5.87787e-02,  4.82972e-02,  3.77324e-03, -8.55950e-03,\n",
       "        -3.25664e-02,  8.61994e-02, -2.15792e-02,  5.29274e-02,\n",
       "         5.15150e-02, -1.06615e-01,  2.51177e-03, -5.10408e-02,\n",
       "        -3.34238e-02,  3.84657e-02, -5.23143e-02,  2.33364e-02,\n",
       "        -5.26496e-02, -4.59715e-02, -2.07377e-02, -2.35089e-02,\n",
       "        -6.48145e-02, -9.28441e-02,  7.27243e-02,  5.59336e-02,\n",
       "         4.14555e-02, -6.69222e-02, -4.75037e-02,  1.08271e-02,\n",
       "         9.65062e-02,  1.07651e-01,  1.45364e-01, -3.08972e-02,\n",
       "        -4.44963e-02, -9.30169e-02,  5.13567e-02,  3.19955e-02,\n",
       "        -1.30451e-01, -3.31182e-03, -9.90804e-02,  5.10875e-02,\n",
       "         5.76700e-02,  1.39682e-02, -4.18186e-02,  8.02980e-03,\n",
       "        -1.18846e-02,  9.41179e-03,  3.15923e-02,  3.80309e-02,\n",
       "        -9.35257e-02,  3.00722e-02, -1.62251e-01, -5.78238e-02,\n",
       "        -5.38612e-03, -3.67886e-02,  1.02983e-02, -6.81867e-03,\n",
       "        -1.98975e-02,  2.98260e-02, -3.81477e-02,  3.29496e-02,\n",
       "        -1.43590e-02, -2.16959e-02, -1.13817e-02,  7.66861e-02,\n",
       "        -8.72365e-02, -2.82974e-03, -1.48523e-02, -4.15522e-02,\n",
       "         8.74797e-02,  1.61771e-02,  1.48880e-02,  1.56076e-02,\n",
       "        -5.07441e-02, -2.41693e-02, -4.88351e-03, -4.03686e-02,\n",
       "        -6.82286e-03, -1.14735e-01, -2.81491e-02, -3.26299e-02,\n",
       "         1.05455e-02,  2.61924e-04, -1.82259e-02, -1.16185e-02,\n",
       "        -1.93590e-01,  1.11779e-01,  3.87919e-02,  2.83245e-02,\n",
       "         5.56808e-02, -1.02547e-02,  1.03567e-02,  1.13772e-02,\n",
       "         2.98408e-02,  5.23679e-02, -1.64570e-02,  1.47820e-02,\n",
       "         8.80707e-02,  2.75594e-02,  1.17242e-01,  9.12558e-02,\n",
       "         7.16955e-02,  6.10029e-02,  4.99869e-02, -1.44714e-02,\n",
       "         6.79538e-02,  4.91654e-02,  5.16527e-02, -2.00179e-02,\n",
       "        -6.36170e-02,  6.42310e-02,  4.38914e-02,  9.46702e-02,\n",
       "        -6.50964e-02,  1.09850e-01,  6.03706e-02,  1.35814e-01,\n",
       "        -2.07339e-01, -1.05115e-02,  4.71221e-02, -2.31838e-02]),\n",
       " array([ 5.93703e-02, -8.23614e-03,  1.25724e-02,  1.04206e-02,\n",
       "        -1.06029e-01,  3.31596e-02,  3.92384e-02, -7.25999e-02,\n",
       "         4.18946e-02,  1.12320e-02,  1.18884e-01,  4.77529e-02,\n",
       "         9.99194e-02, -4.57685e-02, -4.29797e-02, -3.03740e-02,\n",
       "        -3.02159e-02, -4.99049e-02,  3.21392e-02,  7.20440e-02,\n",
       "        -3.14767e-02,  4.65233e-02, -8.85024e-02,  2.39733e-03,\n",
       "        -9.50015e-02, -8.39402e-02,  3.48846e-02, -3.01440e-02,\n",
       "         6.87039e-02,  3.53690e-02, -7.65971e-02,  2.60387e-02,\n",
       "        -4.66535e-02,  8.15324e-02,  1.19116e-02, -9.22773e-02,\n",
       "        -5.61304e-02,  5.20656e-02,  4.33121e-02, -3.37296e-02,\n",
       "         8.07516e-02, -2.45031e-02, -6.29561e-02,  2.56891e-02,\n",
       "         3.34454e-02, -3.06222e-02, -3.17929e-02, -2.79233e-02,\n",
       "         1.73655e-02,  2.19516e-02, -3.87564e-02, -3.50658e-02,\n",
       "        -2.64751e-02,  3.12516e-02, -9.49532e-02,  5.31793e-03,\n",
       "         5.47126e-03,  1.40046e-01, -2.88941e-02,  4.86202e-02,\n",
       "         3.16100e-02, -5.37357e-02,  1.19796e-01, -1.04224e-01,\n",
       "        -1.48216e-02, -3.85903e-02, -4.58301e-02,  3.98419e-02,\n",
       "        -5.44116e-02,  5.28281e-02, -3.71492e-02, -4.16987e-02,\n",
       "        -3.05256e-02, -7.15566e-02, -1.01811e-02, -9.85939e-03,\n",
       "         9.58943e-02,  5.80387e-02, -6.22956e-02, -7.98401e-02,\n",
       "        -6.75864e-02,  3.43650e-02, -9.98982e-03,  3.21380e-02,\n",
       "        -7.34427e-02, -9.60905e-02, -2.13422e-02, -5.65326e-03,\n",
       "        -6.09756e-02, -6.56718e-02, -5.56507e-02, -1.63566e-03,\n",
       "         1.32416e-01, -1.17633e-01,  4.88639e-02, -1.85981e-02,\n",
       "         1.16791e-02,  7.90807e-02, -3.86718e-02, -4.31223e-02,\n",
       "        -2.77305e-02, -7.69208e-02,  1.02612e-01,  2.70612e-02,\n",
       "        -9.48461e-02,  2.56878e-02, -4.35042e-02,  7.98789e-02,\n",
       "        -8.78595e-04,  5.83333e-02,  3.02717e-02,  4.03076e-02,\n",
       "        -9.42490e-02, -1.11875e-01, -1.97074e-02, -1.43211e-02,\n",
       "         6.76037e-02,  2.11212e-02,  6.47414e-02,  5.39242e-02,\n",
       "         1.60103e-01, -9.92821e-03, -1.16975e-01,  1.02688e-01,\n",
       "         4.22544e-03, -8.76037e-02,  7.13194e-02,  8.37858e-03,\n",
       "         1.73126e-02,  1.28038e-02, -2.11256e-02, -1.77963e-02,\n",
       "         2.06081e-03, -5.12115e-02, -1.15467e-01,  4.17123e-02,\n",
       "        -6.16765e-02,  4.09972e-02,  3.63565e-02,  3.73364e-02,\n",
       "        -2.64921e-02, -4.13151e-04,  2.80382e-02, -1.08209e-02,\n",
       "         6.81437e-02,  4.41157e-02,  7.40287e-02, -1.18755e-02,\n",
       "         4.99462e-03,  4.44295e-02,  6.82108e-03, -7.88854e-02,\n",
       "        -6.58730e-02,  2.17203e-02, -6.50937e-02, -7.00934e-02,\n",
       "         6.88244e-02, -3.65770e-02,  2.92733e-02, -1.15578e-02,\n",
       "        -1.15738e-01,  1.66322e-01, -1.10888e-01,  7.22851e-02,\n",
       "         1.17418e-01,  3.17706e-02, -5.27339e-02, -4.66545e-02,\n",
       "         5.51681e-02, -6.28608e-02, -6.76695e-02,  1.46766e-02,\n",
       "        -5.42282e-02, -4.42398e-02, -3.55522e-02,  4.68148e-02,\n",
       "         3.64113e-02,  9.78591e-02, -2.60077e-02, -7.68734e-03,\n",
       "         1.10006e-02, -7.33826e-04,  1.80670e-02,  2.45586e-02,\n",
       "        -5.75760e-02,  8.16615e-02,  3.27911e-03,  3.78793e-02,\n",
       "        -3.39295e-02, -5.49992e-02, -1.18500e-02, -4.18820e-02,\n",
       "         2.58741e-02,  6.36598e-02, -3.29093e-02, -5.51456e-02,\n",
       "         4.79695e-02,  2.01635e-02, -6.65540e-02, -1.79167e-01,\n",
       "         3.92647e-02,  4.65685e-02,  2.77729e-03,  1.16757e-01,\n",
       "         9.96997e-03, -4.10601e-02, -5.34282e-02,  9.96497e-02,\n",
       "         5.99499e-02,  6.91056e-02,  7.97024e-02, -3.42076e-02,\n",
       "         3.80957e-02, -1.65890e-02,  2.34134e-02, -1.37438e-02,\n",
       "        -2.77555e-02, -5.57454e-02, -1.08323e-01, -3.53732e-03,\n",
       "         2.50567e-02, -4.28714e-02, -4.50561e-02,  4.70258e-02,\n",
       "        -5.48192e-02,  3.73012e-02, -1.16715e-01, -3.15441e-02,\n",
       "         2.70062e-02,  1.78295e-02,  6.38043e-02,  3.81724e-02,\n",
       "        -6.03035e-02,  1.46881e-02,  3.27101e-03, -2.41275e-02,\n",
       "         3.46776e-02,  1.79342e-03, -1.50441e-03, -9.56516e-03,\n",
       "        -2.77920e-02, -3.89625e-03,  7.51280e-02,  4.72732e-02,\n",
       "         7.97865e-02,  4.71279e-02,  3.23393e-02,  1.69546e-02,\n",
       "        -2.48567e-04,  8.26828e-02,  3.69235e-02,  1.60436e-02,\n",
       "         1.23256e-02, -2.99948e-02, -1.66883e-01, -2.69289e-02,\n",
       "        -1.22087e-01, -1.95556e-02,  2.65346e-02,  6.88055e-02,\n",
       "         8.38076e-02,  3.13109e-02,  2.01557e-02, -1.70589e-02,\n",
       "         1.44787e-03, -2.47592e-02, -2.15433e-02, -3.43564e-02,\n",
       "        -7.20099e-05,  2.25618e-02, -4.10453e-02,  5.60966e-02,\n",
       "         1.73715e-02,  2.44119e-03, -7.35663e-02, -1.05415e-01,\n",
       "         7.41295e-02,  3.05693e-02,  3.43922e-03,  2.51228e-02,\n",
       "         3.18108e-03,  3.66205e-02,  9.14709e-03,  6.51331e-03,\n",
       "         6.48089e-02,  1.43353e-02, -2.35723e-02,  5.49330e-02,\n",
       "        -8.70140e-02, -1.33022e-02,  1.30418e-02, -1.62589e-01,\n",
       "         2.41024e-02,  5.34708e-02,  1.09282e-02,  1.76320e-02,\n",
       "        -8.34898e-03,  2.16667e-02, -8.19967e-02,  4.30980e-02]),\n",
       " array([-0.0321128 ,  0.0531727 ,  0.00837402,  0.035669  ,  0.0241547 ,\n",
       "        -0.0755378 ,  0.00339066, -0.111764  ,  0.104693  ,  0.0222457 ,\n",
       "         0.0852364 ,  0.0251318 ,  0.0155212 , -0.0222755 ,  0.111551  ,\n",
       "        -0.0306784 , -0.0453605 , -0.0485651 , -0.0700929 ,  0.093216  ,\n",
       "        -0.0723939 , -0.0395903 , -0.0605412 , -0.0258691 , -0.0612524 ,\n",
       "        -0.0425422 ,  0.024502  , -0.091563  , -0.081156  ,  0.0794374 ,\n",
       "         0.0263966 ,  0.0809848 ,  0.012158  ,  0.0148134 ,  0.0449639 ,\n",
       "        -0.0371871 , -0.0230767 ,  0.00568025, -0.0531717 ,  0.00191568,\n",
       "        -0.030481  , -0.0704075 , -0.067134  ,  0.0973077 , -0.0145502 ,\n",
       "        -0.010579  ,  0.0462761 ,  0.0343319 , -0.0273343 , -0.0224835 ,\n",
       "         0.0717751 , -0.0418379 , -0.0332078 , -0.0343869 ,  0.042958  ,\n",
       "         0.0753464 , -0.12095   ,  0.0466216 ,  0.0635502 , -0.0155374 ,\n",
       "        -0.00237858,  0.044671  ,  0.0512629 , -0.0367094 , -0.0312416 ,\n",
       "         0.0114422 , -0.066093  ,  0.054836  ,  0.00529385,  0.0576512 ,\n",
       "        -0.0973158 ,  0.0292233 ,  0.0474868 ,  0.0352987 , -0.00189024,\n",
       "        -0.035013  , -0.0544448 ,  0.0642451 ,  0.0215499 , -0.0344489 ,\n",
       "         0.0162373 ,  0.00841494, -0.0569578 , -0.00635237, -0.00349194,\n",
       "         0.0299996 ,  0.0796909 ,  0.122796  ,  0.0873642 , -0.0123772 ,\n",
       "         0.0103404 , -0.0473763 , -0.136756  , -0.0623768 ,  0.0429421 ,\n",
       "        -0.045915  ,  0.0039839 ,  0.0204059 ,  0.00811792, -0.0144244 ,\n",
       "        -0.0606512 , -0.00246652, -0.0660914 ,  0.0760141 , -0.107611  ,\n",
       "        -0.0190771 ,  0.0264029 ,  0.110227  , -0.0617195 , -0.062933  ,\n",
       "        -0.0476963 ,  0.0164852 ,  0.0450783 ,  0.0183199 , -0.0156629 ,\n",
       "         0.0156749 ,  0.0106489 ,  0.0177233 , -0.00961189,  0.0174538 ,\n",
       "         0.0440724 ,  0.0317279 ,  0.0361372 , -0.0229465 ,  0.0512167 ,\n",
       "        -0.0309247 , -0.0291691 ,  0.00319408, -0.0163294 ,  0.0189631 ,\n",
       "        -0.0490315 ,  0.034829  , -0.017785  ,  0.0353753 , -0.0611313 ,\n",
       "         0.0342775 ,  0.0556812 , -0.168819  , -0.0457279 , -0.0274366 ,\n",
       "        -0.056011  ,  0.157024  ,  0.0497279 , -0.0494543 ,  0.00100125,\n",
       "         0.0535995 , -0.0983453 , -0.03844   , -0.0495594 ,  0.0292744 ,\n",
       "        -0.00945701, -0.10277   , -0.045574  , -0.0799365 , -0.0045256 ,\n",
       "         0.036471  ,  0.0337637 , -0.00540193,  0.0532008 ,  0.113381  ,\n",
       "         0.0608962 , -0.00411199, -0.132793  ,  0.0246173 ,  0.135554  ,\n",
       "         0.0529968 , -0.0437722 , -0.0264691 ,  0.0885298 ,  0.00196543,\n",
       "        -0.0553432 , -0.0776909 , -0.0395648 , -0.00360257,  0.0838801 ,\n",
       "         0.0269991 ,  0.0532221 , -0.0507458 ,  0.0201929 ,  0.0147608 ,\n",
       "        -0.058942  ,  0.0221263 , -0.0180555 , -0.023193  ,  0.00578951,\n",
       "         0.0423287 , -0.0303615 , -0.0467005 ,  0.0395263 , -0.0644037 ,\n",
       "         0.100164  , -0.0707869 ,  0.120576  ,  0.0355233 , -0.0670168 ,\n",
       "        -0.040616  ,  0.0433878 ,  0.129372  , -0.0790798 ,  0.00107717,\n",
       "         0.00240323,  0.0309703 , -0.00347201,  0.0135131 ,  0.200083  ,\n",
       "        -0.0171327 , -0.0769557 ,  0.0709618 ,  0.00133963,  0.0265369 ,\n",
       "         0.0487479 , -0.0123321 , -0.00277219, -0.0359258 ,  0.00314516,\n",
       "        -0.0286434 , -0.0161908 , -0.0661665 , -0.0150566 ,  0.0384164 ,\n",
       "        -0.0146115 , -0.0698656 ,  0.0594989 ,  0.0139607 ,  0.0172883 ,\n",
       "        -0.00258729, -0.153985  , -0.0253881 , -0.0105787 , -0.0423425 ,\n",
       "         0.0523251 ,  0.0696549 , -0.0264644 , -0.0776442 , -0.0114329 ,\n",
       "        -0.0918418 ,  0.0401375 , -0.039436  , -0.0387243 ,  0.0335715 ,\n",
       "        -0.0302158 , -0.00537829,  0.0233803 ,  0.00087315, -0.0681162 ,\n",
       "        -0.0167349 ,  0.0290751 , -0.048698  , -0.0477224 , -0.0361035 ,\n",
       "         0.0305599 ,  0.0317075 , -0.0468011 , -0.0764188 ,  0.103788  ,\n",
       "        -0.033316  ,  0.0236705 , -0.087733  ,  0.0496979 ,  0.0197205 ,\n",
       "         0.077438  ,  0.108644  ,  0.00662751, -0.0328036 , -0.0788613 ,\n",
       "        -0.0982033 , -0.0767976 ,  0.0885678 , -0.105451  , -0.0931682 ,\n",
       "        -0.130019  , -0.0941523 ,  0.0224652 ,  0.0605447 , -0.0925631 ,\n",
       "        -0.0636557 , -0.00387757,  0.0338975 , -0.0603093 ,  0.0245245 ,\n",
       "         0.107697  ,  0.0185428 ,  0.00655772,  0.0310062 ,  0.0538976 ,\n",
       "         0.0633804 ,  0.0161858 , -0.00629673, -0.121556  ,  0.0212824 ,\n",
       "        -0.0412904 , -0.0828665 ,  0.067985  ,  0.0135653 , -0.0727501 ,\n",
       "        -0.0176313 , -0.0535065 , -0.0338084 , -0.00724238, -0.0712966 ]),\n",
       " array([ 7.42186e-02, -3.99519e-02, -3.55676e-02,  6.32581e-02,\n",
       "        -8.57187e-02, -5.75726e-02,  6.72467e-02, -4.09222e-02,\n",
       "        -7.25616e-03,  2.45057e-02,  7.91388e-02,  4.55080e-02,\n",
       "        -4.14478e-02, -1.09513e-01, -8.90765e-02, -3.58511e-02,\n",
       "        -3.99071e-02, -2.02112e-03,  2.26697e-03,  4.42483e-02,\n",
       "        -5.29093e-02, -5.09586e-03, -1.90505e-02, -2.41264e-03,\n",
       "        -6.22980e-02,  2.33528e-02, -4.68997e-03, -6.84089e-02,\n",
       "        -8.05197e-02, -7.78127e-02,  2.29107e-02,  1.25919e-01,\n",
       "        -9.87879e-03, -1.92380e-03,  6.05563e-02, -5.04714e-02,\n",
       "         7.08705e-02,  5.14678e-03,  4.50893e-02, -1.28361e-02,\n",
       "         1.00671e-01, -3.00243e-02,  3.06174e-04, -7.07956e-02,\n",
       "         3.51528e-02,  1.11369e-01, -1.29941e-02,  1.49297e-02,\n",
       "         4.59211e-02, -2.89894e-02, -8.87688e-03, -9.01082e-02,\n",
       "         7.38079e-02, -4.33620e-02,  1.04931e-03,  1.30294e-01,\n",
       "        -3.44464e-02,  6.87446e-03, -5.38998e-02,  8.21454e-02,\n",
       "        -1.43846e-02, -5.00843e-02,  1.14836e-01, -1.90293e-02,\n",
       "        -1.19670e-01,  4.15580e-02, -1.14147e-01, -7.41623e-02,\n",
       "        -3.88545e-02,  3.03295e-02, -4.75039e-02,  7.76429e-02,\n",
       "        -6.14829e-02,  8.27547e-06, -1.17349e-01,  1.19069e-03,\n",
       "         1.27841e-01,  6.30679e-02,  2.89123e-02, -6.60568e-03,\n",
       "        -4.94929e-02,  1.81019e-03, -8.19237e-02,  4.59258e-02,\n",
       "        -8.92771e-02,  2.70389e-02, -1.74357e-02,  1.35366e-02,\n",
       "         8.18534e-02,  2.15450e-03, -1.10614e-02, -4.03443e-02,\n",
       "         2.41361e-02, -2.57671e-02,  6.26621e-02,  2.74669e-02,\n",
       "         7.34805e-02, -4.24774e-02,  1.79940e-02, -2.07692e-02,\n",
       "         1.03549e-01,  6.59191e-03,  3.34592e-02, -6.25619e-02,\n",
       "        -1.07110e-01,  5.42250e-03, -1.85295e-02,  4.31981e-02,\n",
       "        -3.63420e-02,  5.13320e-02, -6.63509e-02, -3.46159e-02,\n",
       "        -1.07006e-01,  4.35259e-02,  4.98661e-02, -4.37931e-02,\n",
       "        -2.29327e-02,  4.30191e-02, -6.14505e-02, -4.34744e-03,\n",
       "         3.31651e-02,  6.87212e-02, -1.14358e-01,  2.70199e-02,\n",
       "        -3.05290e-03,  4.88899e-02,  5.33588e-02,  4.68423e-03,\n",
       "         9.12848e-02,  7.03965e-02, -2.46898e-02,  3.09304e-02,\n",
       "        -2.54310e-03,  8.75169e-02,  2.80409e-02,  3.92655e-02,\n",
       "        -1.16042e-02,  4.21772e-03, -2.08075e-02,  1.38389e-01,\n",
       "         7.04664e-02,  4.37591e-02, -2.47163e-02, -9.92983e-03,\n",
       "         7.51676e-02, -2.81702e-02, -7.36680e-02, -3.05249e-02,\n",
       "         9.14448e-02, -2.89355e-02,  2.26742e-02, -1.25482e-01,\n",
       "        -2.31124e-02,  8.84266e-03,  2.34595e-02,  3.53255e-02,\n",
       "        -2.08888e-02,  7.89511e-03,  1.12857e-01,  3.64542e-02,\n",
       "         2.09608e-03,  7.90343e-02, -1.15982e-01,  2.29676e-02,\n",
       "         7.54786e-02,  2.70382e-03, -7.30909e-02, -1.16013e-02,\n",
       "         9.03425e-02,  4.18730e-02, -8.21908e-02,  3.00684e-02,\n",
       "        -4.52271e-03,  3.03470e-02,  2.70525e-02,  1.13632e-01,\n",
       "         5.02729e-02, -6.22651e-03,  9.47530e-03,  9.08427e-03,\n",
       "         3.81384e-02, -2.16254e-02, -4.26558e-02, -7.92465e-04,\n",
       "        -3.67153e-03,  3.52429e-02, -2.02684e-02, -7.11142e-02,\n",
       "         5.33979e-02, -1.54329e-02, -6.79615e-02,  3.54092e-02,\n",
       "        -2.83786e-03,  8.14589e-02, -7.04938e-02, -1.28374e-01,\n",
       "        -6.19569e-02,  3.22164e-02,  2.36027e-02, -3.18986e-02,\n",
       "        -2.74574e-02,  1.79298e-02, -4.26216e-02, -4.31861e-03,\n",
       "         3.33266e-02, -3.16055e-02,  3.59534e-02,  1.33807e-01,\n",
       "        -9.06335e-02,  5.91596e-02,  4.29983e-02,  3.02389e-02,\n",
       "        -1.92052e-03,  7.53577e-02,  6.64337e-02, -4.46954e-02,\n",
       "         3.14656e-03, -9.90855e-02, -5.47354e-02, -2.69177e-02,\n",
       "         4.34779e-02,  2.99203e-02,  7.78640e-02, -2.14784e-02,\n",
       "        -6.20002e-03,  6.42624e-02, -3.82703e-02,  4.11276e-03,\n",
       "         6.38008e-02,  7.36385e-03, -7.22979e-02,  1.07437e-02,\n",
       "         8.71048e-03,  5.46808e-02, -9.70427e-02,  7.50105e-02,\n",
       "        -3.57854e-02, -2.69720e-02,  7.04628e-02, -1.17807e-02,\n",
       "        -2.67443e-02, -1.38694e-03,  2.18454e-02, -1.03742e-02,\n",
       "        -2.90915e-02,  1.40720e-01, -1.94919e-02, -4.31255e-03,\n",
       "         9.71026e-02, -2.22355e-02, -4.74783e-02,  8.30390e-02,\n",
       "        -1.07963e-01, -6.83432e-02,  1.81645e-01,  2.73559e-03,\n",
       "         3.61794e-02, -5.62101e-02, -2.26264e-02,  7.67747e-04,\n",
       "         1.56252e-02,  1.42833e-02,  6.02295e-02,  1.73874e-02,\n",
       "        -1.17093e-01, -3.77438e-02, -1.28907e-02,  8.32916e-02,\n",
       "         4.16259e-02, -4.50361e-02, -2.06583e-02,  9.77698e-02,\n",
       "        -3.70354e-02,  1.71585e-02,  1.36969e-02, -5.23222e-02,\n",
       "         4.12038e-02,  2.46872e-02,  4.08466e-02, -1.28803e-02,\n",
       "        -2.66282e-02,  4.42661e-02,  4.96648e-02, -4.23666e-03,\n",
       "         3.40414e-02,  5.60387e-02,  2.49886e-02,  1.47139e-02,\n",
       "        -1.04076e-01,  1.05669e-01,  1.66050e-02, -1.53710e-02,\n",
       "        -1.79387e-02,  7.60246e-02,  7.23674e-02,  1.37000e-01,\n",
       "         4.56519e-02,  3.52493e-04,  1.32471e-01, -6.34017e-02]),\n",
       " array([ 0.00975112,  0.119637  , -0.0942776 , -0.0464149 , -0.0405434 ,\n",
       "         0.0475084 ,  0.0341872 ,  0.0266829 , -0.0355644 ,  0.148003  ,\n",
       "         0.0681747 , -0.0877465 , -0.0283309 , -0.056195  ,  0.0114812 ,\n",
       "         0.0438521 , -0.0808381 ,  0.00349589, -0.0155833 ,  0.0698691 ,\n",
       "        -0.00705903,  0.0350561 , -0.0915204 , -0.00819792,  0.00479954,\n",
       "        -0.0177702 , -0.00994384, -0.108691  ,  0.008076  , -0.0209999 ,\n",
       "         0.00426352,  0.0702555 , -0.0877146 ,  0.0910797 , -0.0147118 ,\n",
       "        -0.11022   ,  0.0349289 , -0.0851626 ,  0.00283883,  0.0750625 ,\n",
       "         0.0730617 , -0.0312385 , -0.0256113 , -0.0315099 ,  0.0347672 ,\n",
       "         0.0652587 ,  0.0988442 ,  0.0823979 ,  0.0689653 , -0.158082  ,\n",
       "        -0.00817641, -0.0464158 ,  0.0574543 , -0.0144348 , -0.0958095 ,\n",
       "         0.02447   ,  0.0374128 , -0.0076234 , -0.0600084 ,  0.023464  ,\n",
       "         0.01985   , -0.0847562 ,  0.0872168 ,  0.00823615,  0.0127491 ,\n",
       "         0.0181383 , -0.126212  , -0.0121579 , -0.0223335 ,  0.00148263,\n",
       "        -0.0563427 ,  0.0144894 ,  0.0832793 , -0.177106  , -0.0517708 ,\n",
       "        -0.0542267 ,  0.123522  ,  0.0595698 ,  0.00219836,  0.0156276 ,\n",
       "         0.0353615 ,  0.0186483 , -0.0429712 , -0.00473874, -0.034195  ,\n",
       "         0.028294  ,  0.046897  ,  0.0644226 ,  0.106598  , -0.00026571,\n",
       "        -0.00815025,  0.00438235,  0.109577  , -0.0406536 , -0.0719481 ,\n",
       "         0.0736738 ,  0.0275263 , -0.0491297 ,  0.00337114, -0.107607  ,\n",
       "        -0.0425055 ,  0.0382756 ,  0.0650691 , -0.00754835, -0.078798  ,\n",
       "         0.00483923, -0.0186827 ,  0.0460076 ,  0.0578245 ,  0.0159246 ,\n",
       "        -0.0178582 , -0.0492316 ,  0.00614735, -0.0202196 , -0.00607911,\n",
       "        -0.007078  ,  0.0671585 ,  0.0297627 , -0.0805695 , -0.0156748 ,\n",
       "        -0.00812021,  0.0745784 ,  0.0481133 ,  0.06913   ,  0.0675901 ,\n",
       "        -0.085362  ,  0.0251587 ,  0.0119791 ,  0.0171626 ,  0.0727988 ,\n",
       "        -0.0318013 , -0.0016124 , -0.0352005 ,  0.0177587 ,  0.0282304 ,\n",
       "         0.116075  , -0.032585  , -0.0285519 , -0.0775812 ,  0.0595998 ,\n",
       "        -0.0182417 ,  0.0426937 ,  0.00515793, -0.00357626,  0.0414304 ,\n",
       "         0.0729902 ,  0.0148321 , -0.0238366 ,  0.0554372 ,  0.0469339 ,\n",
       "         0.0147837 , -0.0850903 , -0.00783743, -0.0524577 , -0.0337407 ,\n",
       "        -0.114862  , -0.0686778 , -0.0705654 ,  0.0488455 , -0.0265024 ,\n",
       "        -0.0491378 ,  0.0351447 ,  0.00272222,  0.00390732,  0.118423  ,\n",
       "        -0.0300674 , -0.0802817 , -0.0535262 ,  0.0989052 ,  0.0356557 ,\n",
       "        -0.170423  ,  0.052     , -0.0317037 ,  0.0409809 ,  0.0316994 ,\n",
       "         0.123209  , -0.0334113 ,  0.018638  , -0.0682869 , -0.103262  ,\n",
       "         0.0487244 , -0.0872005 ,  0.0222187 ,  0.0167851 , -0.0115659 ,\n",
       "         0.0435872 , -0.0102539 , -0.0080929 ,  0.123839  ,  0.0290373 ,\n",
       "        -0.106611  , -0.0402306 ,  0.130107  ,  0.049695  , -0.0533811 ,\n",
       "         0.0382213 , -0.0161471 , -0.0145961 , -0.134773  ,  0.00497049,\n",
       "        -0.0465312 , -0.134493  , -0.0337239 ,  0.0264446 ,  0.0396196 ,\n",
       "        -0.0369539 , -0.030764  ,  0.0156583 ,  0.0837196 ,  0.0425554 ,\n",
       "         0.0781432 , -0.0137224 , -0.126679  ,  0.0223628 ,  0.00073405,\n",
       "        -0.0578896 , -0.0650061 , -0.0938807 ,  0.0639242 ,  0.098554  ,\n",
       "        -0.103743  ,  0.0103537 , -0.0303705 ,  0.0311502 ,  0.033287  ,\n",
       "         0.0248492 , -0.0539245 , -0.0914327 , -0.0064936 , -0.0358289 ,\n",
       "         0.0876889 ,  0.0103675 , -0.036118  , -0.00805633,  0.00622018,\n",
       "         0.0584753 , -0.00209006,  0.0444164 ,  0.0114529 , -0.00076925,\n",
       "        -0.00021932,  0.0145257 ,  0.0398693 ,  0.0228918 ,  0.0262819 ,\n",
       "         0.00346863,  0.0301739 , -0.0421571 ,  0.00913725,  0.029883  ,\n",
       "         0.0490262 ,  0.0254422 , -0.137204  ,  0.0251723 , -0.0342355 ,\n",
       "        -0.12476   , -0.0847641 , -0.00615219, -0.0313119 ,  0.00693453,\n",
       "         0.0421954 , -0.0459513 , -0.0218726 ,  0.0107243 , -0.0536707 ,\n",
       "         0.00755717,  0.0235506 ,  0.0299614 ,  0.0114588 ,  0.0290584 ,\n",
       "        -0.0248488 , -0.0276563 ,  0.0396026 ,  0.0581892 , -0.088952  ,\n",
       "         0.0239154 ,  0.0350618 , -0.0199812 ,  0.0510433 , -0.0699488 ,\n",
       "        -0.0057464 , -0.0381105 , -0.0695138 , -0.00149769,  0.0505493 ,\n",
       "        -0.0167692 ,  0.050989  ,  0.0461348 , -0.00064027,  0.00910974,\n",
       "        -0.0185248 , -0.0104393 ,  0.0772929 ,  0.044558  ,  0.105982  ,\n",
       "        -0.105275  , -0.0124132 ,  0.00745753, -0.020058  ,  0.0512259 ]),\n",
       " array([-5.32839e-02,  1.22943e-02,  2.82871e-03,  4.14429e-02,\n",
       "        -3.45682e-03, -4.19058e-03,  5.16534e-02, -6.38747e-02,\n",
       "         1.52649e-02,  1.14597e-01, -4.50997e-02, -5.84489e-02,\n",
       "        -2.93236e-02, -1.22344e-01,  2.76032e-02, -8.24311e-02,\n",
       "        -3.45318e-03,  6.41649e-02,  6.27238e-02,  4.42568e-02,\n",
       "        -5.36898e-02,  5.36541e-02, -2.99472e-02, -6.78686e-02,\n",
       "         3.75509e-02,  3.56274e-03,  8.95571e-02, -3.58683e-02,\n",
       "         6.17538e-02,  5.82185e-02, -9.88697e-02,  2.91362e-04,\n",
       "        -2.60870e-02,  4.56498e-02, -4.38833e-03,  3.99678e-02,\n",
       "        -3.00383e-02,  2.54811e-02, -2.41434e-02, -6.58481e-02,\n",
       "         1.47692e-02,  5.03914e-02, -2.44268e-02,  6.20545e-02,\n",
       "        -1.66100e-02,  7.35517e-02,  1.46108e-02,  6.68918e-03,\n",
       "        -7.80636e-03,  1.49448e-02,  3.21820e-02, -9.53428e-02,\n",
       "         4.45238e-02, -3.40022e-02, -6.86636e-02,  2.62837e-02,\n",
       "        -3.82610e-02,  1.26272e-01, -5.53971e-02, -4.18271e-02,\n",
       "        -6.74391e-02, -2.74805e-02, -2.88687e-02,  4.33886e-02,\n",
       "        -1.70748e-02, -3.68676e-02, -1.24632e-01,  5.07900e-02,\n",
       "         7.21572e-03, -3.03086e-02, -5.65166e-02,  4.62843e-02,\n",
       "        -3.34028e-02, -1.48895e-01, -3.41844e-02,  6.20344e-02,\n",
       "         1.64980e-02,  7.77481e-02,  4.26234e-02, -3.22135e-02,\n",
       "         9.23376e-02, -3.41617e-03,  6.51790e-03, -5.81890e-02,\n",
       "        -1.02483e-01, -5.21000e-02, -6.17613e-03,  6.95333e-02,\n",
       "        -4.18402e-02, -8.96351e-02,  4.35159e-02, -5.24945e-02,\n",
       "        -9.83628e-03, -1.26235e-01,  5.16726e-02,  6.03902e-03,\n",
       "         4.62092e-02,  2.65443e-02, -8.80627e-02,  4.86890e-02,\n",
       "         1.48254e-02, -3.97376e-02,  1.34907e-02,  5.42952e-03,\n",
       "         1.43982e-02, -1.46651e-02, -3.97836e-02,  7.13319e-02,\n",
       "         2.56959e-04, -6.15797e-02,  3.90637e-02, -6.03597e-02,\n",
       "        -1.07751e-01, -2.13905e-02,  6.42940e-02, -3.63153e-02,\n",
       "         5.11669e-02,  2.85279e-02,  6.12440e-02,  6.14422e-02,\n",
       "        -5.44502e-03,  7.11403e-02, -3.31415e-02,  1.70708e-01,\n",
       "        -2.49453e-02, -7.56328e-02,  3.67717e-02, -1.46315e-02,\n",
       "         5.43321e-02,  6.67754e-02, -1.17399e-01,  3.63728e-02,\n",
       "        -6.47725e-02,  7.44467e-02,  5.23504e-02,  6.68294e-02,\n",
       "         1.01253e-02,  3.64639e-02, -5.21325e-02, -1.94713e-03,\n",
       "        -6.14523e-02, -8.36606e-03,  5.49363e-02, -6.82056e-02,\n",
       "        -8.88826e-04,  3.44454e-02, -1.26720e-01, -7.32606e-02,\n",
       "        -3.08040e-02, -9.26787e-02, -3.22493e-02, -1.36695e-01,\n",
       "        -2.21647e-02,  2.49564e-02, -6.85250e-02,  4.61721e-03,\n",
       "        -9.40877e-03,  6.84528e-02,  1.29694e-01,  2.54703e-02,\n",
       "         5.72185e-03,  6.53495e-02, -7.48387e-02, -2.30166e-02,\n",
       "         3.53412e-02, -5.20402e-03,  1.16569e-01, -5.20254e-02,\n",
       "         6.66886e-02,  6.66048e-02,  2.00788e-02, -3.15001e-02,\n",
       "        -2.59575e-02,  1.35727e-02, -4.57037e-02, -9.14719e-03,\n",
       "        -2.55739e-02,  5.27274e-03, -7.74486e-02, -9.14176e-03,\n",
       "        -1.95673e-02, -9.76599e-02,  2.16771e-02,  7.46828e-02,\n",
       "         6.23082e-02,  1.03542e-01, -3.13203e-03, -1.47710e-02,\n",
       "         1.10516e-02,  1.93540e-02, -1.03478e-01, -1.27316e-01,\n",
       "         7.42987e-03,  1.43451e-01,  3.18039e-02, -5.80820e-02,\n",
       "        -8.59710e-02, -7.06953e-03, -5.75368e-02,  2.50681e-02,\n",
       "         6.08272e-04, -2.89748e-03, -4.80106e-02, -3.94650e-02,\n",
       "        -6.09947e-03,  2.36285e-02, -3.48279e-02,  5.07513e-02,\n",
       "         1.43327e-01,  6.86903e-03,  1.02313e-01, -4.54839e-02,\n",
       "         6.23244e-02,  4.23789e-02,  6.56222e-02, -9.68610e-02,\n",
       "         9.03359e-03, -4.12298e-02,  4.46349e-02,  4.76966e-02,\n",
       "         3.70631e-04, -3.56535e-02, -5.90525e-02, -7.50062e-02,\n",
       "        -8.67182e-02,  2.63097e-02, -2.36400e-02, -3.81280e-02,\n",
       "        -3.22963e-02, -2.45757e-02,  3.29080e-03,  3.37676e-02,\n",
       "        -5.92516e-02,  9.79013e-02, -1.70979e-02,  5.66094e-02,\n",
       "        -1.99555e-02, -7.99753e-02, -7.75542e-02,  4.50042e-02,\n",
       "         4.83781e-02,  7.91694e-02,  4.45620e-02,  3.93436e-02,\n",
       "        -1.68560e-02,  5.10286e-03,  1.99926e-02, -6.45602e-02,\n",
       "        -5.60635e-02,  9.91678e-05, -4.57895e-02, -4.29313e-04,\n",
       "        -1.24842e-01,  3.84757e-02,  3.39905e-02,  9.96313e-03,\n",
       "        -7.46876e-02, -3.85377e-02,  1.54955e-03, -3.60589e-02,\n",
       "        -1.70437e-02,  3.59034e-02, -1.36326e-02,  2.50654e-02,\n",
       "        -1.34411e-01,  2.41645e-02, -7.15937e-02,  1.03407e-01,\n",
       "         3.26537e-03,  1.58246e-03, -8.08880e-02,  1.05040e-01,\n",
       "        -2.69130e-02, -1.20338e-02, -1.17888e-01, -1.55223e-01,\n",
       "         4.89592e-02,  6.47612e-02, -2.47531e-02, -3.06638e-02,\n",
       "         3.81441e-02,  3.25771e-02, -3.85044e-02, -6.52258e-02,\n",
       "        -4.66174e-02, -6.87587e-02,  3.27270e-02,  9.37118e-02,\n",
       "        -5.72961e-02,  6.91191e-02,  4.18407e-02,  2.95088e-02,\n",
       "         9.52899e-03, -2.92386e-03,  3.33590e-02, -1.56023e-02,\n",
       "        -5.69650e-02, -3.56416e-02,  5.28706e-02, -1.80918e-02]),\n",
       " array([-5.12788e-02, -4.81153e-02,  2.56433e-02,  5.49389e-03,\n",
       "        -1.35755e-01,  5.00081e-02,  7.58046e-03, -3.27040e-02,\n",
       "         1.45394e-01, -2.23281e-03, -4.78347e-02, -4.52802e-02,\n",
       "        -6.85475e-03,  4.25302e-02,  6.31074e-02,  8.88147e-03,\n",
       "         5.45719e-02, -6.39777e-02,  5.06178e-02,  1.46603e-01,\n",
       "         2.47173e-02,  9.85926e-02, -2.61023e-02, -2.49854e-02,\n",
       "        -4.71673e-02, -3.99848e-02, -1.53346e-02, -6.11324e-02,\n",
       "         1.61748e-02,  6.88753e-02, -1.06421e-02,  6.76308e-02,\n",
       "        -9.21598e-02,  9.35296e-02, -2.21703e-02, -7.89017e-02,\n",
       "         8.67821e-02, -3.85648e-02, -1.38924e-02, -6.72232e-02,\n",
       "         6.90706e-02, -2.27641e-02, -3.00493e-02,  5.32328e-02,\n",
       "        -3.50711e-02,  8.93919e-02,  1.69787e-02,  5.54545e-02,\n",
       "         1.11552e-02,  6.75378e-02, -1.11073e-01, -4.54214e-02,\n",
       "        -6.62127e-03,  5.29771e-02, -6.77127e-02,  1.11407e-02,\n",
       "        -9.04197e-02,  3.74612e-02, -1.45046e-01,  1.04513e-01,\n",
       "        -2.88707e-02, -7.47479e-02,  6.22128e-02, -9.24262e-02,\n",
       "        -1.14132e-01, -4.63588e-02, -6.65484e-02, -9.18961e-03,\n",
       "        -1.73161e-02, -1.07174e-02, -1.47061e-01,  2.93242e-02,\n",
       "         7.56924e-03,  2.19735e-02,  6.09682e-03, -4.81089e-02,\n",
       "        -5.74090e-03,  2.91258e-02, -7.47307e-02, -6.41281e-02,\n",
       "        -2.71432e-03, -1.68946e-02, -1.72301e-02,  1.16386e-02,\n",
       "        -2.27403e-02, -1.96676e-02, -7.09774e-02,  1.05866e-01,\n",
       "         6.60806e-02,  3.40606e-02, -8.24828e-02, -1.13455e-01,\n",
       "         1.08400e-01, -6.53115e-02,  4.85351e-02, -2.81246e-02,\n",
       "         1.01735e-01,  8.84807e-02, -7.61401e-03, -1.57805e-02,\n",
       "        -5.61659e-02, -1.19884e-02,  6.86373e-02, -2.17435e-02,\n",
       "        -9.52759e-02,  1.41165e-02, -9.64490e-03,  8.45525e-02,\n",
       "        -8.33095e-02, -1.04882e-01, -3.94063e-02, -1.91412e-03,\n",
       "         3.52521e-02,  1.95377e-02,  4.37532e-02, -1.51405e-03,\n",
       "         6.59132e-02,  5.68151e-02, -1.48311e-02, -1.55504e-02,\n",
       "         9.88236e-02,  2.03073e-03,  2.55782e-03,  3.78878e-02,\n",
       "         4.02186e-03,  6.11599e-03,  1.14180e-01,  6.82699e-02,\n",
       "        -3.83238e-03, -3.48191e-02, -7.54223e-02,  1.26191e-02,\n",
       "         3.01329e-02,  6.89827e-02, -1.37728e-01, -1.14398e-01,\n",
       "        -3.83371e-02,  6.98514e-02, -9.81183e-02,  4.83872e-02,\n",
       "         2.93645e-02,  9.32132e-02,  3.72695e-02, -1.23250e-02,\n",
       "         8.42057e-02,  4.53150e-02, -3.96128e-03,  9.97093e-02,\n",
       "         5.50939e-02,  4.54482e-02,  1.62906e-02, -2.57550e-02,\n",
       "        -4.06285e-02, -1.00749e-01, -1.22380e-03, -6.05181e-02,\n",
       "         1.68350e-02, -1.20431e-02,  9.48237e-02, -6.02588e-02,\n",
       "         6.28781e-02,  7.18480e-02, -1.14898e-01, -7.83366e-03,\n",
       "         1.17979e-01, -7.54188e-02, -8.94102e-02, -2.22427e-02,\n",
       "         1.13496e-01,  7.18814e-02,  4.71276e-03, -2.58811e-02,\n",
       "        -9.76593e-02,  4.32742e-02,  2.02423e-02,  7.80439e-02,\n",
       "         4.57150e-02, -1.57576e-02, -1.89810e-02, -9.15541e-02,\n",
       "         4.20395e-02,  4.05485e-02,  4.04333e-02,  4.84458e-02,\n",
       "         4.94855e-02,  7.54693e-02, -2.77057e-02, -5.70122e-02,\n",
       "         1.16279e-02,  4.16580e-02,  4.19208e-02, -7.20670e-02,\n",
       "         5.18171e-02,  6.85955e-03, -6.31462e-02, -1.92629e-02,\n",
       "        -4.18242e-02,  5.66501e-02, -3.74901e-03,  2.35645e-02,\n",
       "        -5.13209e-02, -3.43054e-02,  2.08764e-02,  7.19268e-02,\n",
       "        -1.84409e-02, -6.82483e-02, -1.47759e-02,  1.12363e-02,\n",
       "         2.48767e-02,  1.53417e-02,  3.76508e-02,  2.98986e-03,\n",
       "        -2.66527e-02,  2.66453e-02,  3.91446e-02,  4.95341e-02,\n",
       "         5.16311e-02, -1.60396e-03,  1.21849e-02, -7.43567e-02,\n",
       "        -2.12815e-03,  9.62851e-02,  2.73915e-02,  5.03603e-02,\n",
       "         8.68256e-02,  4.28605e-03,  1.60042e-03,  3.19002e-02,\n",
       "        -1.91990e-02, -2.77030e-02, -1.93629e-02, -5.12429e-02,\n",
       "        -8.24792e-02,  7.90695e-02, -5.07513e-02, -4.88330e-02,\n",
       "        -1.75022e-02,  7.52055e-03,  8.47089e-02,  5.64053e-02,\n",
       "         1.01309e-02, -3.66130e-02, -4.03995e-03, -3.99372e-02,\n",
       "        -4.29306e-02, -1.77207e-02,  1.12549e-02, -1.62598e-02,\n",
       "        -6.66125e-02, -7.32268e-02,  3.87247e-02, -6.03694e-02,\n",
       "         7.18044e-02,  2.49399e-02, -1.79259e-02,  6.79645e-02,\n",
       "         7.53878e-03, -8.18472e-02,  8.27171e-02, -1.35739e-02,\n",
       "         7.48341e-04,  6.19688e-02, -2.19056e-02, -3.66304e-02,\n",
       "        -4.13596e-02, -3.03003e-02,  1.96855e-02, -5.59006e-02,\n",
       "         2.26351e-02,  2.05690e-02, -5.96117e-02, -5.85458e-04,\n",
       "         2.12931e-02, -3.66175e-02, -3.45077e-02, -6.71424e-02,\n",
       "        -4.42195e-02,  1.27122e-01,  1.79554e-03, -3.42115e-02,\n",
       "        -1.69202e-02,  1.14094e-04,  6.90264e-03, -1.30242e-02,\n",
       "         3.51245e-03, -5.23316e-02,  3.52099e-02, -9.12236e-02,\n",
       "        -6.47688e-02,  1.02392e-02, -1.06165e-02,  1.51648e-02,\n",
       "        -1.40325e-02, -1.49852e-02, -5.70022e-02, -7.74510e-02,\n",
       "        -8.58341e-02,  1.54861e-01, -8.27665e-02,  8.48889e-02]),\n",
       " array([ 1.12826e-02, -6.71803e-02, -9.81728e-03,  2.94519e-02,\n",
       "         2.14481e-04,  2.46093e-03, -4.10060e-03, -6.80936e-02,\n",
       "         1.81481e-02,  6.36653e-02,  1.53175e-01, -8.39842e-02,\n",
       "         1.08310e-01, -4.91142e-02, -8.63641e-02, -2.52936e-02,\n",
       "        -4.63349e-02, -1.77916e-02, -1.41944e-02,  6.71455e-02,\n",
       "        -7.43263e-02, -2.64280e-04, -1.19757e-01, -3.80226e-03,\n",
       "        -8.99903e-02,  7.37435e-03,  8.60215e-02,  2.74930e-03,\n",
       "         7.72617e-02, -3.35144e-02, -2.87343e-02,  1.24651e-01,\n",
       "        -8.55462e-02,  9.22579e-02,  2.28850e-02, -4.10335e-02,\n",
       "         1.29951e-03, -8.38041e-02,  7.31206e-02, -3.09161e-03,\n",
       "         5.76818e-02, -6.31184e-02, -6.00970e-02,  5.65826e-02,\n",
       "         2.97152e-02, -8.49665e-02,  3.47891e-03, -4.20404e-02,\n",
       "         3.38751e-02, -1.08848e-02,  8.97108e-03,  6.13928e-02,\n",
       "         2.61734e-02,  2.40385e-02, -7.74596e-02, -9.67332e-03,\n",
       "        -4.81988e-02,  6.94957e-02, -2.42491e-02,  2.47999e-02,\n",
       "        -8.58575e-02, -1.44792e-01,  1.09740e-01, -6.76860e-02,\n",
       "        -2.35472e-02, -8.85851e-02, -1.04747e-01,  1.40180e-02,\n",
       "        -1.09704e-01, -3.88153e-02, -7.89062e-02, -4.34260e-03,\n",
       "        -2.64663e-02, -7.40495e-02, -3.81357e-02, -4.68287e-02,\n",
       "         6.76015e-02,  5.56545e-02,  1.84169e-02,  2.74827e-02,\n",
       "         1.38082e-02,  1.03230e-01, -1.29362e-01, -5.22507e-02,\n",
       "        -1.35895e-02, -2.43786e-02, -4.81230e-03,  5.98608e-02,\n",
       "         3.37631e-02, -9.52838e-02, -3.65026e-02,  6.35903e-02,\n",
       "         6.61430e-02, -1.52296e-01,  6.16991e-03,  1.25276e-03,\n",
       "        -4.11868e-03,  6.44327e-03,  8.55733e-03, -3.10041e-05,\n",
       "         4.59427e-02, -4.37032e-02,  5.08919e-02, -8.34513e-02,\n",
       "        -8.52562e-02, -3.20481e-02, -6.05096e-02,  6.43475e-02,\n",
       "         7.19748e-02,  5.05118e-02, -5.52893e-03,  1.82213e-02,\n",
       "        -1.27666e-01, -5.29908e-02,  2.07376e-03,  2.56974e-02,\n",
       "         3.01015e-02,  7.39649e-02,  9.31386e-02,  7.98150e-02,\n",
       "         1.59111e-01,  1.24996e-03, -5.33906e-02,  5.06108e-02,\n",
       "         1.35983e-02, -5.93580e-03,  6.12139e-02,  7.96099e-02,\n",
       "         5.90979e-02,  4.20495e-02, -1.55070e-02,  4.61889e-02,\n",
       "        -1.33500e-02,  1.37127e-02,  2.54036e-02,  2.98324e-02,\n",
       "        -1.19349e-01,  6.00508e-02,  3.61411e-02,  5.65306e-02,\n",
       "        -1.19154e-02,  5.46535e-02,  2.38315e-02, -1.72430e-03,\n",
       "         6.86681e-02,  1.10954e-01,  4.64012e-02,  5.15392e-02,\n",
       "        -3.75640e-02,  4.62412e-02,  1.73509e-02, -1.13720e-01,\n",
       "        -4.66487e-02, -5.74488e-03, -8.42043e-02, -7.45145e-02,\n",
       "         4.72527e-03,  1.46411e-02,  1.05348e-01,  2.14894e-02,\n",
       "        -1.03001e-01,  1.21251e-01, -7.07625e-02, -1.68155e-02,\n",
       "         1.43133e-01, -2.75236e-02,  1.11813e-02, -8.61996e-03,\n",
       "         2.09205e-02, -9.95727e-02, -1.13507e-01,  5.01579e-02,\n",
       "        -8.23312e-02,  5.71243e-02,  9.87622e-03,  7.80674e-02,\n",
       "         7.59771e-03,  6.08560e-02,  1.72756e-02,  2.03919e-04,\n",
       "         3.00639e-02, -2.90721e-04, -3.45062e-02,  2.11086e-02,\n",
       "        -3.72537e-02,  8.50139e-02, -2.33816e-02, -2.47121e-02,\n",
       "         1.00987e-02, -6.28812e-03,  9.01034e-03, -1.28976e-01,\n",
       "         1.01373e-01,  4.49848e-02, -4.76972e-02,  2.80739e-02,\n",
       "         4.35052e-02,  5.48644e-03, -4.07198e-02,  6.07765e-03,\n",
       "        -2.00559e-02, -4.93866e-02, -5.48143e-02,  3.80163e-02,\n",
       "         7.13368e-02, -2.87536e-02, -1.86328e-02,  4.65693e-02,\n",
       "         3.28530e-02,  4.01075e-02,  7.76635e-02,  2.41589e-02,\n",
       "         6.62901e-02, -6.18614e-02, -3.72497e-02, -2.46812e-02,\n",
       "         8.94799e-03, -1.09984e-01,  1.57612e-02,  8.33403e-03,\n",
       "         4.64920e-02, -5.60192e-02, -5.69775e-02,  3.63386e-02,\n",
       "        -4.23757e-02, -2.85256e-02, -4.83648e-02, -3.00164e-02,\n",
       "         2.47378e-02, -2.93548e-02,  3.72093e-02,  4.52082e-02,\n",
       "        -3.93663e-02, -6.29473e-02, -3.40207e-02,  1.05428e-02,\n",
       "        -4.55001e-02, -4.69981e-02,  3.39448e-02, -2.21930e-02,\n",
       "         2.11406e-02,  2.12142e-02,  4.87659e-02,  4.48334e-02,\n",
       "         3.49881e-02,  5.92408e-02,  5.28185e-02,  9.79846e-03,\n",
       "         6.33920e-02,  7.38819e-03,  6.49850e-03, -5.39702e-02,\n",
       "        -4.11062e-02, -2.17593e-02, -9.44857e-02,  3.32950e-02,\n",
       "        -3.89706e-02,  9.81810e-03,  6.08419e-02,  1.86545e-02,\n",
       "         2.81497e-02, -2.77385e-02,  2.91926e-02,  7.73555e-03,\n",
       "        -5.59897e-02,  3.57279e-02,  6.20732e-03,  8.01326e-02,\n",
       "         8.64837e-02, -1.90868e-02, -9.49661e-03,  1.07991e-02,\n",
       "        -3.68730e-03,  2.12485e-02, -9.54814e-02, -7.96646e-02,\n",
       "         6.99310e-02,  8.90966e-02,  1.26530e-02,  4.41189e-02,\n",
       "        -5.33279e-02, -3.70968e-03,  8.21138e-02,  9.37674e-02,\n",
       "         7.53638e-02,  1.49149e-02, -1.26574e-02,  4.34230e-02,\n",
       "        -5.22856e-02,  9.87166e-03,  2.92157e-03, -1.31351e-01,\n",
       "        -5.62856e-03,  6.39164e-02,  1.49503e-02, -5.54039e-02,\n",
       "        -2.50436e-03,  9.61082e-02, -6.43627e-02, -6.99482e-02]),\n",
       " array([-0.00848589, -0.00871167, -0.0243466 ,  0.0249751 ,  0.00259683,\n",
       "         0.0964336 , -0.0618073 , -0.0293589 , -0.0140828 ,  0.0430783 ,\n",
       "         0.0248523 , -0.0390221 , -0.0352449 , -0.0130249 , -0.0202423 ,\n",
       "        -0.0190224 ,  0.00846917,  0.0315433 ,  0.0324371 , -0.00829734,\n",
       "        -0.053322  ,  0.0173089 , -0.0166567 , -0.0627475 , -0.0467356 ,\n",
       "        -0.0201556 ,  0.0552708 ,  0.0768845 ,  0.00781277,  0.0435367 ,\n",
       "         0.0188056 ,  0.0522897 , -0.0438618 ,  0.034269  ,  0.0550036 ,\n",
       "        -0.0447232 ,  0.0714484 , -0.139098  ,  0.0598877 , -0.0648071 ,\n",
       "         0.028779  , -0.0863973 , -0.0306935 , -0.0601519 ,  0.0390078 ,\n",
       "         0.00547898,  0.0434902 , -0.129295  , -0.0132047 ,  0.00721457,\n",
       "         0.0231643 , -0.0078161 , -0.0249326 , -0.0043712 , -0.0199161 ,\n",
       "         0.0190689 ,  0.0520193 , -0.0112147 ,  0.0832396 ,  0.00654571,\n",
       "        -0.0433594 ,  0.0320938 ,  0.0455711 , -0.0753878 , -0.0269441 ,\n",
       "        -0.0337803 , -0.0527501 ,  0.0785347 , -0.0446251 ,  0.0467992 ,\n",
       "         0.00796338,  0.0849592 ,  0.00120731, -0.077846  , -0.0311476 ,\n",
       "         0.0123272 ,  0.139004  ,  0.0492573 , -0.00251494,  0.00722378,\n",
       "         0.00741315, -0.0383753 , -0.0164064 , -0.044506  , -0.0714597 ,\n",
       "         0.09118   , -0.0674888 ,  0.0193352 ,  0.0552484 , -0.062957  ,\n",
       "        -0.00123939, -0.129223  ,  0.0718042 , -0.0338209 ,  0.0385372 ,\n",
       "         0.0243732 ,  0.0181163 ,  0.01086   , -0.0384802 ,  0.0740633 ,\n",
       "         0.0482239 ,  0.0117632 , -0.0126451 ,  0.00804834, -0.00084242,\n",
       "         0.0432404 ,  0.0196788 ,  0.055087  , -0.0332412 ,  0.105958  ,\n",
       "         0.176983  , -0.105438  , -0.0299192 , -0.0127388 ,  0.0414398 ,\n",
       "        -0.172954  ,  0.0107891 ,  0.0205105 , -0.027531  ,  0.0170838 ,\n",
       "         0.107037  ,  0.00198453, -0.0255177 , -0.0115321 , -0.0161688 ,\n",
       "         0.0226569 , -0.0213659 , -0.0326465 ,  0.0850963 ,  0.0437726 ,\n",
       "         0.0704286 , -0.00092222,  0.0232888 , -0.0567987 ,  0.0649437 ,\n",
       "        -0.0527822 ,  0.0659886 , -0.0966333 ,  0.0205945 ,  0.150584  ,\n",
       "         0.079808  ,  0.131282  ,  0.119616  , -0.0418421 , -0.0316237 ,\n",
       "         0.0694269 , -0.0129698 , -0.0714004 ,  0.0613241 , -0.0130708 ,\n",
       "         0.0964394 ,  0.0166088 , -0.0348407 ,  0.0170037 , -0.0886573 ,\n",
       "        -0.10646   , -0.0948986 , -0.10784   , -0.0990779 ,  0.0435186 ,\n",
       "        -0.0286396 ,  0.0518468 ,  0.00821716,  0.0684647 , -0.00181151,\n",
       "        -0.00668698, -0.0139889 ,  0.0327539 ,  0.0738169 ,  0.011468  ,\n",
       "        -0.0721328 ,  0.0130369 ,  0.0158693 , -0.0562171 ,  0.0464715 ,\n",
       "         0.112746  ,  0.0174355 ,  0.111467  , -0.0088569 , -0.00790935,\n",
       "         0.0846495 , -0.021225  ,  0.0718905 ,  0.0129088 , -0.0325186 ,\n",
       "         0.0495115 ,  0.0224844 , -0.0561654 ,  0.0449356 ,  0.0599133 ,\n",
       "        -0.0200956 ,  0.00528727, -0.0153496 , -0.00761406, -0.0320893 ,\n",
       "        -0.0763657 ,  0.00927796,  0.033821  , -0.0541927 , -0.112905  ,\n",
       "         0.0292513 ,  0.0234207 , -0.0844325 ,  0.0783894 , -0.0351169 ,\n",
       "        -0.0784332 ,  0.116784  ,  0.0976773 ,  0.103922  ,  0.0204428 ,\n",
       "         0.180398  , -0.0298648 ,  0.0642178 ,  0.0398111 , -0.0163527 ,\n",
       "        -0.0126521 ,  0.0225838 , -0.0103159 , -0.0114246 , -0.0241818 ,\n",
       "         0.0457044 , -0.0436632 , -0.0620269 ,  0.0194529 ,  0.0740337 ,\n",
       "         0.0191338 ,  0.0605453 , -0.0830379 , -0.0140744 ,  0.0164188 ,\n",
       "         0.0471139 ,  0.110936  , -0.00821368,  0.0436946 , -0.117472  ,\n",
       "         0.0872698 , -0.0685665 ,  0.038863  , -0.0636283 , -0.00614133,\n",
       "         0.0621796 , -0.0054873 ,  0.0204998 , -0.00757365, -0.107399  ,\n",
       "         0.0103577 ,  0.0292857 , -0.044611  , -0.0408769 , -0.0100595 ,\n",
       "        -0.0180174 ,  0.0185649 , -0.0711911 , -0.00080891,  0.0289099 ,\n",
       "        -0.10346   , -0.00326083, -0.107389  ,  0.0312607 , -0.0851733 ,\n",
       "         0.104837  , -0.00435092,  0.0650458 , -0.0073794 , -0.0661051 ,\n",
       "         0.0170591 , -0.0286388 ,  0.00076672, -0.00496174, -0.00649464,\n",
       "        -0.00323052, -0.0842678 ,  0.116356  ,  0.0679023 , -0.0211743 ,\n",
       "        -0.0918418 , -0.040125  , -0.0847592 ,  0.0493211 ,  0.0709743 ,\n",
       "         0.0708452 , -0.0489089 ,  0.0731311 ,  0.0277361 ,  0.0343728 ,\n",
       "         0.104346  , -0.0661226 , -0.0616778 ,  0.0536095 , -0.0294502 ,\n",
       "         0.0216108 , -0.0115197 , -0.0727222 , -0.00921309,  0.00805407,\n",
       "         0.050963  ,  0.0235575 ,  0.0571827 , -0.0254564 ,  0.0208241 ]),\n",
       " array([-0.111545  ,  0.0397625 , -0.0532838 ,  0.050597  , -0.0402989 ,\n",
       "        -0.0328704 ,  0.00609144, -0.0413968 , -0.0369903 ,  0.0753762 ,\n",
       "        -0.0210376 ,  0.00087352,  0.02035   ,  0.0168281 ,  0.0386468 ,\n",
       "        -0.0218937 ,  0.0129076 ,  0.028146  ,  0.0315439 ,  0.018534  ,\n",
       "         0.00611114,  0.0511706 , -0.0527902 , -0.0673102 , -0.0119509 ,\n",
       "         0.0924287 ,  0.0148702 ,  0.0110683 ,  0.0291703 , -0.0224446 ,\n",
       "        -0.0465358 ,  0.0443147 ,  0.0721962 ,  0.0656685 , -0.0645476 ,\n",
       "        -0.0825763 ,  0.0121363 ,  0.0300512 , -0.0701621 , -0.0750555 ,\n",
       "         0.112275  , -0.0193585 ,  0.0254268 , -0.0354651 ,  0.0898495 ,\n",
       "         0.13475   ,  0.0443735 , -0.0103344 ,  0.00595159,  0.00159982,\n",
       "        -0.0175014 , -0.127993  , -0.00744991, -0.0056941 , -0.0488058 ,\n",
       "        -0.0104463 , -0.018068  ,  0.0127179 , -0.0875132 ,  0.0570963 ,\n",
       "        -0.0989455 ,  0.0286546 ,  0.0740471 , -0.0342674 , -0.0165782 ,\n",
       "        -0.0727628 , -0.0615152 ,  0.0134307 ,  0.0288859 , -0.0374132 ,\n",
       "        -0.00482144,  0.00159739, -0.0350918 , -0.0694247 , -0.0818261 ,\n",
       "         0.0424766 ,  0.105594  ,  0.113936  ,  0.0329865 ,  0.0490955 ,\n",
       "        -0.0225621 ,  0.0406142 , -0.0106623 ,  0.0478054 , -0.0391574 ,\n",
       "         0.0267345 , -0.049591  ,  0.0229908 , -0.0399669 , -0.0270894 ,\n",
       "        -0.0240853 , -0.0100358 ,  0.0530061 , -0.107113  ,  0.018036  ,\n",
       "         0.00780551,  0.11517   ,  0.0478671 , -0.0730743 ,  0.0227705 ,\n",
       "         0.0531999 , -0.0908297 ,  0.00585164, -0.0783891 , -0.0417199 ,\n",
       "        -0.0546178 , -0.0630835 , -0.0994743 ,  0.0780196 ,  0.0537191 ,\n",
       "        -0.0366641 ,  0.0309314 , -0.0292065 ,  0.0127599 ,  0.0433737 ,\n",
       "         0.0113862 ,  0.126547  , -0.0255134 ,  0.0206519 ,  0.00449762,\n",
       "         0.0922921 ,  0.0259201 , -0.00075788,  0.169261  , -0.00050308,\n",
       "        -0.0812318 ,  0.0388607 ,  0.0228264 ,  0.00939825,  0.0571955 ,\n",
       "        -0.0380291 , -0.00378351, -0.0462088 , -0.00563088, -0.0253536 ,\n",
       "         0.0189051 ,  0.0295108 , -0.0548414 ,  0.0497684 ,  0.00380937,\n",
       "         0.00606625,  0.00367035,  0.0275685 , -0.0483423 , -0.0145512 ,\n",
       "         0.0314456 , -0.0605697 , -0.0639768 , -0.00684171, -0.0579866 ,\n",
       "        -0.00868055, -0.0759075 , -0.0151775 ,  0.00257153, -0.0784935 ,\n",
       "         0.00804952,  0.0336608 ,  0.0650077 ,  0.0151294 ,  0.0961211 ,\n",
       "        -0.072096  ,  0.100813  , -0.055468  ,  0.0325026 , -0.0158606 ,\n",
       "         0.0375922 , -0.066254  , -0.0494904 ,  0.080431  ,  0.0719816 ,\n",
       "        -0.0640715 , -0.0504656 , -0.117639  , -0.00812913, -0.0197759 ,\n",
       "        -0.00944312, -0.019574  ,  0.00138521,  0.0568807 , -0.0257007 ,\n",
       "        -0.0084684 , -0.0881427 ,  0.0223379 ,  0.0864628 , -0.0454138 ,\n",
       "         0.0552554 ,  0.0187473 ,  0.0317578 ,  0.0714802 , -0.0541358 ,\n",
       "         0.0257375 , -0.156106  , -0.0335475 ,  0.0271117 , -0.0367458 ,\n",
       "        -0.0184206 ,  0.0104479 ,  0.0399862 , -0.158308  ,  0.0109997 ,\n",
       "         0.0290073 ,  0.0801378 ,  0.0771613 ,  0.00309198, -0.00221497,\n",
       "         0.00648951, -0.0784815 ,  0.00223002,  0.111918  , -0.00197263,\n",
       "         0.174372  , -0.0315893 ,  0.0464087 , -0.0811481 , -0.0318338 ,\n",
       "        -0.0426816 , -0.0134815 , -0.0646005 , -0.0407924 ,  0.0923427 ,\n",
       "        -0.0802848 , -0.087184  ,  0.00735226, -0.020696  , -0.00026101,\n",
       "         0.0219359 , -0.0876342 ,  0.0340361 , -0.0934039 ,  0.0208861 ,\n",
       "         0.0741992 ,  0.120344  , -0.0373807 , -0.0367709 , -0.07319   ,\n",
       "         0.0515658 ,  0.00861597, -0.0569138 , -0.0281455 , -0.0368727 ,\n",
       "         0.0557461 , -0.0133088 , -0.012274  , -0.00292502, -0.0309209 ,\n",
       "         0.0982481 ,  0.169467  ,  0.0257941 , -0.0494893 , -0.001474  ,\n",
       "         0.0216792 , -0.0369659 , -0.0434918 , -0.00169843, -0.00977396,\n",
       "        -0.00154699, -0.0605609 , -0.0680011 , -0.0766207 , -0.0202486 ,\n",
       "        -0.0179623 , -0.0514319 , -0.146735  , -0.101431  , -0.103628  ,\n",
       "        -0.00855808, -0.0111844 ,  0.0593297 , -0.00456395, -0.00987444,\n",
       "        -0.0632336 ,  0.0135288 ,  0.111425  ,  0.083418  , -0.0365033 ,\n",
       "        -0.0118003 , -0.031197  ,  0.0176431 ,  0.0396763 , -0.0642703 ,\n",
       "         0.060762  ,  0.0255193 , -0.10487   , -0.0313649 ,  0.0216312 ,\n",
       "        -0.0702411 ,  0.116516  ,  0.143552  , -0.0892077 ,  0.0425839 ,\n",
       "         0.013569  ,  0.0890763 ,  0.015173  , -0.0224001 , -0.0070148 ,\n",
       "        -0.0679431 , -0.0725815 ,  0.0195514 , -0.0338698 , -0.0335708 ]),\n",
       " array([-3.38803e-02, -4.33580e-02,  4.96198e-03, -4.45243e-02,\n",
       "         2.78129e-02, -2.06729e-02, -3.69229e-02,  4.33130e-02,\n",
       "         9.33946e-03,  3.01268e-02, -9.84228e-02,  1.86365e-02,\n",
       "        -7.59824e-02,  3.65185e-02,  6.45181e-02, -2.78896e-02,\n",
       "        -1.42439e-02,  4.34769e-02, -2.18132e-03,  6.64451e-03,\n",
       "         1.12086e-02,  7.48663e-03, -7.70651e-03, -1.99866e-02,\n",
       "        -4.32137e-03, -6.78570e-02, -9.28433e-03, -1.71756e-02,\n",
       "        -2.39890e-02, -1.22970e-03,  1.13110e-02,  1.18212e-02,\n",
       "        -1.03545e-01, -8.50424e-03, -4.89878e-02, -3.31633e-02,\n",
       "        -1.38327e-02, -8.78345e-02,  1.65035e-02, -4.19210e-02,\n",
       "         9.59509e-02, -8.43667e-02,  2.76138e-02, -1.41715e-03,\n",
       "        -3.87974e-02,  3.81558e-02,  5.21114e-02, -6.34563e-02,\n",
       "        -4.07686e-02, -2.62415e-03,  4.46253e-02, -6.15041e-02,\n",
       "         3.16414e-02, -6.17067e-02, -2.02890e-02, -1.21840e-01,\n",
       "         5.43134e-03, -4.56235e-02,  1.46595e-02,  3.67068e-02,\n",
       "        -1.02627e-01, -5.48293e-02, -1.96652e-02, -4.02795e-02,\n",
       "        -1.57764e-02, -2.95668e-02, -6.64527e-02, -2.12920e-02,\n",
       "        -7.98562e-02, -6.82391e-02,  7.01996e-02,  7.03165e-03,\n",
       "         8.91697e-02, -2.23267e-02, -5.76897e-02,  3.77291e-02,\n",
       "         7.29095e-02,  1.00636e-01,  2.59056e-04,  6.04568e-02,\n",
       "         8.02008e-02,  1.27921e-01, -4.65917e-02, -5.19922e-02,\n",
       "        -6.91246e-02,  2.13769e-02, -6.63108e-02,  6.70208e-02,\n",
       "        -7.41445e-02, -5.07527e-03, -7.19860e-02, -4.39464e-02,\n",
       "         1.42952e-01, -8.47901e-02,  2.35020e-02,  8.74188e-02,\n",
       "         2.30564e-02,  5.12414e-02, -6.65884e-02, -2.04554e-02,\n",
       "        -2.19532e-02, -1.29737e-02,  3.48429e-02, -5.52212e-02,\n",
       "         1.56232e-02,  1.16134e-02,  4.70137e-02, -7.83990e-02,\n",
       "        -6.70483e-03,  1.26767e-01, -2.70304e-02,  3.57660e-02,\n",
       "         1.43839e-02, -3.53989e-02, -1.37727e-02,  6.61512e-02,\n",
       "         2.58846e-02,  2.23932e-02, -2.47268e-02,  6.52555e-02,\n",
       "         4.30947e-02, -2.09665e-02, -1.60938e-01,  1.35164e-01,\n",
       "         2.38098e-02, -9.03994e-02,  5.52900e-02,  9.76004e-02,\n",
       "         4.58678e-02,  4.48634e-02, -4.13025e-02, -3.74146e-02,\n",
       "         7.51599e-02, -9.53135e-03,  2.81583e-02,  8.70554e-02,\n",
       "         9.14457e-02, -7.02670e-02, -5.71511e-02, -7.56754e-04,\n",
       "         5.35243e-02,  5.50177e-02, -5.97700e-03, -1.00709e-01,\n",
       "         8.53978e-02,  1.11878e-01,  2.93502e-02, -2.32909e-02,\n",
       "         1.13618e-02,  1.04520e-01,  5.56196e-02, -2.46181e-02,\n",
       "        -4.05972e-02,  4.34403e-03, -4.00208e-02, -6.06918e-02,\n",
       "        -1.17644e-01, -2.51510e-02,  2.70225e-02,  5.32355e-02,\n",
       "        -2.58225e-02, -2.11265e-03, -1.55606e-01,  3.99005e-02,\n",
       "         2.90251e-02,  6.43314e-03,  3.95748e-02,  6.39973e-02,\n",
       "        -3.13766e-02, -6.21949e-02, -2.78673e-02, -2.41694e-02,\n",
       "        -7.82351e-02,  1.89177e-02, -7.33256e-02, -2.21786e-02,\n",
       "        -5.13758e-02, -1.55859e-02, -8.47011e-02,  5.29670e-02,\n",
       "        -7.17224e-02, -1.74926e-02, -5.91220e-02, -9.66951e-03,\n",
       "         3.53537e-05,  1.04918e-01,  1.96777e-02, -4.82257e-02,\n",
       "         4.42986e-02, -5.42280e-02,  4.65258e-03, -8.71692e-02,\n",
       "        -4.97665e-02, -5.41700e-02, -1.29247e-01, -8.96011e-02,\n",
       "        -3.85667e-02, -1.06704e-01, -5.85347e-02,  9.56630e-02,\n",
       "        -4.42668e-03,  8.52538e-03,  1.66583e-02, -4.72408e-02,\n",
       "        -8.70796e-03, -1.08089e-01,  2.57453e-03,  6.42299e-02,\n",
       "         1.83709e-01,  5.79393e-02,  1.07903e-01, -3.81793e-02,\n",
       "         1.36922e-02, -3.81863e-02,  1.80904e-02,  6.77871e-02,\n",
       "         2.89922e-02, -1.49699e-02, -4.04954e-02,  6.93273e-02,\n",
       "         7.08723e-03,  4.08103e-02, -1.44309e-02, -3.48159e-03,\n",
       "         3.49104e-02, -4.13600e-03, -2.47715e-02, -3.86023e-02,\n",
       "        -3.15687e-02, -3.05918e-02,  1.29715e-02,  2.15668e-02,\n",
       "        -2.00925e-02,  5.61986e-02, -9.72509e-03, -8.29347e-02,\n",
       "        -1.54240e-02,  6.16386e-02, -5.42547e-02, -3.69384e-02,\n",
       "        -4.98646e-02,  7.40693e-02,  2.94726e-02, -6.56464e-02,\n",
       "        -1.18530e-01,  1.19782e-01,  4.51085e-02,  1.27395e-02,\n",
       "         9.02001e-02,  7.25277e-02, -1.74764e-02, -5.08100e-02,\n",
       "        -2.12491e-02,  5.65542e-03,  1.60384e-04, -2.31492e-02,\n",
       "         2.75824e-02, -1.11712e-01,  6.22958e-03, -2.46793e-02,\n",
       "        -1.28123e-02, -5.59498e-02, -4.34528e-02,  9.02245e-03,\n",
       "        -1.15804e-01, -1.26175e-01, -4.33314e-02,  8.99751e-03,\n",
       "        -3.24104e-02, -1.03260e-01, -3.42106e-03,  3.78454e-02,\n",
       "        -4.96665e-03,  3.31214e-03, -5.07727e-02,  1.18234e-02,\n",
       "         1.29309e-02,  1.10536e-01,  5.85488e-02, -4.01378e-02,\n",
       "        -2.20716e-02,  4.41812e-02, -1.05488e-02, -3.80567e-02,\n",
       "         1.32984e-01,  1.72944e-02,  5.69607e-02,  8.32798e-02,\n",
       "        -2.73045e-02, -1.03869e-01,  3.17616e-02, -6.87553e-03,\n",
       "        -5.42433e-02,  6.10933e-03, -2.01399e-02, -1.44876e-01,\n",
       "         7.70723e-03,  5.26771e-02,  7.22132e-03,  1.69309e-02]),\n",
       " array([-5.24680e-02,  4.30161e-03, -2.30686e-02,  1.03002e-01,\n",
       "        -5.53160e-02,  1.93671e-02,  6.20998e-03, -1.00064e-01,\n",
       "         2.18995e-02,  4.93024e-02, -5.28710e-02,  4.13968e-02,\n",
       "        -7.76444e-02, -3.36446e-02,  4.32930e-02,  5.69799e-03,\n",
       "        -2.47782e-02, -3.79670e-02, -7.96420e-02, -2.99228e-02,\n",
       "        -4.97743e-02,  4.98560e-02,  3.51806e-02, -7.42441e-02,\n",
       "         2.74465e-02, -1.63145e-02,  9.89941e-02, -6.66904e-02,\n",
       "        -3.78680e-02,  3.93237e-02, -1.01410e-02, -1.90658e-02,\n",
       "        -1.03879e-01,  1.57971e-03,  3.73093e-02, -5.21330e-02,\n",
       "        -3.75205e-02, -7.39706e-02,  1.57788e-02, -3.45944e-02,\n",
       "         4.44779e-02,  9.01845e-02, -8.94577e-04,  2.14784e-02,\n",
       "         1.03010e-01,  4.59195e-02,  9.85041e-03, -6.75166e-02,\n",
       "        -8.65349e-03,  1.30285e-02,  8.95161e-02,  5.21403e-02,\n",
       "        -4.93352e-02,  3.37642e-02, -8.87987e-02, -4.58374e-02,\n",
       "         3.17327e-02, -3.64871e-03, -5.70931e-02,  1.18501e-01,\n",
       "        -2.43595e-02,  8.19373e-03,  3.72363e-02,  7.58392e-02,\n",
       "         2.48995e-02, -1.36988e-03, -9.79494e-04,  4.65624e-02,\n",
       "        -4.25144e-02,  2.75853e-02, -1.66180e-02,  6.78903e-02,\n",
       "        -1.74169e-02, -3.89347e-03,  4.71441e-03,  1.32292e-02,\n",
       "         1.11743e-01,  4.17928e-02,  5.89609e-02, -1.09056e-01,\n",
       "         3.15492e-03,  7.33437e-03, -6.20335e-02,  2.18712e-01,\n",
       "         2.02976e-02, -4.36444e-02, -2.58521e-02,  4.75955e-02,\n",
       "         7.85425e-03, -5.82423e-03, -4.12150e-03,  5.54347e-03,\n",
       "        -1.69626e-02, -4.78424e-02, -8.25994e-03,  1.08361e-01,\n",
       "         8.35982e-02, -5.55725e-02, -2.98268e-02,  4.41409e-02,\n",
       "         4.13029e-02,  4.79742e-02,  7.84542e-02, -6.67613e-02,\n",
       "        -1.71757e-01,  5.16684e-02,  4.19607e-02, -3.03930e-02,\n",
       "         8.17263e-02, -8.89578e-03, -3.19399e-02, -9.66326e-02,\n",
       "         3.46583e-02,  6.22324e-02,  4.05678e-02, -5.34475e-03,\n",
       "         7.15786e-02,  1.35969e-01, -8.97480e-02, -8.86817e-02,\n",
       "         4.89531e-03,  4.69148e-03, -1.56207e-02,  3.36168e-02,\n",
       "         2.43877e-02, -4.58334e-02,  7.41242e-02,  2.92400e-02,\n",
       "        -2.14477e-02,  7.98263e-02,  3.42067e-02, -6.71782e-02,\n",
       "        -5.11885e-02,  3.76057e-02,  2.31821e-02,  2.27600e-02,\n",
       "        -3.63730e-02, -7.80580e-02, -1.53738e-02, -4.28624e-02,\n",
       "         1.00104e-01,  1.21203e-01,  7.99657e-04, -3.63968e-03,\n",
       "         8.78488e-02,  6.63336e-02,  9.82920e-03, -6.05807e-02,\n",
       "         6.86764e-02, -4.05881e-02,  2.69834e-02, -4.52030e-02,\n",
       "         3.96619e-02,  2.06651e-02, -8.31000e-02, -1.17974e-01,\n",
       "        -7.41854e-02, -2.10028e-02,  1.04506e-01, -1.43227e-02,\n",
       "        -7.16568e-02,  2.41576e-02,  3.65613e-03,  9.52361e-03,\n",
       "         9.25967e-02,  1.04052e-01, -2.46902e-02,  3.59229e-02,\n",
       "         1.14853e-01,  3.82152e-02, -1.05949e-02, -5.43572e-02,\n",
       "        -4.90891e-02,  1.30254e-02, -5.50809e-03,  1.27758e-01,\n",
       "        -1.44731e-02,  6.92843e-02,  5.31783e-02,  3.27313e-02,\n",
       "         2.31564e-02,  7.75250e-03, -9.60763e-03,  1.41401e-01,\n",
       "        -7.32441e-03,  9.86992e-03, -1.62923e-02, -1.04322e-01,\n",
       "         8.55964e-02, -4.49569e-02,  3.41283e-02, -5.75120e-02,\n",
       "         4.77489e-02,  1.13549e-01, -7.44368e-02, -4.45870e-02,\n",
       "        -4.34978e-02, -3.76751e-02, -6.90631e-03, -4.62351e-02,\n",
       "         7.70958e-02, -1.76212e-02,  4.05833e-02,  3.82648e-02,\n",
       "        -3.19964e-02,  5.02449e-02,  3.05569e-02, -1.76654e-02,\n",
       "         4.51451e-02,  9.97122e-02,  1.06652e-01,  3.26777e-02,\n",
       "         2.60650e-02, -1.19348e-01,  5.36632e-02, -6.14506e-02,\n",
       "         8.81743e-02, -8.32984e-02,  3.40032e-02,  6.35082e-02,\n",
       "        -1.40778e-01, -8.86010e-02,  2.54042e-02, -4.37284e-03,\n",
       "        -5.79592e-03,  1.09254e-01,  1.83583e-02, -5.33102e-02,\n",
       "         2.18963e-02,  6.88175e-02, -2.18753e-02,  1.04734e-02,\n",
       "        -5.57008e-04,  8.13020e-03, -7.64583e-02,  4.51550e-02,\n",
       "         1.01283e-01,  2.03769e-02,  2.18146e-03, -4.83579e-02,\n",
       "         1.05764e-02, -1.08952e-01, -2.91844e-02,  5.02137e-02,\n",
       "        -3.93755e-02,  1.34997e-02, -8.11445e-02, -3.24779e-02,\n",
       "         2.11431e-02,  3.97432e-02, -4.45251e-02,  5.41771e-03,\n",
       "        -4.52123e-02, -1.17498e-01, -3.16341e-02, -6.79501e-03,\n",
       "         6.33909e-02, -8.15049e-02, -5.39883e-02, -1.57250e-02,\n",
       "        -3.58719e-02,  7.34277e-02, -4.07835e-02, -2.03678e-02,\n",
       "        -1.08444e-01, -1.11432e-02, -4.23079e-02, -2.05249e-02,\n",
       "         1.99879e-02,  1.60432e-02,  1.78222e-02, -7.64114e-02,\n",
       "         9.42292e-03,  6.52173e-02, -4.18146e-02,  7.54692e-02,\n",
       "         4.99721e-02,  8.31027e-02,  8.59066e-03, -5.22884e-02,\n",
       "        -5.54231e-02, -9.19066e-03, -2.25381e-02,  4.86203e-02,\n",
       "         1.39498e-02, -4.49167e-02, -1.15291e-02,  4.81252e-02,\n",
       "        -5.84100e-02,  2.30968e-02,  5.34183e-02,  2.86167e-02,\n",
       "         6.59313e-02,  3.24249e-02, -3.33080e-02,  1.99296e-04,\n",
       "        -3.02618e-02,  8.88615e-02,  6.38825e-02,  4.27401e-02]),\n",
       " array([-0.0271246 , -0.112166  , -0.0458135 ,  0.0775148 , -0.112529  ,\n",
       "        -0.00782289, -0.053559  ,  0.0185049 ,  0.00387291,  0.122905  ,\n",
       "        -0.0822417 , -0.0545864 , -0.0758786 , -0.0354154 , -0.00801548,\n",
       "        -0.0589079 ,  0.0303507 ,  0.0725591 ,  0.00921697, -0.0776337 ,\n",
       "         0.00853376,  0.0329131 , -0.0264538 , -0.108985  , -0.0771106 ,\n",
       "         0.0547649 ,  0.0571093 ,  0.0820581 , -0.10589   , -0.00856646,\n",
       "         0.0663071 ,  0.0435783 , -0.0894732 ,  0.00018662,  0.0130818 ,\n",
       "        -0.0343546 ,  0.113568  , -0.0242782 ,  0.0271771 , -0.0416627 ,\n",
       "         0.0125948 , -0.0129086 , -0.0616228 ,  0.04255   ,  0.035579  ,\n",
       "         0.0408125 ,  0.105546  ,  0.00961913,  0.0185724 ,  0.013748  ,\n",
       "         0.0728475 , -0.0792744 , -0.0218756 , -0.0952243 , -0.0819565 ,\n",
       "        -0.0251707 , -0.0194695 ,  0.0262591 , -0.0436937 ,  0.0883949 ,\n",
       "        -0.0213366 ,  0.0684451 ,  0.17628   , -0.0458191 , -0.0739124 ,\n",
       "         0.051906  , -0.0214197 ,  0.0466708 , -0.0672083 ,  0.0349475 ,\n",
       "         0.00815532,  0.0864336 ,  0.0566576 , -0.115719  , -0.0774921 ,\n",
       "         0.027924  ,  0.159592  ,  0.0287492 ,  0.0492667 , -0.0789608 ,\n",
       "        -0.0142078 , -0.066807  , -0.0688847 ,  0.0950398 , -0.0600078 ,\n",
       "        -0.0269695 ,  0.0133577 ,  0.0234701 , -0.0317097 ,  0.0514864 ,\n",
       "         0.0503958 , -0.0282478 ,  0.00982561, -0.00629411, -0.0198274 ,\n",
       "         0.0674725 ,  0.00661428, -0.0137761 ,  0.0405144 ,  0.0192935 ,\n",
       "         0.0876027 , -0.0301758 ,  0.0504322 , -0.0296167 ,  0.0231854 ,\n",
       "        -0.00356189, -0.0227134 , -0.0240411 ,  0.021738  ,  0.0733854 ,\n",
       "        -0.0261704 , -0.0784197 , -0.0493776 , -0.0822423 ,  0.00778837,\n",
       "        -0.141669  ,  0.0831401 , -0.0351676 , -0.0383438 ,  0.0689011 ,\n",
       "         0.0320369 ,  0.0135969 , -0.0675348 ,  0.0026944 , -0.00848668,\n",
       "        -0.0666766 , -0.0448814 ,  0.0210293 ,  0.0976096 ,  0.0852644 ,\n",
       "        -0.071739  ,  0.0108326 , -0.076537  ,  0.0352076 ,  0.0430803 ,\n",
       "         0.00120588,  0.0235318 , -0.027139  , -0.0495123 , -0.0316474 ,\n",
       "        -0.00396   ,  0.00504446,  0.0628825 ,  0.0577674 , -0.0382837 ,\n",
       "         0.0227903 ,  0.0502352 , -0.11949   ,  0.167015  ,  0.03468   ,\n",
       "         0.032059  , -0.0252666 , -0.0995921 ,  0.0154706 ,  0.00627059,\n",
       "        -0.0344305 , -0.0991407 ,  0.0148898 ,  0.0418759 , -0.0269722 ,\n",
       "         0.0395418 ,  0.0668224 , -0.0747085 ,  0.09203   , -0.0133349 ,\n",
       "         0.0389511 , -0.0792386 ,  0.0279302 ,  0.0382719 ,  0.0495581 ,\n",
       "         0.0259833 , -0.0520405 ,  0.00846458,  0.0543109 ,  0.0363545 ,\n",
       "         0.107145  ,  0.116554  , -0.00574922, -0.0342253 , -0.0371087 ,\n",
       "         0.0247989 , -0.0249619 ,  0.0459068 ,  0.0126935 , -0.00974726,\n",
       "        -0.00371637,  0.0193403 , -0.0282134 ,  0.151406  , -0.13907   ,\n",
       "        -0.0215675 , -0.0115504 , -0.0548775 ,  0.0973558 , -0.0708541 ,\n",
       "         0.0405179 ,  0.00525245, -0.00455449, -0.0573191 , -0.0279432 ,\n",
       "         0.0243791 , -0.09905   ,  0.0175119 ,  0.0497489 , -0.0365418 ,\n",
       "        -0.0743435 , -0.0522628 ,  0.0939192 , -0.0331578 ,  0.0609493 ,\n",
       "         0.0986788 ,  0.00623949,  0.0177196 , -0.0315803 ,  0.0461365 ,\n",
       "        -0.0405986 , -0.0126308 , -0.0578255 , -0.00088767, -0.0207697 ,\n",
       "        -0.111368  ,  0.0430465 ,  0.0221441 , -0.0433362 , -0.0357968 ,\n",
       "         0.0844541 , -0.0413412 , -0.034497  , -0.0146173 ,  0.00932282,\n",
       "         0.0705273 ,  0.00809071,  0.0249707 ,  0.147354  ,  0.00852136,\n",
       "         0.0727075 , -0.0213553 ,  0.0167867 ,  0.0566244 , -0.043689  ,\n",
       "        -0.0273514 ,  0.0293261 ,  0.00022661,  0.0688408 , -0.0206533 ,\n",
       "         0.0936168 ,  0.00858034,  0.034465  ,  0.00591072,  0.123848  ,\n",
       "        -0.016199  , -0.0146925 , -0.0104442 , -0.0705626 , -0.0190541 ,\n",
       "         0.0129376 ,  0.0742217 , -0.0788396 ,  0.0162275 , -0.00634243,\n",
       "         0.0863404 , -0.00303176, -0.0197922 ,  0.00537417, -0.147392  ,\n",
       "        -0.0115541 , -0.0584148 ,  0.00054356,  0.0764684 , -0.0325357 ,\n",
       "         0.0413671 , -0.0186696 ,  0.105891  ,  0.0844514 , -0.0326645 ,\n",
       "        -0.0259395 ,  0.0133359 ,  0.0101059 ,  0.0283676 ,  0.0314001 ,\n",
       "        -0.00614611, -0.0191187 ,  0.0982305 , -0.0114786 ,  0.0612427 ,\n",
       "         0.0590131 , -0.0267586 ,  0.0336579 , -0.0144497 ,  0.0582442 ,\n",
       "         0.0397527 , -0.0518192 , -0.0750558 , -0.0112987 ,  0.0391862 ,\n",
       "        -0.0245861 , -0.0217213 ,  0.0135904 ,  0.0995795 , -0.0168194 ]),\n",
       " array([ 0.00975112,  0.119637  , -0.0942776 , -0.0464149 , -0.0405434 ,\n",
       "         0.0475084 ,  0.0341872 ,  0.0266829 , -0.0355644 ,  0.148003  ,\n",
       "         0.0681747 , -0.0877465 , -0.0283309 , -0.056195  ,  0.0114812 ,\n",
       "         0.0438521 , -0.0808381 ,  0.00349589, -0.0155833 ,  0.0698691 ,\n",
       "        -0.00705903,  0.0350561 , -0.0915204 , -0.00819792,  0.00479954,\n",
       "        -0.0177702 , -0.00994384, -0.108691  ,  0.008076  , -0.0209999 ,\n",
       "         0.00426352,  0.0702555 , -0.0877146 ,  0.0910797 , -0.0147118 ,\n",
       "        -0.11022   ,  0.0349289 , -0.0851626 ,  0.00283883,  0.0750625 ,\n",
       "         0.0730617 , -0.0312385 , -0.0256113 , -0.0315099 ,  0.0347672 ,\n",
       "         0.0652587 ,  0.0988442 ,  0.0823979 ,  0.0689653 , -0.158082  ,\n",
       "        -0.00817641, -0.0464158 ,  0.0574543 , -0.0144348 , -0.0958095 ,\n",
       "         0.02447   ,  0.0374128 , -0.0076234 , -0.0600084 ,  0.023464  ,\n",
       "         0.01985   , -0.0847562 ,  0.0872168 ,  0.00823615,  0.0127491 ,\n",
       "         0.0181383 , -0.126212  , -0.0121579 , -0.0223335 ,  0.00148263,\n",
       "        -0.0563427 ,  0.0144894 ,  0.0832793 , -0.177106  , -0.0517708 ,\n",
       "        -0.0542267 ,  0.123522  ,  0.0595698 ,  0.00219836,  0.0156276 ,\n",
       "         0.0353615 ,  0.0186483 , -0.0429712 , -0.00473874, -0.034195  ,\n",
       "         0.028294  ,  0.046897  ,  0.0644226 ,  0.106598  , -0.00026571,\n",
       "        -0.00815025,  0.00438235,  0.109577  , -0.0406536 , -0.0719481 ,\n",
       "         0.0736738 ,  0.0275263 , -0.0491297 ,  0.00337114, -0.107607  ,\n",
       "        -0.0425055 ,  0.0382756 ,  0.0650691 , -0.00754835, -0.078798  ,\n",
       "         0.00483923, -0.0186827 ,  0.0460076 ,  0.0578245 ,  0.0159246 ,\n",
       "        -0.0178582 , -0.0492316 ,  0.00614735, -0.0202196 , -0.00607911,\n",
       "        -0.007078  ,  0.0671585 ,  0.0297627 , -0.0805695 , -0.0156748 ,\n",
       "        -0.00812021,  0.0745784 ,  0.0481133 ,  0.06913   ,  0.0675901 ,\n",
       "        -0.085362  ,  0.0251587 ,  0.0119791 ,  0.0171626 ,  0.0727988 ,\n",
       "        -0.0318013 , -0.0016124 , -0.0352005 ,  0.0177587 ,  0.0282304 ,\n",
       "         0.116075  , -0.032585  , -0.0285519 , -0.0775812 ,  0.0595998 ,\n",
       "        -0.0182417 ,  0.0426937 ,  0.00515793, -0.00357626,  0.0414304 ,\n",
       "         0.0729902 ,  0.0148321 , -0.0238366 ,  0.0554372 ,  0.0469339 ,\n",
       "         0.0147837 , -0.0850903 , -0.00783743, -0.0524577 , -0.0337407 ,\n",
       "        -0.114862  , -0.0686778 , -0.0705654 ,  0.0488455 , -0.0265024 ,\n",
       "        -0.0491378 ,  0.0351447 ,  0.00272222,  0.00390732,  0.118423  ,\n",
       "        -0.0300674 , -0.0802817 , -0.0535262 ,  0.0989052 ,  0.0356557 ,\n",
       "        -0.170423  ,  0.052     , -0.0317037 ,  0.0409809 ,  0.0316994 ,\n",
       "         0.123209  , -0.0334113 ,  0.018638  , -0.0682869 , -0.103262  ,\n",
       "         0.0487244 , -0.0872005 ,  0.0222187 ,  0.0167851 , -0.0115659 ,\n",
       "         0.0435872 , -0.0102539 , -0.0080929 ,  0.123839  ,  0.0290373 ,\n",
       "        -0.106611  , -0.0402306 ,  0.130107  ,  0.049695  , -0.0533811 ,\n",
       "         0.0382213 , -0.0161471 , -0.0145961 , -0.134773  ,  0.00497049,\n",
       "        -0.0465312 , -0.134493  , -0.0337239 ,  0.0264446 ,  0.0396196 ,\n",
       "        -0.0369539 , -0.030764  ,  0.0156583 ,  0.0837196 ,  0.0425554 ,\n",
       "         0.0781432 , -0.0137224 , -0.126679  ,  0.0223628 ,  0.00073405,\n",
       "        -0.0578896 , -0.0650061 , -0.0938807 ,  0.0639242 ,  0.098554  ,\n",
       "        -0.103743  ,  0.0103537 , -0.0303705 ,  0.0311502 ,  0.033287  ,\n",
       "         0.0248492 , -0.0539245 , -0.0914327 , -0.0064936 , -0.0358289 ,\n",
       "         0.0876889 ,  0.0103675 , -0.036118  , -0.00805633,  0.00622018,\n",
       "         0.0584753 , -0.00209006,  0.0444164 ,  0.0114529 , -0.00076925,\n",
       "        -0.00021932,  0.0145257 ,  0.0398693 ,  0.0228918 ,  0.0262819 ,\n",
       "         0.00346863,  0.0301739 , -0.0421571 ,  0.00913725,  0.029883  ,\n",
       "         0.0490262 ,  0.0254422 , -0.137204  ,  0.0251723 , -0.0342355 ,\n",
       "        -0.12476   , -0.0847641 , -0.00615219, -0.0313119 ,  0.00693453,\n",
       "         0.0421954 , -0.0459513 , -0.0218726 ,  0.0107243 , -0.0536707 ,\n",
       "         0.00755717,  0.0235506 ,  0.0299614 ,  0.0114588 ,  0.0290584 ,\n",
       "        -0.0248488 , -0.0276563 ,  0.0396026 ,  0.0581892 , -0.088952  ,\n",
       "         0.0239154 ,  0.0350618 , -0.0199812 ,  0.0510433 , -0.0699488 ,\n",
       "        -0.0057464 , -0.0381105 , -0.0695138 , -0.00149769,  0.0505493 ,\n",
       "        -0.0167692 ,  0.050989  ,  0.0461348 , -0.00064027,  0.00910974,\n",
       "        -0.0185248 , -0.0104393 ,  0.0772929 ,  0.044558  ,  0.105982  ,\n",
       "        -0.105275  , -0.0124132 ,  0.00745753, -0.020058  ,  0.0512259 ]),\n",
       " array([-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000]),\n",
       " array([-8.54317e-02, -4.64408e-02, -1.47025e-02,  6.37729e-02,\n",
       "        -3.88752e-02,  3.81393e-03,  2.33396e-02, -9.18837e-02,\n",
       "        -5.34460e-02,  6.55852e-02,  5.58143e-02,  2.41750e-02,\n",
       "         3.10262e-02, -3.14703e-02,  1.12954e-01, -3.95656e-02,\n",
       "        -4.47765e-02, -6.40872e-02,  1.29428e-02,  7.33941e-02,\n",
       "         1.34111e-02,  6.23749e-02, -8.20502e-02, -5.45712e-02,\n",
       "        -6.40298e-02, -1.24159e-01,  1.43699e-02, -7.28293e-02,\n",
       "        -1.59349e-02, -3.81483e-02, -1.93806e-02,  1.01286e-01,\n",
       "        -7.03214e-04,  1.43744e-01, -6.24260e-03, -1.96978e-03,\n",
       "         1.39250e-02, -4.89056e-02,  9.10632e-02, -8.96558e-03,\n",
       "         1.22394e-01, -4.79306e-02,  7.63962e-03, -1.21434e-03,\n",
       "        -3.18069e-02, -3.72801e-02, -9.47495e-03,  1.23740e-02,\n",
       "         1.22765e-01, -3.49063e-02, -5.00903e-02, -1.37202e-02,\n",
       "         1.89669e-02, -4.08966e-02, -3.52192e-02,  8.06146e-02,\n",
       "        -6.04734e-02,  1.01878e-01, -5.21971e-02,  6.53862e-02,\n",
       "         6.67100e-03,  6.33222e-02,  4.18213e-02, -3.10063e-02,\n",
       "        -1.06116e-02, -9.77056e-02, -2.95722e-02,  6.38991e-02,\n",
       "        -5.36113e-02,  5.00754e-02, -3.25864e-02, -4.74001e-02,\n",
       "         3.55261e-02, -6.24798e-02, -5.74051e-02, -2.71786e-03,\n",
       "         1.25369e-01,  9.11330e-02,  2.15780e-03, -1.94077e-02,\n",
       "         3.99068e-02, -1.44156e-02, -3.56575e-02,  2.24546e-02,\n",
       "        -1.74930e-02,  5.64400e-02, -1.31969e-02,  5.29244e-02,\n",
       "         6.77727e-03, -8.25952e-03, -5.30112e-02, -3.84760e-02,\n",
       "         1.26886e-01, -9.64271e-03, -8.38226e-03,  4.40095e-02,\n",
       "         9.20140e-03,  2.79437e-02, -4.70131e-02, -7.14233e-02,\n",
       "        -1.79157e-02, -4.03359e-02,  1.03870e-01, -1.57858e-01,\n",
       "        -6.19633e-02, -6.42802e-02, -1.19791e-01,  5.90041e-05,\n",
       "        -8.06944e-02,  1.11507e-01,  2.61997e-02, -8.64730e-02,\n",
       "        -1.06380e-01, -1.90569e-03, -2.98233e-02,  8.66960e-02,\n",
       "         5.33574e-02,  4.40999e-02,  1.45619e-03, -1.99302e-02,\n",
       "         1.41052e-01,  6.48952e-03, -1.05176e-01,  5.49912e-02,\n",
       "         2.36508e-02,  3.93751e-03,  1.76658e-01,  2.04151e-02,\n",
       "         3.38039e-02,  5.56915e-02,  3.20932e-02, -3.00464e-02,\n",
       "        -1.14884e-02,  8.84576e-03, -1.03885e-01, -1.01027e-01,\n",
       "         1.45800e-02,  2.86453e-02, -6.86649e-02, -1.14931e-03,\n",
       "        -5.46751e-03,  2.92336e-02,  5.55449e-02,  1.95855e-02,\n",
       "         3.64206e-02,  1.95541e-02,  3.91495e-02, -5.58782e-02,\n",
       "         2.90421e-02, -2.63350e-02, -2.47664e-02, -1.51619e-01,\n",
       "         2.69923e-02, -3.63277e-02, -8.98792e-02, -7.92793e-02,\n",
       "        -9.54866e-02, -8.26034e-02,  1.11728e-01,  1.45480e-02,\n",
       "         2.52582e-02,  5.08996e-02, -1.34129e-01,  5.41384e-02,\n",
       "         1.38704e-01, -3.09424e-02, -4.98610e-02, -1.41508e-02,\n",
       "        -3.02667e-03,  2.88257e-02,  3.86104e-02,  1.20078e-02,\n",
       "        -2.66735e-02, -5.80596e-02, -7.01584e-02,  4.84819e-02,\n",
       "         5.05197e-02, -1.47644e-02, -7.03810e-02, -2.44970e-02,\n",
       "         3.34739e-02, -5.07551e-02, -7.77679e-02, -1.81331e-02,\n",
       "         6.24217e-02,  5.50646e-02,  1.21196e-02, -2.95289e-02,\n",
       "         4.73648e-02, -3.44790e-02, -1.32196e-02, -7.21874e-03,\n",
       "         4.78856e-02,  1.84927e-02, -3.17531e-02,  7.60599e-03,\n",
       "        -8.21510e-02,  3.46724e-02, -6.24185e-02,  4.18780e-03,\n",
       "         2.32484e-02,  1.13961e-02, -1.31771e-01, -3.13992e-03,\n",
       "         6.30124e-03,  4.27462e-03,  5.73027e-02,  5.75131e-02,\n",
       "         4.19635e-02,  2.52204e-02,  5.27525e-02, -5.25597e-02,\n",
       "         1.91329e-02, -3.58002e-02, -4.25403e-02, -1.16940e-02,\n",
       "         6.63487e-02, -5.67962e-02, -3.84227e-02,  6.51113e-02,\n",
       "         9.01056e-03, -6.96771e-02, -7.10430e-02, -6.26573e-02,\n",
       "        -4.74083e-02, -1.33817e-01, -1.42261e-02,  4.78746e-02,\n",
       "         7.90607e-02, -1.02910e-01, -6.47268e-03,  2.89185e-02,\n",
       "         2.31371e-02, -1.37518e-03,  6.33359e-02,  7.97548e-02,\n",
       "         1.25678e-02,  1.90783e-02, -6.51101e-02,  1.51034e-03,\n",
       "         1.67596e-02, -6.07913e-03,  1.17422e-01, -5.85001e-02,\n",
       "        -6.74952e-02,  7.05395e-03,  7.11579e-02, -1.60618e-02,\n",
       "         9.09556e-03,  1.96156e-02,  1.06928e-02, -8.94836e-03,\n",
       "        -7.76445e-02, -2.59445e-02, -1.42085e-01,  5.02637e-02,\n",
       "        -4.82735e-02, -1.28369e-02, -8.56435e-02,  2.68776e-02,\n",
       "        -5.63007e-02,  1.68038e-02,  6.83779e-02,  2.08699e-03,\n",
       "         1.74404e-02, -6.13934e-02,  6.86243e-02,  3.54634e-03,\n",
       "        -2.63171e-02, -2.63633e-03, -9.14811e-02,  8.82292e-03,\n",
       "        -7.84096e-03,  2.93188e-02,  5.09728e-03, -9.60576e-02,\n",
       "         5.93205e-02,  4.84513e-02,  7.61655e-02, -3.01074e-02,\n",
       "        -4.98600e-02,  3.16532e-02, -3.71081e-02, -4.31130e-03,\n",
       "         3.78329e-02, -4.36276e-02, -1.00776e-02, -2.05185e-02,\n",
       "         1.11575e-01,  2.61690e-02, -4.01881e-02, -1.04252e-01,\n",
       "        -2.05341e-02,  6.35482e-02,  3.90191e-02,  3.40490e-02,\n",
       "        -2.08788e-02,  3.93569e-02,  3.47346e-02, -2.77117e-02]),\n",
       " array([-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000]),\n",
       " array([-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000]),\n",
       " array([-5.22697e-03, -7.20679e-02, -4.69798e-02,  2.10742e-03,\n",
       "         3.78310e-02, -1.02886e-01,  1.26289e-02, -2.01745e-02,\n",
       "        -6.49353e-02, -8.12823e-02,  8.29968e-03, -2.10022e-02,\n",
       "        -1.37717e-01, -1.22291e-01, -4.10478e-03,  1.23791e-02,\n",
       "         4.99740e-02,  2.33335e-02, -1.03871e-02,  4.10863e-02,\n",
       "         3.57665e-02,  4.89648e-03, -6.60712e-02, -9.66157e-02,\n",
       "        -7.10495e-02, -1.58259e-01, -5.88923e-02, -7.14613e-02,\n",
       "        -6.16929e-02,  8.39564e-02,  1.85913e-03,  7.41539e-02,\n",
       "         2.79641e-02,  8.72676e-02,  8.23051e-02, -9.66811e-02,\n",
       "         1.43534e-02, -3.10735e-02,  2.74578e-03, -1.00456e-01,\n",
       "         3.53274e-02,  5.59570e-02,  5.69124e-02,  6.94651e-03,\n",
       "        -4.26405e-03, -1.42560e-02,  6.61516e-02,  7.78819e-02,\n",
       "         4.86633e-02, -4.07945e-02,  1.99267e-02, -1.03719e-01,\n",
       "         3.33414e-02, -8.96126e-02, -4.95177e-02,  3.67334e-02,\n",
       "         2.84061e-02,  5.06613e-02, -7.09842e-03,  5.35427e-02,\n",
       "         2.09357e-02, -7.70879e-02,  5.08194e-02, -7.33252e-02,\n",
       "         2.05887e-02,  8.07513e-02, -3.12970e-02, -3.56123e-02,\n",
       "        -7.26997e-02,  5.61161e-02,  3.45897e-02, -5.08229e-02,\n",
       "         8.31592e-02,  2.02998e-02, -3.58808e-02,  5.08173e-02,\n",
       "         1.02295e-02,  2.97481e-02, -9.96818e-03,  8.34509e-03,\n",
       "        -1.02206e-01,  3.45423e-02,  7.57180e-03,  7.92609e-02,\n",
       "        -2.36958e-02, -7.02908e-02,  4.66271e-02, -1.78320e-02,\n",
       "         3.01127e-02, -2.65054e-02,  3.45030e-02,  1.69234e-03,\n",
       "         2.39780e-02, -5.30400e-02, -6.27861e-02,  1.07293e-01,\n",
       "        -1.17082e-01,  4.64720e-02, -1.86425e-02, -2.12987e-02,\n",
       "         3.64598e-02, -8.25652e-03, -4.07470e-02, -5.45468e-02,\n",
       "         2.63541e-02,  4.88549e-02,  1.95186e-02, -9.81958e-02,\n",
       "         5.81586e-02, -1.36656e-02,  7.97714e-03, -3.13252e-04,\n",
       "        -1.15344e-01,  2.65703e-02,  8.91776e-02, -6.95428e-02,\n",
       "        -6.09741e-02,  3.45792e-02, -1.33682e-02,  8.97177e-02,\n",
       "         2.05562e-02, -1.39977e-02,  1.44104e-02,  1.16127e-01,\n",
       "         9.73377e-05, -1.16882e-01, -7.63171e-02,  8.26011e-02,\n",
       "        -7.52753e-02, -1.69985e-02,  5.62769e-02, -1.63647e-02,\n",
       "        -6.23997e-02,  6.55199e-02, -1.12695e-02, -5.27023e-02,\n",
       "        -5.45413e-02, -6.18567e-02,  9.14516e-02,  2.24808e-02,\n",
       "         4.36049e-02,  1.06162e-02,  8.15237e-02,  6.95084e-02,\n",
       "        -7.46622e-02,  1.73412e-02, -1.83070e-02,  1.12338e-01,\n",
       "        -1.76901e-02,  4.19963e-02, -1.70703e-02,  8.06646e-02,\n",
       "        -3.25382e-02,  4.72879e-04,  3.46013e-02, -6.51094e-03,\n",
       "         4.55275e-02,  3.00756e-02, -3.00557e-03, -2.75934e-02,\n",
       "         5.98801e-03,  3.85846e-02,  1.70166e-02, -3.02950e-02,\n",
       "         1.12466e-01,  1.99565e-02,  3.85178e-02, -3.64793e-02,\n",
       "         6.08646e-02,  7.32999e-02,  1.33722e-02, -6.02697e-02,\n",
       "        -1.68544e-01, -5.79565e-03, -2.82714e-02,  3.60478e-02,\n",
       "        -3.53124e-02, -4.55519e-03, -4.95953e-02, -4.58235e-02,\n",
       "         4.45857e-02, -6.34239e-02,  2.12870e-02, -1.85025e-02,\n",
       "        -8.30056e-02,  1.45953e-02,  2.23760e-02, -1.03089e-01,\n",
       "         8.48976e-02, -5.78731e-04, -1.20514e-02,  7.57694e-02,\n",
       "         1.35455e-01,  1.27707e-01, -1.42071e-02, -1.26859e-01,\n",
       "         3.72143e-02,  9.38931e-03, -3.42505e-02, -6.87210e-02,\n",
       "         9.44670e-02, -4.84136e-04,  9.42076e-02, -8.53905e-02,\n",
       "        -2.75058e-02, -8.23365e-02,  9.46449e-02,  3.14823e-02,\n",
       "         1.24286e-01,  9.51804e-03,  8.51366e-02, -8.98937e-02,\n",
       "         4.95495e-02,  3.57125e-02, -9.86488e-02, -3.90728e-02,\n",
       "         6.86458e-02, -1.35850e-01,  1.31682e-02, -1.53007e-02,\n",
       "         5.66913e-04,  1.10231e-02,  1.86295e-02,  4.40359e-03,\n",
       "         2.55193e-02, -3.41701e-02, -2.21117e-02,  5.14921e-02,\n",
       "         1.18699e-02,  3.73254e-02,  1.10348e-02,  4.05944e-02,\n",
       "         2.91779e-02,  3.10536e-02,  9.78486e-03,  1.07958e-02,\n",
       "         6.99097e-02, -8.93113e-02, -6.36354e-02, -3.20968e-02,\n",
       "        -7.24649e-02, -6.61167e-02, -5.35596e-02, -2.64982e-02,\n",
       "        -2.89826e-02, -6.26037e-05, -3.60909e-02, -6.79084e-02,\n",
       "        -6.17683e-02,  1.49983e-02,  4.62558e-02, -3.26331e-02,\n",
       "         2.76290e-02,  9.25432e-02,  2.64939e-02, -2.36021e-02,\n",
       "         2.74014e-02, -6.69652e-02,  4.33753e-02, -7.72223e-02,\n",
       "         3.29058e-02, -4.54648e-02,  5.70058e-02,  6.56941e-02,\n",
       "        -1.10067e-01, -9.67868e-02, -3.51653e-02, -6.48021e-02,\n",
       "        -1.65220e-02,  4.88620e-02, -4.91096e-02, -7.01983e-03,\n",
       "         6.67272e-02,  9.01986e-03,  3.41197e-02, -5.39765e-02,\n",
       "         7.54243e-02,  2.37250e-02,  1.04407e-01,  2.14643e-02,\n",
       "        -5.94920e-04,  1.37111e-02, -2.91352e-02, -3.83053e-02,\n",
       "         7.55809e-03,  5.10716e-02,  5.16754e-02, -2.90464e-02,\n",
       "        -9.76213e-02,  8.99629e-03, -3.17288e-02, -1.30094e-02,\n",
       "         8.28589e-02, -4.96324e-02,  6.13970e-02, -7.06529e-02,\n",
       "        -7.40298e-02,  2.28430e-02,  5.49095e-02,  2.43322e-02]),\n",
       " array([-0.0434222 ,  0.0563041 , -0.0412265 , -0.0131407 , -0.0497862 ,\n",
       "        -0.0368448 ,  0.0220474 , -0.0710356 , -0.0101149 ,  0.0693871 ,\n",
       "        -0.0630604 ,  0.0454874 , -0.0279397 ,  0.00995619, -0.0196435 ,\n",
       "         0.0190495 ,  0.0745139 ,  0.0863349 , -0.0414587 ,  0.00208408,\n",
       "         0.00653857, -0.0251664 ,  0.0159972 , -0.0631474 , -0.0449885 ,\n",
       "        -0.058476  , -0.0124005 , -0.0630498 , -0.0980329 ,  0.0430994 ,\n",
       "        -0.0499657 ,  0.0586954 , -0.126359  , -0.0465216 , -0.0496183 ,\n",
       "        -0.0865722 , -0.023722  , -0.00659736, -0.0649749 , -0.0337615 ,\n",
       "         0.0039877 , -0.062778  , -0.0249926 , -0.0772308 , -0.0234275 ,\n",
       "         0.0230533 ,  0.0744215 , -0.0376832 ,  0.0095835 , -0.00059616,\n",
       "        -0.0327231 ,  0.0150393 , -0.0257934 , -0.0668369 , -0.142829  ,\n",
       "         0.171247  , -0.0802748 ,  0.0561412 , -0.0558512 , -0.00289039,\n",
       "        -0.0767173 , -0.0513185 ,  0.0804746 , -0.0197218 , -0.0433916 ,\n",
       "        -0.082673  ,  0.0419705 ,  0.0383733 , -0.0373717 , -0.0398419 ,\n",
       "         0.0287287 ,  0.0627171 , -0.0345188 , -0.0487147 , -0.0415252 ,\n",
       "        -0.0367683 ,  0.0772939 , -0.0123087 , -0.0510002 ,  0.0196374 ,\n",
       "         0.0814295 ,  0.0379759 , -0.00670945, -0.0198116 , -0.0375192 ,\n",
       "         0.0206478 ,  0.0153335 ,  0.0118509 , -0.00985505, -0.0711983 ,\n",
       "         0.130426  ,  0.0281424 ,  0.0356309 , -0.0335566 ,  0.00574903,\n",
       "         0.119071  ,  0.0307217 , -0.0166697 , -0.0677769 ,  0.00811654,\n",
       "         0.0719074 , -0.0471942 ,  0.0421201 ,  0.0141208 , -0.0777014 ,\n",
       "        -0.0146445 ,  0.00400752,  0.0260143 , -0.00261594,  0.0469192 ,\n",
       "         0.0805385 , -0.00496202,  0.054838  ,  0.0321339 , -0.0451871 ,\n",
       "        -0.0779551 ,  0.0632169 ,  0.017503  , -0.0292152 ,  0.0502179 ,\n",
       "         0.0738952 ,  0.00824929, -0.016866  ,  0.0833032 ,  0.0490462 ,\n",
       "         0.00876715,  0.0265123 , -0.0756125 ,  0.0109232 ,  0.0343728 ,\n",
       "        -0.0635191 , -0.0944834 , -0.134888  ,  0.0388934 ,  0.0306603 ,\n",
       "        -0.0274217 , -0.0271636 ,  0.00996759,  0.0296199 , -0.0160004 ,\n",
       "         0.00446631,  0.00351151,  0.0300229 , -0.0550518 ,  0.0585431 ,\n",
       "         0.0479757 , -0.0441973 , -0.125962  , -0.06173   , -0.00171632,\n",
       "         0.00658068, -0.0097914 ,  0.00127772,  0.00236789, -0.169442  ,\n",
       "        -0.018366  , -0.00287901,  0.046348  ,  0.0201398 , -0.0443472 ,\n",
       "         0.0120441 ,  0.0546188 , -0.065135  , -0.0365285 ,  0.0806599 ,\n",
       "         0.0206912 , -0.062004  , -0.079234  , -0.00117932, -0.0722782 ,\n",
       "        -0.0917964 , -0.0325154 , -0.0382184 ,  0.0209148 , -0.0251886 ,\n",
       "         0.175855  ,  0.0204504 ,  0.0540162 , -0.0488119 , -0.056627  ,\n",
       "         0.00146686, -0.0372142 ,  0.0336504 ,  0.0232451 , -0.0685005 ,\n",
       "         0.0839266 ,  0.0171085 ,  0.0129765 ,  0.030358  , -0.0287497 ,\n",
       "        -0.0530213 , -0.129662  ,  0.0290003 ,  0.112636  , -0.0579057 ,\n",
       "         0.00249601, -0.0730132 ,  0.0159781 , -0.157437  ,  0.0698609 ,\n",
       "         0.00483966,  0.030684  ,  0.0980969 ,  0.00324883, -0.0253909 ,\n",
       "         0.0071351 , -0.129196  , -0.00682134,  0.171803  ,  0.0484444 ,\n",
       "         0.107471  , -0.0160338 ,  0.0860085 , -0.0553035 ,  0.149459  ,\n",
       "        -0.00338618,  0.00845435, -0.0592432 , -0.025135  ,  0.0386542 ,\n",
       "         0.00119805, -0.0512249 , -0.0670503 , -0.0102278 ,  0.0208635 ,\n",
       "         0.0515962 , -0.0446853 , -0.0635614 , -0.0415614 ,  0.0524685 ,\n",
       "         0.00504828,  0.00904029,  0.00232449,  0.0496469 ,  0.0124968 ,\n",
       "         0.0890065 , -0.0200749 ,  0.123768  ,  0.0624809 , -0.00671419,\n",
       "         0.0135565 ,  0.0580995 ,  0.0809918 ,  0.0959352 , -0.00374047,\n",
       "         0.093053  ,  0.100496  ,  0.0397303 , -0.0247533 ,  0.0255858 ,\n",
       "         0.0377087 , -0.0681305 , -0.0241296 , -0.0137832 ,  0.0402055 ,\n",
       "         0.110381  , -0.0167643 , -0.0931571 , -0.0172707 , -0.0437315 ,\n",
       "         0.0763397 ,  0.011751  , -0.00297053,  0.0425368 , -0.038946  ,\n",
       "        -0.0723152 , -0.0971534 ,  0.0459774 ,  0.0479438 , -0.0181515 ,\n",
       "        -0.038953  , -0.0162739 , -0.0602028 ,  0.019323  , -0.0197936 ,\n",
       "        -0.110532  ,  0.0227543 ,  0.0169707 , -0.0492143 , -0.0181132 ,\n",
       "         0.0271314 , -0.0151327 , -0.0510236 , -0.0216234 ,  0.00423801,\n",
       "         0.0438398 ,  0.00926403,  0.0705492 , -0.0819977 ,  0.0526854 ,\n",
       "         0.0140824 ,  0.108481  , -0.0586272 , -0.0857516 ,  0.0402011 ,\n",
       "        -0.100283  ,  0.0606247 ,  0.0295759 ,  0.0821655 , -0.0630428 ]),\n",
       " array([ 0.0853956 ,  0.0389108 , -0.129018  ,  0.0522256 ,  0.0061449 ,\n",
       "        -0.0599977 ,  0.0378161 , -0.116264  , -0.0751159 ,  0.0434669 ,\n",
       "        -0.0741452 , -0.0101062 , -0.0606848 ,  0.0390608 ,  0.0531944 ,\n",
       "        -0.064408  ,  0.00688347, -0.0741154 ,  0.0819041 ,  0.141724  ,\n",
       "        -0.00636526,  0.078532  , -0.0552364 , -0.0454727 , -0.0241208 ,\n",
       "        -0.0122665 , -0.0469508 , -0.0451369 , -0.0870011 ,  0.0898835 ,\n",
       "         0.0577244 ,  0.0382811 , -0.00031351,  0.0269347 , -0.0318646 ,\n",
       "        -0.0268951 , -0.0148556 ,  0.0385141 ,  0.0385156 , -0.0221274 ,\n",
       "        -0.0492402 , -0.0339753 ,  0.0669767 , -0.00592187,  0.0109533 ,\n",
       "         0.0539468 ,  0.0535762 , -0.0666564 ,  0.0429336 ,  0.0162293 ,\n",
       "         0.0340322 , -0.13997   , -0.0941886 , -0.103251  , -0.0262293 ,\n",
       "        -0.0490636 ,  0.070773  , -0.00821728,  0.0431434 , -0.0310614 ,\n",
       "        -0.0377809 ,  0.0433155 ,  0.0043688 , -0.0704138 , -0.0409225 ,\n",
       "        -0.0226895 , -0.0366106 , -0.033031  , -0.0442725 , -0.0985653 ,\n",
       "        -0.0606029 , -0.107931  ,  0.0609332 , -0.0828262 ,  0.0379207 ,\n",
       "        -0.0412495 ,  0.0198624 , -0.0217556 , -0.012586  , -0.0336469 ,\n",
       "         0.0938265 , -0.0512656 , -0.0798494 , -0.116601  ,  0.111262  ,\n",
       "        -0.02767   ,  0.0693508 , -0.0791441 , -0.00755601, -0.0813465 ,\n",
       "         0.0363388 , -0.049065  , -0.0218079 ,  0.00367919, -0.0670669 ,\n",
       "         0.0578214 ,  0.0123151 ,  0.0227085 , -0.0668126 ,  0.0843805 ,\n",
       "         0.0801033 , -0.0165232 ,  0.0458159 , -0.0582316 ,  0.0731869 ,\n",
       "        -0.0129899 , -0.108871  , -0.0325511 ,  0.0369404 , -0.0195705 ,\n",
       "        -0.108616  ,  0.0128334 , -0.0232083 , -0.0022683 ,  0.0567731 ,\n",
       "        -0.0469802 , -0.0409356 , -0.0062566 ,  0.00317629,  0.0215603 ,\n",
       "        -0.0246023 ,  0.0315016 , -0.0396096 ,  0.0290894 ,  0.00420932,\n",
       "        -0.0255644 , -0.00405321,  0.00464647, -0.0362412 , -0.0441297 ,\n",
       "         0.0644316 , -0.0157307 , -0.0288484 , -0.0269291 ,  0.0331582 ,\n",
       "         0.138828  , -0.089548  ,  0.00232999, -0.00144495, -0.00112752,\n",
       "         0.011126  ,  0.0622169 ,  0.0725837 ,  0.0226752 , -0.0360858 ,\n",
       "         0.136354  ,  0.0510765 , -0.0668954 ,  0.024007  ,  0.0268526 ,\n",
       "         0.155538  , -0.0497231 , -0.029659  , -0.0291685 , -0.0408554 ,\n",
       "        -0.102187  ,  0.0650865 ,  0.0600641 ,  0.0390556 ,  0.0326915 ,\n",
       "        -0.0199923 ,  0.00838466, -0.118778  , -0.082     ,  0.0249071 ,\n",
       "         0.0162034 , -0.0483916 , -0.00141779, -0.0507148 ,  0.0512343 ,\n",
       "        -0.00068765, -0.126558  ,  0.0078134 , -0.0517721 , -0.055553  ,\n",
       "         0.0576884 , -0.0491254 , -0.0649257 ,  0.0504048 ,  0.0231284 ,\n",
       "        -0.00348157, -0.0504219 ,  0.00243481,  0.0385518 , -0.0749747 ,\n",
       "         0.0437061 , -0.0278526 , -0.0732245 ,  0.0850761 ,  0.0227098 ,\n",
       "        -0.0892938 , -0.0246429 ,  0.00384292,  0.0367803 , -0.0035598 ,\n",
       "         0.0555936 ,  0.0679427 ,  0.1143    , -0.106384  , -0.00957615,\n",
       "        -0.0636824 ,  0.0989324 , -0.00898587,  0.0340789 , -0.0414466 ,\n",
       "        -0.0297998 ,  0.0481566 ,  0.0844108 , -0.0262168 ,  0.032313  ,\n",
       "         0.146125  , -0.020108  , -0.00437052,  0.0100728 , -0.0536287 ,\n",
       "        -0.0932852 ,  0.0414443 , -0.0672745 , -0.0754863 ,  0.0669283 ,\n",
       "         0.0458376 , -0.0576131 , -0.0772694 ,  0.106394  ,  0.0306646 ,\n",
       "         0.00779708, -0.056444  , -0.034516  , -0.0209896 , -0.053091  ,\n",
       "         0.0231107 , -0.0845976 , -0.0126564 , -0.0385768 , -0.0201132 ,\n",
       "        -0.00290299,  0.0337422 , -0.0589231 , -0.0631441 ,  0.0671177 ,\n",
       "         0.137905  , -0.112811  ,  0.0151372 , -0.0481605 , -0.0274786 ,\n",
       "        -0.0233882 ,  0.0340797 , -0.0298784 ,  0.0612519 ,  0.0535269 ,\n",
       "        -0.0229475 , -0.048793  ,  0.0384621 ,  0.078755  , -0.0273539 ,\n",
       "        -0.00888691,  0.00404382, -0.0418291 ,  0.0924965 ,  0.0654603 ,\n",
       "        -0.024632  ,  0.0767541 , -0.00478602,  0.0636504 , -0.139252  ,\n",
       "         0.109766  , -0.00367964, -0.0479898 ,  0.0277282 ,  0.0290434 ,\n",
       "        -0.0311088 , -0.00531586, -0.0717113 ,  0.0011353 ,  0.0376961 ,\n",
       "        -0.0306017 , -0.0282268 ,  0.0274308 ,  0.0562527 , -0.0163562 ,\n",
       "         0.0146553 ,  0.0377449 , -0.0522349 , -0.105001  , -0.0292304 ,\n",
       "        -0.0372784 ,  0.0829094 ,  0.0113036 , -0.100916  ,  0.0767445 ,\n",
       "        -0.0587399 , -0.0232758 ,  0.00909345,  0.0218894 , -0.00879249,\n",
       "        -0.0657436 ,  0.064104  , -0.0497383 ,  0.0594081 , -0.00402358]),\n",
       " array([ 0.00172683,  0.0467167 , -0.0543203 ,  0.0595875 , -0.0566068 ,\n",
       "         0.0223836 ,  0.0507448 ,  0.0255245 ,  0.126772  ,  0.106475  ,\n",
       "         0.0678858 , -0.0744506 ,  0.0441606 , -0.0458201 , -0.0108641 ,\n",
       "         0.00248181, -0.00275894, -0.0596435 , -0.0197418 ,  0.0340541 ,\n",
       "        -0.0142585 , -0.00968671, -0.053102  , -0.0496656 , -0.0504219 ,\n",
       "         0.0164192 ,  0.0857522 , -0.0745537 ,  0.0561234 ,  0.00376456,\n",
       "        -0.0761745 ,  0.122418  , -0.0495499 ,  0.121483  ,  0.0676158 ,\n",
       "        -0.0556961 , -0.00056478, -0.0595557 ,  0.080172  , -0.0993222 ,\n",
       "         0.0457947 , -0.00395399, -0.0654121 ,  0.00943459,  0.02314   ,\n",
       "         0.0154478 , -0.0203013 , -0.0633562 ,  0.0322186 , -0.0198596 ,\n",
       "         0.0171446 ,  0.0255239 , -0.107357  , -0.0224892 , -0.0766141 ,\n",
       "        -0.0169123 ,  0.00391445,  0.0653646 , -0.107899  ,  0.0871805 ,\n",
       "        -0.0191098 , -0.136411  ,  0.0372907 , -0.0325151 ,  0.0417809 ,\n",
       "         0.0312858 , -0.0677322 , -0.0190738 , -0.0991011 , -0.00864124,\n",
       "        -0.0924817 , -0.0326638 , -0.0293627 , -0.0926335 , -0.0531943 ,\n",
       "        -0.0967985 ,  0.100791  ,  0.0826452 ,  0.0399521 , -0.0445901 ,\n",
       "        -0.0310706 ,  0.0408622 , -0.0726993 ,  0.00101365, -0.0367698 ,\n",
       "        -0.0128451 , -0.0433633 ,  0.0722492 ,  0.0598069 , -0.0308803 ,\n",
       "         0.0257444 , -0.0225655 ,  0.0510636 , -0.114247  ,  0.012522  ,\n",
       "         0.0714863 ,  0.0349047 ,  0.0198258 ,  0.0162936 , -0.0419392 ,\n",
       "         0.0144436 , -0.079801  ,  0.107426  , -0.029499  , -0.0846071 ,\n",
       "        -0.0255942 , -0.055638  , -0.00036102, -0.0121625 , -0.0292451 ,\n",
       "         0.0286366 ,  0.0168039 , -0.110971  , -0.0606911 , -0.0250476 ,\n",
       "         0.0218788 ,  0.0494452 ,  0.0449176 , -0.0299938 ,  0.0716486 ,\n",
       "         0.0980655 ,  0.0206164 , -0.00648939,  0.142393  ,  0.0131768 ,\n",
       "         0.0366405 ,  0.0860348 ,  0.0311442 ,  0.0174735 ,  0.0651018 ,\n",
       "         0.107833  ,  0.0498476 , -0.0581344 , -0.0139901 ,  0.049155  ,\n",
       "         0.0603339 , -0.0205224 ,  0.084592  , -0.0595651 ,  0.0566015 ,\n",
       "        -0.0519616 ,  0.112607  ,  0.0325117 , -0.0615162 ,  0.109877  ,\n",
       "         0.10342   , -0.0552064 , -0.0339963 , -0.00869386,  0.0124443 ,\n",
       "         0.0272701 , -0.0872845 , -0.0396317 ,  0.0474661 , -0.0462613 ,\n",
       "        -0.0505247 , -0.0594664 ,  0.00491263,  0.109799  ,  0.0231026 ,\n",
       "        -0.0111932 ,  0.076038  , -0.0420705 ,  0.106942  ,  0.129548  ,\n",
       "        -0.0873287 ,  0.0212109 , -0.0428269 ,  0.0970033 , -0.0576271 ,\n",
       "        -0.0378131 ,  0.0475752 ,  0.0173795 , -0.00470522, -0.0210793 ,\n",
       "         0.0614343 ,  0.0800316 ,  0.106712  , -0.025002  , -0.0471898 ,\n",
       "         0.0564943 , -0.10615   ,  0.0032406 ,  0.0338243 ,  0.0149823 ,\n",
       "         0.136691  ,  0.00098089, -0.0976895 ,  0.0622845 , -0.0490685 ,\n",
       "        -0.0139349 , -0.0285229 ,  0.0584106 ,  0.0417294 , -0.00582659,\n",
       "         0.0503326 , -0.0226377 ,  0.0640525 , -0.083203  , -0.0199262 ,\n",
       "         0.0787546 , -0.101946  , -0.0110837 ,  0.0349492 ,  0.00198282,\n",
       "        -0.0352917 , -0.086095  , -0.020543  ,  0.113528  ,  0.0133433 ,\n",
       "         0.0981874 ,  0.0003345 ,  0.033248  , -0.0616933 , -0.017008  ,\n",
       "         0.00382966, -0.0220187 , -0.152866  , -0.0531377 , -0.012374  ,\n",
       "        -0.0130999 , -0.103336  , -0.017717  ,  0.0199768 , -0.0105854 ,\n",
       "         0.00837396, -0.0829077 , -0.0634469 ,  0.0616746 ,  0.0707397 ,\n",
       "         0.0346803 ,  0.0663338 , -0.0523185 , -0.0957604 , -0.0782568 ,\n",
       "         0.0653867 ,  0.0170821 , -0.00820826,  0.00444793,  0.0100975 ,\n",
       "         0.0192325 , -0.00564054,  0.0207489 , -0.0447318 ,  0.0782647 ,\n",
       "         0.0312818 ,  0.0392374 , -0.0457159 , -0.00194437,  0.0371991 ,\n",
       "        -0.0114332 ,  0.00053552, -0.0791993 , -0.0285001 , -0.0709748 ,\n",
       "        -0.0488981 ,  0.0270425 , -0.0213458 ,  0.00810683,  0.0668602 ,\n",
       "        -0.0264015 ,  0.0383047 , -0.00205679, -0.0197941 , -0.035353  ,\n",
       "        -0.0192435 , -0.003007  ,  0.0652719 ,  0.0669366 ,  0.00561999,\n",
       "        -0.0283886 , -0.00271127,  0.0415612 ,  0.0291423 , -0.0614731 ,\n",
       "        -0.0226038 , -0.0030778 ,  0.127466  , -0.0110655 ,  0.0214128 ,\n",
       "         0.0871796 ,  0.0287086 ,  0.0890645 ,  0.0838803 ,  0.0489782 ,\n",
       "         0.0270385 ,  0.040845  ,  0.0141638 , -0.0372664 ,  0.041792  ,\n",
       "         0.0840003 , -0.0541354 ,  0.101925  ,  0.0646035 ,  0.00785695,\n",
       "        -0.0309435 ,  0.00028286,  0.0315602 , -0.0136776 , -0.00925541]),\n",
       " array([ 2.32777e-02, -5.82365e-02, -2.55849e-02,  3.52706e-02,\n",
       "        -9.41430e-02,  9.30855e-02, -9.65273e-03, -4.89918e-02,\n",
       "        -6.52687e-03,  3.62688e-02, -6.14942e-02,  5.16494e-02,\n",
       "        -6.24615e-02,  4.00829e-02, -3.13521e-02, -1.02050e-01,\n",
       "         4.07718e-02, -8.31719e-02, -4.42855e-03,  8.52695e-02,\n",
       "         1.44708e-02,  6.28997e-02, -3.58020e-02, -4.55959e-02,\n",
       "        -5.02941e-02,  8.49728e-03, -3.82439e-02, -3.88803e-02,\n",
       "         9.98474e-02,  1.18966e-01,  3.42784e-02,  1.35968e-01,\n",
       "        -5.45472e-02,  8.00898e-02,  4.94159e-02, -8.24977e-02,\n",
       "         9.10835e-02, -7.59660e-02,  6.55531e-02, -7.04290e-02,\n",
       "         4.42011e-03, -1.24294e-01, -9.11191e-02,  2.93893e-02,\n",
       "         8.13042e-03,  6.93639e-03,  9.59758e-02, -3.44580e-02,\n",
       "         2.54550e-02,  2.31445e-02,  9.35799e-02, -1.92681e-03,\n",
       "        -8.57195e-02, -1.10167e-02, -1.69863e-03, -3.89213e-02,\n",
       "        -5.13032e-02,  8.49734e-03, -2.11261e-02,  8.61415e-02,\n",
       "        -2.99401e-02, -1.94334e-03,  1.69893e-01, -7.59056e-02,\n",
       "        -7.12575e-02, -1.79102e-02, -4.30978e-02,  4.38240e-02,\n",
       "        -1.10716e-02,  7.15704e-02,  2.28032e-02,  3.92230e-03,\n",
       "         3.02913e-05, -1.06869e-01, -2.97405e-02,  3.66159e-02,\n",
       "         1.50316e-01,  5.85943e-02,  4.78543e-02, -4.01812e-02,\n",
       "         6.05140e-02, -6.32524e-02, -2.00453e-02, -1.89204e-02,\n",
       "        -6.54747e-02,  1.57083e-03, -9.45214e-02,  1.37306e-01,\n",
       "         1.25843e-03, -5.20874e-02, -5.89175e-02, -1.91084e-02,\n",
       "         1.40717e-01, -7.34795e-02,  1.63264e-02,  6.48854e-02,\n",
       "         8.96744e-02, -3.50463e-02, -6.78436e-02,  1.07051e-01,\n",
       "        -2.27492e-02, -5.39174e-02, -5.68076e-02,  3.75925e-02,\n",
       "         4.27501e-02, -1.03868e-03, -2.09347e-02,  5.11567e-03,\n",
       "        -7.29060e-02,  3.60068e-02, -1.71712e-02, -9.66825e-03,\n",
       "        -6.93639e-03,  6.82537e-03,  6.64466e-03, -5.10363e-02,\n",
       "         7.81091e-02, -9.59766e-02,  9.92474e-02,  3.86877e-02,\n",
       "         7.05177e-02,  4.33654e-02,  6.21277e-02,  4.73635e-02,\n",
       "        -1.02569e-01, -1.25069e-01,  4.22893e-02,  7.65997e-02,\n",
       "         1.49004e-02,  4.70484e-02,  2.16944e-02,  5.83698e-02,\n",
       "        -9.80633e-02,  2.50847e-02,  5.93538e-03,  5.06375e-02,\n",
       "        -4.93570e-02,  1.88363e-02,  1.65819e-02,  5.00206e-04,\n",
       "         1.16822e-01,  1.08569e-01, -1.65814e-02, -4.17712e-02,\n",
       "         2.70016e-02,  2.48236e-02, -1.03210e-02, -1.55535e-02,\n",
       "         9.52332e-03,  3.73608e-02,  4.71893e-02, -6.65121e-02,\n",
       "        -4.53620e-02, -5.13461e-03, -5.62582e-02, -1.45762e-02,\n",
       "        -1.19258e-01, -1.32747e-02,  5.25293e-02, -1.18050e-02,\n",
       "        -4.46538e-02,  4.32720e-02, -7.78805e-02,  9.08838e-02,\n",
       "        -1.74768e-02,  2.76308e-02, -5.15544e-02, -3.62613e-02,\n",
       "         4.94335e-02,  4.56230e-02,  2.83864e-02, -3.11383e-02,\n",
       "         6.69384e-03,  4.40171e-02, -2.47110e-02,  4.76394e-02,\n",
       "        -1.47043e-02, -7.27936e-02, -1.86999e-02,  4.48291e-02,\n",
       "        -3.43217e-02,  3.64799e-02,  4.83867e-02,  4.56212e-03,\n",
       "        -7.09248e-04, -1.10441e-01, -6.56688e-02, -7.41192e-02,\n",
       "         3.62616e-02, -2.39979e-02,  4.14753e-02, -1.01291e-01,\n",
       "        -3.04865e-02,  3.22052e-02, -5.08679e-02, -5.53387e-02,\n",
       "        -1.84106e-02, -3.62564e-02, -4.74185e-02, -3.50154e-02,\n",
       "        -2.29894e-02, -1.41847e-02, -9.54973e-02, -3.68568e-02,\n",
       "         8.85346e-03, -1.15170e-01, -6.09927e-02, -3.28227e-02,\n",
       "         1.75065e-02,  6.79846e-02,  1.51647e-01, -8.32478e-02,\n",
       "        -5.73581e-02, -6.26854e-02,  5.73139e-02, -4.47763e-02,\n",
       "        -2.84931e-02,  5.22670e-02,  1.61304e-02,  4.58340e-02,\n",
       "        -1.88179e-02,  1.52347e-02, -4.03391e-02,  3.31892e-02,\n",
       "         1.94405e-02,  2.18348e-02, -8.98425e-03, -3.83257e-02,\n",
       "        -6.40711e-02,  3.22954e-02,  3.33557e-02, -3.39058e-02,\n",
       "         6.11598e-02,  2.49765e-02,  4.94307e-02, -5.76056e-02,\n",
       "         7.79442e-03,  1.24649e-02,  2.81299e-02, -3.01354e-03,\n",
       "         8.37586e-02, -1.43407e-02,  6.06970e-02, -1.09938e-01,\n",
       "        -2.99835e-02,  1.11040e-01,  1.38269e-02,  9.66177e-03,\n",
       "        -1.01694e-01,  1.20166e-01,  5.76947e-02, -5.18300e-02,\n",
       "        -3.91123e-02,  7.70969e-03, -5.17715e-03,  5.39152e-02,\n",
       "         5.82678e-02, -1.87058e-01,  7.45775e-02,  8.92669e-03,\n",
       "         2.49177e-02,  2.67723e-02, -4.41101e-02, -2.70502e-03,\n",
       "        -8.89876e-03,  2.40445e-02, -8.98959e-03, -1.36213e-01,\n",
       "        -5.03472e-02, -1.78854e-02,  3.16159e-02,  4.78710e-02,\n",
       "        -4.74842e-03,  6.57894e-03, -3.24504e-02, -2.12243e-02,\n",
       "         2.63615e-02,  1.03767e-02,  1.00726e-02,  3.09786e-02,\n",
       "        -3.91137e-02, -3.02962e-02, -1.38360e-02, -1.50567e-02,\n",
       "         1.00337e-01,  6.70885e-02,  7.48981e-02,  4.67345e-02,\n",
       "         9.79357e-03,  8.43076e-02, -7.19179e-02, -4.74906e-02,\n",
       "         6.24078e-02, -2.25565e-04, -2.50809e-02,  7.67186e-03,\n",
       "         2.92838e-02, -2.43577e-02,  1.95169e-02,  3.46617e-02])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(working_df['content_y'].shape[0]):\n",
    "    working_df['content_y'][i] = [x if type(x) == np.ndarray else np.array([-1000.5]*300) for x in working_df['content_y'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\pandas\\core\\frame.py:4301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "working_df = working_df[['sex', 'content_y']]\n",
    "working_df.rename(columns={\"content_y\": \"content\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = working_df[['content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = working_df['sex']\n",
    "X_train2, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "# Création des données cibles.\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treating_X(X):\n",
    "    X = X.reset_index().drop('index', axis=1)\n",
    "    maxi = 0\n",
    "    for i in range(len(X['content'])):\n",
    "        if len(X['content'][i]) > maxi:\n",
    "            maxi = len(X['content'][i])\n",
    "    c = np.zeros((X.shape[0], maxi, 300))\n",
    "    i = 0\n",
    "    for element in X['content']:\n",
    "        a_len = len(element)\n",
    "        a = np.array(element)\n",
    "        c[i][:a_len] = a\n",
    "        i+=1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.45 GiB for an array with shape (11148, 58, 300) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-b3be7f682e93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#c = treating_X(X_train2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mc_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtreating_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-143-3799f0ab5aaf>\u001b[0m in \u001b[0;36mtreating_X\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmaxi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mmaxi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.45 GiB for an array with shape (11148, 58, 300) and data type float64"
     ]
    }
   ],
   "source": [
    "#c = treating_X(X_train2)\n",
    "c_test = treating_X(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "def init_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking(mask_value = 0))\n",
    "    model.add(layers.LSTM(100, dropout=0.25, recurrent_dropout=0.25, activation='tanh'))\n",
    "    model.add(layers.Dense(128, activation='tanh'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26011, 58, 300)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18207 samples, validate on 7804 samples\n",
      "Epoch 1/1000\n",
      "18207/18207 [==============================] - 123s 7ms/sample - loss: 0.6905 - acc: 0.5476 - val_loss: 0.6869 - val_acc: 0.5645\n",
      "Epoch 2/1000\n",
      "18207/18207 [==============================] - 116s 6ms/sample - loss: 0.6879 - acc: 0.5517 - val_loss: 0.6985 - val_acc: 0.5645\n",
      "Epoch 3/1000\n",
      "18207/18207 [==============================] - 113s 6ms/sample - loss: 0.6877 - acc: 0.5551 - val_loss: 0.6858 - val_acc: 0.5645\n",
      "Epoch 4/1000\n",
      "18207/18207 [==============================] - 110s 6ms/sample - loss: 0.6871 - acc: 0.5574 - val_loss: 0.6861 - val_acc: 0.5642\n",
      "Epoch 5/1000\n",
      "18207/18207 [==============================] - 106s 6ms/sample - loss: 0.6852 - acc: 0.5596 - val_loss: 0.6855 - val_acc: 0.5643\n",
      "Epoch 6/1000\n",
      "18207/18207 [==============================] - 106s 6ms/sample - loss: 0.6838 - acc: 0.5585 - val_loss: 0.6899 - val_acc: 0.5639\n",
      "Epoch 7/1000\n",
      "11296/18207 [=================>............] - ETA: 32s - loss: 0.6817 - acc: 0.5678"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-abd5b337d878>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience = 10, monitor='val_loss', restore_best_weights=True)\n",
    "model = init_model()\n",
    "model.fit(c, y_train, batch_size = 32, epochs=1000, validation_split = 0.3, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11148/11148 [==============================] - 16s 1ms/sample - loss: 0.4793 - acc: 0.8167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47929147977661307, 0.8167384]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(c_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record à 16.36% avec ce modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "def init_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking(mask_value = 0))\n",
    "    model.add(layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2, activation='tanh'))\n",
    "    model.add(layers.Dense(128, activation='tanh'))\n",
    "    model.add(layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_record = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement de la base de données finale vectorisée en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = pd.read_hdf('../../raw_data/full_mean_df_hdf.h5', 'h5').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " age_list = [47, 51, 42, 56, 27, 44, 59, 52, 34, 60, 41, 57, 63,\\\n",
    "           53, 45, 48, 47, 53, 30, 75, 57, 44, 47, 24, 51, 54, 68,\\\n",
    "           49, 42, 50, 49, 40, 34, 34, 38, 44, 37, 54, 56, 61, 83,\\\n",
    "          44, 45, 59, 45, 67, 53, 48, 33, 42, 32, 57, 34, 47, 40, 48,\\\n",
    "          39, 49, 43, 35, 52, 63, 61, 50, 27, 50, 45, 80, 45, 50, 46,\\\n",
    "          59, 41, 47, 65, 51, 44, 34, 68, 37, 31, 57, 35, 37, 65, 57,\\\n",
    "          48, 61, 55, 72, 49, 45, 36, 58, 32, 57, 30, 57, 62, 44, 36, 51,\\\n",
    "          49, 54, 48, 62, 43, 43, 41, 36, 57, 54, 44, 44, 32, 33, 51, 51,\\\n",
    "          51, 56, 56, 43, 41, 43, 61, 63, 44, 36, 49, 49, 54, 42, 55, 53,\\\n",
    "          41, 62, 36, 19, 43, 56, 51, 70, 48, 51, 27, 46, 44, 53, 35, 35,\\\n",
    "          31, 60, 50, 31, 47, 43, 76, 45, 45, 53, 66, 52, 45, 45, 51, 40, 44,\\\n",
    "          48, 56, 56, 65, 27, 48, 39, 55, 35, 44, 40, 43, 52, 31, 50, 53, 58,\\\n",
    "          38, 59, 34, 52, 53, 46, 49, 58, 43, 55, 58, 26, 62, 72, 41, 36, 48,\\\n",
    "          56, 53, 61, 63, 59, 45, 45, 59, 46, 31, 62, 62, 41,\\\n",
    "          67, 44, 40, 62, 40, 49, 53, 61, 60, 38, 68, 54, 57,\\\n",
    "          37, 33, 50, 40, 63, 30, 45, 67, 57, 52, 43, 63, 64,\\\n",
    "          48, 63, 35, 68, 34, 53, 44, 48, 41, 54, 64, 45, 40,\\\n",
    "          41, 55, 61, 42, 46, 68, 36, 69, 47, 71, 55, 42, 52,\\\n",
    "          55, 34, 59, 75, 50, 39, 53, 50, 49, 61, 47, 29, 45,\\\n",
    "          62, 30, 64, 41, 62, 68, 32, 66, 44, 52, 44, 58, 59,\\\n",
    "          47, 58, 34, 66, 39, 70, 54, 41, 64, 43, 65, 74, 38,\\\n",
    "          46, 56, 47, 57, 38, 40, 35, 36, 57, 54, 44, 61, 32,\\\n",
    "          65, 42, 67, 50, 58, 46, 38, 65, 62, 53, 51, 58, 34,\\\n",
    "          29, 22, 53, 39, 59, 57, 61, 36, 55, 41, 71, 40, 49,\\\n",
    "          63, 44, 57, 49, 41, 65, 52, 54, 46, 33, 30, 45, 61,\\\n",
    "          65, 73, 56, 62, 56, 31, 53, 50, 56, 54, 51, 46, 48,\\\n",
    "          72, 59, 47, 60, 46, 72, 37, 59, 45, 53, 51, 48, 66, 67,\\\n",
    "          37, 41, 47, 35, 36, 34, 57, 36, 41, 60, 34, 54, 56, 37,\\\n",
    "          43, 48, 55, 44, 54, 54, 58, 38, 58, 41, 57, 33, 67, 53,\\\n",
    "          57, 41, 41, 48, 62, 38, 66, 46, 42, 70, 62, 54, 53, 75,\\\n",
    "          45, 33, 64, 45, 40, 38, 68, 30, 48, 37, 55, 67, 40, 37,\\\n",
    "          42, 49, 48, 50, 59, 57, 63, 55, 57, 38, 64, 33, 57, 51,\\\n",
    "          63, 48, 37, 52, 56, 57, 58, 57, 34, 34, 46, 57, 34, 60,\\\n",
    "          70, 40, 56, 63, 61, 50, 58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_femme = [0, 2, 3, 4, 7, 13, 16, 17, 18 , 19, 24, 29, 30, 31, 34, 35, 43, 45, 47, 49, 53, 55, 59, 61, 62, 64,\\\n",
    "         73, 74, 78, 79, 80, 81, 83, 84, 86, 87, 88, 94, 96, 99, 101, 106, 108, 109, 110, 113, 115, 116, 120, 121, 125, 127, 128, 129, 130,\\\n",
    "        136, 141, 146, 152, 153, 154, 157, 160, 161, 164, 166, 170, 171, 172, 177, 180, 186,\\\n",
    "        187, 188, 191, 195, 197, 198, 201, 205, 206, 208, 209, 210, 211, 213, 214, 216, 219, 220, 222,\\\n",
    "        223, 225, 226, 228, 231, 235, 240, 248, 251, 252, 253, 256, 258, 261, 265, 272, 275, 278, 279, 280,\\\n",
    "        286, 289, 294, 296, 297, 299, 300, 304, 305, 306, 307, 310, 312, 313, 316, 318, 322, 327, 331, 332, 334,\\\n",
    "        337, 338, 340, 343, 343, 344, 349, 351, 352, 355, 356, 360, 361, 363, 365, 367, 374, 376, 379, 381, 383, 384,\\\n",
    "        388, 393, 394, 396, 399, 401, 402, 406, 407, 408, 409, 414, 415, 417, 418, 419, 421, 422, 423, 424, 426, 427,\\\n",
    "        432, 433, 434, 435, 436, 438, 441, 442, 443, 446, 447, 448, 451, 452, 457, 458, 459, 460, 461, 463, 464, 468]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wonderful_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c2d5faa92a0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdico\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mage\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_countries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdico\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mwonderful_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"age\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwonderful_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdico\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wonderful_df' is not defined"
     ]
    }
   ],
   "source": [
    "dico = {name:age for name, age in zip(all_countries.name.unique(), age_list)}\n",
    "for name in dico.keys():\n",
    "    wonderful_df[\"age\"] = wonderful_df.name.map(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4efee32861f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdico\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msex\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_countries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdico\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mall_countries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sex\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_countries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdico\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreal_dict_femme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mreel_list_femme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-4efee32861f1>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdico\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msex\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_countries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdico\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mall_countries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sex\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_countries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdico\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreal_dict_femme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mreel_list_femme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sex' is not defined"
     ]
    }
   ],
   "source": [
    "dico = {name:sex for name, age in zip(all_countries.name.unique(), age_list)}\n",
    "for name in dico.keys():\n",
    "    all_countries[\"sex\"] = all_countries.name.map(dico)\n",
    "real_dict_femme = {key:name for key,name in enumerate(tweet_df.name)}\n",
    "reel_list_femme = []\n",
    "for i in key_femme:\n",
    "    reel_list_femme.append(real_dict_femme[i])\n",
    "ll = [1] * len(key_femme)\n",
    "dict_femme = {name:key for name, key in zip(reel_list_femme,ll)}\n",
    "for name in all_countries['name'].unique():\n",
    "    if name in dict_femme.keys():\n",
    "        all_countries[\"sex\"] = all_countries['name'].map(dict_femme)\n",
    "all_countries['sex'] = all_countries['sex'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2888\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2889\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-4d52d8cfb511>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mherbe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_countries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_countries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age'"
     ]
    }
   ],
   "source": [
    "test = np.arange(0,300,1)\n",
    "herbe = all_countries[test]\n",
    "y = all_countries['age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         47\n",
       "1         47\n",
       "2         47\n",
       "3         47\n",
       "4         47\n",
       "          ..\n",
       "137295    58\n",
       "137296    58\n",
       "137297    58\n",
       "137298    58\n",
       "137299    58\n",
       "Name: age, Length: 115656, dtype: int64"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train3, X_test, y_train, y_test = train_test_split(herbe, y, test_size = 0.3)\n",
    "# Création des données cibles.\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "X_train3 = np.array(X_train3)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend\n",
    "backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "def init_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    #model.add(layers.GRU(units=27, activation='tanh'))\n",
    "    #model.add(layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2, activation='tanh'))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "              optimizer='adam', \n",
    "              metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80959, 300)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80959,)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56671 samples, validate on 24288 samples\n",
      "Epoch 1/1000\n",
      "56671/56671 [==============================] - 6s 99us/sample - loss: 1977.8251 - mean_absolute_error: 42.8566 - val_loss: 1462.9929 - val_mean_absolute_error: 36.5133\n",
      "Epoch 2/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 1086.6392 - mean_absolute_error: 30.7420 - val_loss: 761.5781 - val_mean_absolute_error: 25.0913\n",
      "Epoch 3/1000\n",
      "56671/56671 [==============================] - 5s 94us/sample - loss: 540.9730 - mean_absolute_error: 20.2083 - val_loss: 361.2313 - val_mean_absolute_error: 15.7543\n",
      "Epoch 4/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 260.0430 - mean_absolute_error: 12.9784 - val_loss: 188.9491 - val_mean_absolute_error: 10.9223\n",
      "Epoch 5/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 162.3263 - mean_absolute_error: 10.1306 - val_loss: 149.0507 - val_mean_absolute_error: 9.7180\n",
      "Epoch 6/1000\n",
      "56671/56671 [==============================] - 5s 93us/sample - loss: 144.6725 - mean_absolute_error: 9.5940 - val_loss: 142.8320 - val_mean_absolute_error: 9.5362\n",
      "Epoch 7/1000\n",
      "56671/56671 [==============================] - 6s 106us/sample - loss: 139.8028 - mean_absolute_error: 9.4629 - val_loss: 138.7456 - val_mean_absolute_error: 9.4392\n",
      "Epoch 8/1000\n",
      "56671/56671 [==============================] - 7s 117us/sample - loss: 136.1856 - mean_absolute_error: 9.3780 - val_loss: 135.7013 - val_mean_absolute_error: 9.3688\n",
      "Epoch 9/1000\n",
      "56671/56671 [==============================] - 7s 116us/sample - loss: 133.5254 - mean_absolute_error: 9.3143 - val_loss: 133.4907 - val_mean_absolute_error: 9.3140\n",
      "Epoch 10/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 131.6054 - mean_absolute_error: 9.2693 - val_loss: 131.8543 - val_mean_absolute_error: 9.2778\n",
      "Epoch 11/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 130.1500 - mean_absolute_error: 9.2377 - val_loss: 130.6196 - val_mean_absolute_error: 9.2471\n",
      "Epoch 12/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 129.0689 - mean_absolute_error: 9.2117 - val_loss: 129.6878 - val_mean_absolute_error: 9.2204\n",
      "Epoch 13/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 128.2359 - mean_absolute_error: 9.1879 - val_loss: 128.9692 - val_mean_absolute_error: 9.1986\n",
      "Epoch 14/1000\n",
      "56671/56671 [==============================] - 5s 92us/sample - loss: 127.5863 - mean_absolute_error: 9.1679 - val_loss: 128.4100 - val_mean_absolute_error: 9.1803\n",
      "Epoch 15/1000\n",
      "56671/56671 [==============================] - 5s 93us/sample - loss: 127.0725 - mean_absolute_error: 9.1503 - val_loss: 127.9697 - val_mean_absolute_error: 9.1633\n",
      "Epoch 16/1000\n",
      "56671/56671 [==============================] - 6s 99us/sample - loss: 126.6758 - mean_absolute_error: 9.1363 - val_loss: 127.6244 - val_mean_absolute_error: 9.1515\n",
      "Epoch 17/1000\n",
      "56671/56671 [==============================] - 5s 92us/sample - loss: 126.3456 - mean_absolute_error: 9.1248 - val_loss: 127.3371 - val_mean_absolute_error: 9.1396\n",
      "Epoch 18/1000\n",
      "56671/56671 [==============================] - 5s 92us/sample - loss: 126.0745 - mean_absolute_error: 9.1154 - val_loss: 127.1114 - val_mean_absolute_error: 9.1343\n",
      "Epoch 19/1000\n",
      "56671/56671 [==============================] - 5s 92us/sample - loss: 125.8490 - mean_absolute_error: 9.1073 - val_loss: 126.9301 - val_mean_absolute_error: 9.1302\n",
      "Epoch 20/1000\n",
      "56671/56671 [==============================] - 5s 94us/sample - loss: 125.6561 - mean_absolute_error: 9.1024 - val_loss: 126.7486 - val_mean_absolute_error: 9.1236\n",
      "Epoch 21/1000\n",
      "56671/56671 [==============================] - 5s 91us/sample - loss: 125.4875 - mean_absolute_error: 9.0974 - val_loss: 126.5937 - val_mean_absolute_error: 9.1175\n",
      "Epoch 22/1000\n",
      "56671/56671 [==============================] - 5s 90us/sample - loss: 125.3418 - mean_absolute_error: 9.0937 - val_loss: 126.4732 - val_mean_absolute_error: 9.1163\n",
      "Epoch 23/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 125.2073 - mean_absolute_error: 9.0909 - val_loss: 126.3543 - val_mean_absolute_error: 9.1111\n",
      "Epoch 24/1000\n",
      "56671/56671 [==============================] - 5s 97us/sample - loss: 125.0933 - mean_absolute_error: 9.0864 - val_loss: 126.2605 - val_mean_absolute_error: 9.1109\n",
      "Epoch 25/1000\n",
      "56671/56671 [==============================] - 6s 110us/sample - loss: 124.9873 - mean_absolute_error: 9.0844 - val_loss: 126.1740 - val_mean_absolute_error: 9.1094\n",
      "Epoch 26/1000\n",
      "56671/56671 [==============================] - 5s 97us/sample - loss: 124.8883 - mean_absolute_error: 9.0826 - val_loss: 126.0832 - val_mean_absolute_error: 9.1032\n",
      "Epoch 27/1000\n",
      "56671/56671 [==============================] - 5s 91us/sample - loss: 124.7975 - mean_absolute_error: 9.0796 - val_loss: 126.0131 - val_mean_absolute_error: 9.1003\n",
      "Epoch 28/1000\n",
      "56671/56671 [==============================] - 5s 92us/sample - loss: 124.7213 - mean_absolute_error: 9.0770 - val_loss: 125.9442 - val_mean_absolute_error: 9.1022\n",
      "Epoch 29/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 124.6446 - mean_absolute_error: 9.0756 - val_loss: 125.8795 - val_mean_absolute_error: 9.0991\n",
      "Epoch 30/1000\n",
      "56671/56671 [==============================] - 6s 101us/sample - loss: 124.5598 - mean_absolute_error: 9.0729 - val_loss: 125.8382 - val_mean_absolute_error: 9.0947\n",
      "Epoch 31/1000\n",
      "56671/56671 [==============================] - 5s 92us/sample - loss: 124.5094 - mean_absolute_error: 9.0713 - val_loss: 125.7725 - val_mean_absolute_error: 9.0986\n",
      "Epoch 32/1000\n",
      "56671/56671 [==============================] - 5s 94us/sample - loss: 124.4411 - mean_absolute_error: 9.0703 - val_loss: 125.7602 - val_mean_absolute_error: 9.1027\n",
      "Epoch 33/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 124.3941 - mean_absolute_error: 9.0700 - val_loss: 125.6757 - val_mean_absolute_error: 9.0961\n",
      "Epoch 34/1000\n",
      "56671/56671 [==============================] - 5s 91us/sample - loss: 124.3356 - mean_absolute_error: 9.0687 - val_loss: 125.6299 - val_mean_absolute_error: 9.0937\n",
      "Epoch 35/1000\n",
      "56671/56671 [==============================] - 5s 91us/sample - loss: 124.2897 - mean_absolute_error: 9.0662 - val_loss: 125.5932 - val_mean_absolute_error: 9.0942\n",
      "Epoch 36/1000\n",
      "56671/56671 [==============================] - 5s 91us/sample - loss: 124.2339 - mean_absolute_error: 9.0649 - val_loss: 125.5820 - val_mean_absolute_error: 9.0974\n",
      "Epoch 37/1000\n",
      "56671/56671 [==============================] - 5s 90us/sample - loss: 124.1910 - mean_absolute_error: 9.0643 - val_loss: 125.5249 - val_mean_absolute_error: 9.0935\n",
      "Epoch 38/1000\n",
      "56671/56671 [==============================] - 5s 91us/sample - loss: 124.1522 - mean_absolute_error: 9.0640 - val_loss: 125.4924 - val_mean_absolute_error: 9.0926\n",
      "Epoch 39/1000\n",
      "56671/56671 [==============================] - 6s 97us/sample - loss: 124.1097 - mean_absolute_error: 9.0623 - val_loss: 125.4583 - val_mean_absolute_error: 9.0910\n",
      "Epoch 40/1000\n",
      "56671/56671 [==============================] - 6s 99us/sample - loss: 124.0734 - mean_absolute_error: 9.0619 - val_loss: 125.4258 - val_mean_absolute_error: 9.0893\n",
      "Epoch 41/1000\n",
      "56671/56671 [==============================] - 6s 111us/sample - loss: 124.0351 - mean_absolute_error: 9.0613 - val_loss: 125.3986 - val_mean_absolute_error: 9.0859\n",
      "Epoch 42/1000\n",
      "56671/56671 [==============================] - 6s 99us/sample - loss: 124.0055 - mean_absolute_error: 9.0597 - val_loss: 125.3733 - val_mean_absolute_error: 9.0879\n",
      "Epoch 43/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.9772 - mean_absolute_error: 9.0587 - val_loss: 125.3589 - val_mean_absolute_error: 9.0896\n",
      "Epoch 44/1000\n",
      "56671/56671 [==============================] - 6s 103us/sample - loss: 123.9444 - mean_absolute_error: 9.0589 - val_loss: 125.3252 - val_mean_absolute_error: 9.0858\n",
      "Epoch 45/1000\n",
      "56671/56671 [==============================] - 6s 100us/sample - loss: 123.9116 - mean_absolute_error: 9.0574 - val_loss: 125.3211 - val_mean_absolute_error: 9.0894\n",
      "Epoch 46/1000\n",
      "56671/56671 [==============================] - 6s 100us/sample - loss: 123.8879 - mean_absolute_error: 9.0572 - val_loss: 125.2830 - val_mean_absolute_error: 9.0841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "56671/56671 [==============================] - 6s 110us/sample - loss: 123.8635 - mean_absolute_error: 9.0559 - val_loss: 125.2716 - val_mean_absolute_error: 9.0868\n",
      "Epoch 48/1000\n",
      "56671/56671 [==============================] - 6s 108us/sample - loss: 123.8394 - mean_absolute_error: 9.0560 - val_loss: 125.2464 - val_mean_absolute_error: 9.0843\n",
      "Epoch 49/1000\n",
      "56671/56671 [==============================] - 7s 127us/sample - loss: 123.8155 - mean_absolute_error: 9.0550 - val_loss: 125.2396 - val_mean_absolute_error: 9.0864\n",
      "Epoch 50/1000\n",
      "56671/56671 [==============================] - 6s 113us/sample - loss: 123.7936 - mean_absolute_error: 9.0543 - val_loss: 125.2243 - val_mean_absolute_error: 9.0862\n",
      "Epoch 51/1000\n",
      "56671/56671 [==============================] - 6s 108us/sample - loss: 123.7682 - mean_absolute_error: 9.0538 - val_loss: 125.2081 - val_mean_absolute_error: 9.0857\n",
      "Epoch 52/1000\n",
      "56671/56671 [==============================] - 6s 109us/sample - loss: 123.7500 - mean_absolute_error: 9.0540 - val_loss: 125.1823 - val_mean_absolute_error: 9.0830\n",
      "Epoch 53/1000\n",
      "56671/56671 [==============================] - 5s 94us/sample - loss: 123.7331 - mean_absolute_error: 9.0530 - val_loss: 125.1678 - val_mean_absolute_error: 9.0825\n",
      "Epoch 54/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.7131 - mean_absolute_error: 9.0525 - val_loss: 125.1636 - val_mean_absolute_error: 9.0843\n",
      "Epoch 55/1000\n",
      "56671/56671 [==============================] - 6s 97us/sample - loss: 123.6875 - mean_absolute_error: 9.0521 - val_loss: 125.1413 - val_mean_absolute_error: 9.0802\n",
      "Epoch 56/1000\n",
      "56671/56671 [==============================] - 6s 99us/sample - loss: 123.6768 - mean_absolute_error: 9.0516 - val_loss: 125.1286 - val_mean_absolute_error: 9.0812\n",
      "Epoch 57/1000\n",
      "56671/56671 [==============================] - 6s 98us/sample - loss: 123.6578 - mean_absolute_error: 9.0512 - val_loss: 125.1145 - val_mean_absolute_error: 9.0800\n",
      "Epoch 58/1000\n",
      "56671/56671 [==============================] - 5s 97us/sample - loss: 123.6444 - mean_absolute_error: 9.0506 - val_loss: 125.1096 - val_mean_absolute_error: 9.0821\n",
      "Epoch 59/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 123.6279 - mean_absolute_error: 9.0504 - val_loss: 125.0922 - val_mean_absolute_error: 9.0800\n",
      "Epoch 60/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.6121 - mean_absolute_error: 9.0501 - val_loss: 125.0883 - val_mean_absolute_error: 9.0815\n",
      "Epoch 61/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.5997 - mean_absolute_error: 9.0500 - val_loss: 125.0705 - val_mean_absolute_error: 9.0797\n",
      "Epoch 62/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.5820 - mean_absolute_error: 9.0486 - val_loss: 125.0857 - val_mean_absolute_error: 9.0837\n",
      "Epoch 63/1000\n",
      "56671/56671 [==============================] - 5s 94us/sample - loss: 123.5700 - mean_absolute_error: 9.0493 - val_loss: 125.0499 - val_mean_absolute_error: 9.0787\n",
      "Epoch 64/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.5557 - mean_absolute_error: 9.0482 - val_loss: 125.0444 - val_mean_absolute_error: 9.0799\n",
      "Epoch 65/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 123.5440 - mean_absolute_error: 9.0481 - val_loss: 125.0324 - val_mean_absolute_error: 9.0789\n",
      "Epoch 66/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.5307 - mean_absolute_error: 9.0474 - val_loss: 125.0324 - val_mean_absolute_error: 9.0806\n",
      "Epoch 67/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.5154 - mean_absolute_error: 9.0470 - val_loss: 125.0605 - val_mean_absolute_error: 9.0845\n",
      "Epoch 68/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.4992 - mean_absolute_error: 9.0474 - val_loss: 125.0022 - val_mean_absolute_error: 9.0767\n",
      "Epoch 69/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.4971 - mean_absolute_error: 9.0458 - val_loss: 125.0038 - val_mean_absolute_error: 9.0792\n",
      "Epoch 70/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.4821 - mean_absolute_error: 9.0463 - val_loss: 125.0227 - val_mean_absolute_error: 9.0825\n",
      "Epoch 71/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.4743 - mean_absolute_error: 9.0471 - val_loss: 124.9818 - val_mean_absolute_error: 9.0775\n",
      "Epoch 72/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.4594 - mean_absolute_error: 9.0456 - val_loss: 124.9702 - val_mean_absolute_error: 9.0761\n",
      "Epoch 73/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.4486 - mean_absolute_error: 9.0449 - val_loss: 124.9793 - val_mean_absolute_error: 9.0793\n",
      "Epoch 74/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.4400 - mean_absolute_error: 9.0452 - val_loss: 124.9755 - val_mean_absolute_error: 9.0795\n",
      "Epoch 75/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 123.4255 - mean_absolute_error: 9.0443 - val_loss: 124.9730 - val_mean_absolute_error: 9.0799\n",
      "Epoch 76/1000\n",
      "56671/56671 [==============================] - 6s 98us/sample - loss: 123.4261 - mean_absolute_error: 9.0454 - val_loss: 124.9421 - val_mean_absolute_error: 9.0758\n",
      "Epoch 77/1000\n",
      "56671/56671 [==============================] - 6s 98us/sample - loss: 123.4091 - mean_absolute_error: 9.0440 - val_loss: 124.9415 - val_mean_absolute_error: 9.0769\n",
      "Epoch 78/1000\n",
      "56671/56671 [==============================] - 6s 100us/sample - loss: 123.4024 - mean_absolute_error: 9.0438 - val_loss: 124.9263 - val_mean_absolute_error: 9.0744\n",
      "Epoch 79/1000\n",
      "56671/56671 [==============================] - 5s 97us/sample - loss: 123.3964 - mean_absolute_error: 9.0431 - val_loss: 124.9215 - val_mean_absolute_error: 9.0747\n",
      "Epoch 80/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.3859 - mean_absolute_error: 9.0440 - val_loss: 124.9152 - val_mean_absolute_error: 9.0726\n",
      "Epoch 81/1000\n",
      "56671/56671 [==============================] - 5s 97us/sample - loss: 123.3767 - mean_absolute_error: 9.0429 - val_loss: 124.9241 - val_mean_absolute_error: 9.0773\n",
      "Epoch 82/1000\n",
      "56671/56671 [==============================] - 5s 97us/sample - loss: 123.3655 - mean_absolute_error: 9.0422 - val_loss: 124.9228 - val_mean_absolute_error: 9.0779\n",
      "Epoch 83/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.3541 - mean_absolute_error: 9.0427 - val_loss: 124.9047 - val_mean_absolute_error: 9.0761\n",
      "Epoch 84/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 123.3544 - mean_absolute_error: 9.0425 - val_loss: 124.8872 - val_mean_absolute_error: 9.0726\n",
      "Epoch 85/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.3391 - mean_absolute_error: 9.0422 - val_loss: 124.8796 - val_mean_absolute_error: 9.0722\n",
      "Epoch 86/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.3311 - mean_absolute_error: 9.0408 - val_loss: 124.8819 - val_mean_absolute_error: 9.0750\n",
      "Epoch 87/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.3285 - mean_absolute_error: 9.0418 - val_loss: 124.8666 - val_mean_absolute_error: 9.0720\n",
      "Epoch 88/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 123.3230 - mean_absolute_error: 9.0411 - val_loss: 124.8636 - val_mean_absolute_error: 9.0732\n",
      "Epoch 89/1000\n",
      "56671/56671 [==============================] - 5s 97us/sample - loss: 123.3150 - mean_absolute_error: 9.0412 - val_loss: 124.8554 - val_mean_absolute_error: 9.0721\n",
      "Epoch 90/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.3068 - mean_absolute_error: 9.0405 - val_loss: 124.8555 - val_mean_absolute_error: 9.0735\n",
      "Epoch 91/1000\n",
      "56671/56671 [==============================] - 6s 98us/sample - loss: 123.2915 - mean_absolute_error: 9.0400 - val_loss: 124.8513 - val_mean_absolute_error: 9.0734\n",
      "Epoch 92/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 123.2912 - mean_absolute_error: 9.0400 - val_loss: 124.8430 - val_mean_absolute_error: 9.0727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.2855 - mean_absolute_error: 9.0399 - val_loss: 124.8339 - val_mean_absolute_error: 9.0711\n",
      "Epoch 94/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.2737 - mean_absolute_error: 9.0395 - val_loss: 124.8331 - val_mean_absolute_error: 9.0727\n",
      "Epoch 95/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.2696 - mean_absolute_error: 9.0403 - val_loss: 124.8203 - val_mean_absolute_error: 9.0699\n",
      "Epoch 96/1000\n",
      "56671/56671 [==============================] - 6s 99us/sample - loss: 123.2613 - mean_absolute_error: 9.0383 - val_loss: 124.8226 - val_mean_absolute_error: 9.0723\n",
      "Epoch 97/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.2510 - mean_absolute_error: 9.0393 - val_loss: 124.8093 - val_mean_absolute_error: 9.0693\n",
      "Epoch 98/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.2457 - mean_absolute_error: 9.0381 - val_loss: 124.8344 - val_mean_absolute_error: 9.0750\n",
      "Epoch 99/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.2369 - mean_absolute_error: 9.0392 - val_loss: 124.8003 - val_mean_absolute_error: 9.0678\n",
      "Epoch 100/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 123.2286 - mean_absolute_error: 9.0381 - val_loss: 124.7922 - val_mean_absolute_error: 9.0693\n",
      "Epoch 101/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.2296 - mean_absolute_error: 9.0378 - val_loss: 124.7940 - val_mean_absolute_error: 9.0711\n",
      "Epoch 102/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.2198 - mean_absolute_error: 9.0376 - val_loss: 124.7990 - val_mean_absolute_error: 9.0725\n",
      "Epoch 103/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.2154 - mean_absolute_error: 9.0379 - val_loss: 124.7751 - val_mean_absolute_error: 9.0682\n",
      "Epoch 104/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.2102 - mean_absolute_error: 9.0368 - val_loss: 124.7716 - val_mean_absolute_error: 9.0676\n",
      "Epoch 105/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 123.2038 - mean_absolute_error: 9.0367 - val_loss: 124.7658 - val_mean_absolute_error: 9.0676\n",
      "Epoch 106/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.1944 - mean_absolute_error: 9.0362 - val_loss: 124.7784 - val_mean_absolute_error: 9.0716\n",
      "Epoch 107/1000\n",
      "56671/56671 [==============================] - 5s 97us/sample - loss: 123.1868 - mean_absolute_error: 9.0373 - val_loss: 124.7684 - val_mean_absolute_error: 9.0707\n",
      "Epoch 108/1000\n",
      "56671/56671 [==============================] - 5s 95us/sample - loss: 123.1855 - mean_absolute_error: 9.0365 - val_loss: 124.7518 - val_mean_absolute_error: 9.0683\n",
      "Epoch 109/1000\n",
      "56671/56671 [==============================] - 5s 96us/sample - loss: 123.1762 - mean_absolute_error: 9.0360 - val_loss: 124.7438 - val_mean_absolute_error: 9.0670\n",
      "Epoch 110/1000\n",
      "56671/56671 [==============================] - 6s 104us/sample - loss: 123.1658 - mean_absolute_error: 9.0352 - val_loss: 124.7451 - val_mean_absolute_error: 9.0689\n",
      "Epoch 111/1000\n",
      "56671/56671 [==============================] - 6s 98us/sample - loss: 123.1653 - mean_absolute_error: 9.0363 - val_loss: 124.7346 - val_mean_absolute_error: 9.0654\n",
      "Epoch 112/1000\n",
      "56671/56671 [==============================] - 6s 99us/sample - loss: 123.1616 - mean_absolute_error: 9.0357 - val_loss: 124.7296 - val_mean_absolute_error: 9.0650\n",
      "Epoch 113/1000\n",
      "56671/56671 [==============================] - 6s 100us/sample - loss: 123.1519 - mean_absolute_error: 9.0347 - val_loss: 124.7276 - val_mean_absolute_error: 9.0642\n",
      "Epoch 114/1000\n",
      "56671/56671 [==============================] - 6s 101us/sample - loss: 123.1513 - mean_absolute_error: 9.0346 - val_loss: 124.7224 - val_mean_absolute_error: 9.0670\n",
      "Epoch 115/1000\n",
      "56671/56671 [==============================] - 6s 102us/sample - loss: 123.1401 - mean_absolute_error: 9.0341 - val_loss: 124.7349 - val_mean_absolute_error: 9.0701\n",
      "Epoch 116/1000\n",
      "56671/56671 [==============================] - 6s 102us/sample - loss: 123.1392 - mean_absolute_error: 9.0347 - val_loss: 124.7174 - val_mean_absolute_error: 9.0677\n",
      "Epoch 117/1000\n",
      "56671/56671 [==============================] - 6s 101us/sample - loss: 123.1301 - mean_absolute_error: 9.0348 - val_loss: 124.7112 - val_mean_absolute_error: 9.0674\n",
      "Epoch 118/1000\n",
      "56671/56671 [==============================] - 6s 100us/sample - loss: 123.1271 - mean_absolute_error: 9.0345 - val_loss: 124.7004 - val_mean_absolute_error: 9.0644\n",
      "Epoch 119/1000\n",
      "56671/56671 [==============================] - 6s 100us/sample - loss: 123.1237 - mean_absolute_error: 9.0338 - val_loss: 124.6996 - val_mean_absolute_error: 9.0665\n",
      "Epoch 120/1000\n",
      "56671/56671 [==============================] - 6s 102us/sample - loss: 123.1143 - mean_absolute_error: 9.0340 - val_loss: 124.6935 - val_mean_absolute_error: 9.0662\n",
      "Epoch 121/1000\n",
      "56671/56671 [==============================] - 6s 102us/sample - loss: 123.1111 - mean_absolute_error: 9.0336 - val_loss: 124.6866 - val_mean_absolute_error: 9.0649\n",
      "Epoch 122/1000\n",
      "56192/56671 [============================>.] - ETA: 0s - loss: 122.9915 - mean_absolute_error: 9.0301"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-431-b4b07665bf23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m           steps_name='validation_steps')\n\u001b[0m\u001b[0;32m    441\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience = 20, monitor='val_loss', restore_best_weights=True)\n",
    "model = init_model()\n",
    "model.fit(X_train3, y_train, batch_size = 32, epochs=1000, validation_split = 0.3, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34697/34697 [==============================] - 1s 35us/sample - loss: 125.2299 - mean_absolute_error: 9.1084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[125.22992701087523, 9.108447]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0175197 ,  0.00992171, -0.01704188, ...,  0.05187736,\n",
       "         0.01849563,  0.01764313],\n",
       "       [-0.03293978, -0.02777258,  0.00764282, ..., -0.00032787,\n",
       "         0.02070131,  0.00792274],\n",
       "       [-0.02664617, -0.01571659, -0.00623735, ...,  0.01619654,\n",
       "         0.02345402,  0.04484541],\n",
       "       ...,\n",
       "       [-0.0140244 , -0.01213397, -0.03705579, ...,  0.02204706,\n",
       "         0.05742015,  0.02219241],\n",
       "       [-0.02169255, -0.06224019,  0.06070153, ...,  0.02377004,\n",
       "         0.0277255 ,  0.02276788],\n",
       "       [-0.01176275,  0.00484191, -0.01935203, ...,  0.0553019 ,\n",
       "         0.02143506,  0.02002919]])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.history.history['loss']\n",
    "acc = model.history.history['mean_absolute_error']\n",
    "val_loss = model.history.history['val_loss']\n",
    "val_acc = model.history.history['val_mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x226a95a8b88>"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss, label = 'loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.xlabel('n_epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x226ab536a88>"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc, label='mean_absolute_error')\n",
    "plt.plot(val_acc, label='val_mean_absolute_error')\n",
    "plt.xlabel('n_epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.012661\n",
       "1      0.002554\n",
       "2     -0.014151\n",
       "3      0.012570\n",
       "4     -0.028476\n",
       "         ...   \n",
       "295   -0.049243\n",
       "296   -0.025033\n",
       "297    0.058314\n",
       "298    0.019128\n",
       "299    0.022892\n",
       "Name: 0, Length: 300, dtype: float64"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "herbe.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renvoie le député le plus proche de votre tweet\n",
    "def predict_tweet(df, model, n_tweet, one_tweet = True):\n",
    "    '''\n",
    "    La fonction prend la base de données originale (par député), un modèle entraîné et un numéro de tweet en entrée.\n",
    "    Elle renvoie le député le plus proche du texte proposé.\n",
    "    Quand one_tweet = False, on ressort le député le plus proche du tweet.\n",
    "    Quand one_tweet = True, on sort le député le plus proche du compte twitter.\n",
    "    '''\n",
    "    test = np.arange(0,300,1)\n",
    "    herbe = df[test]\n",
    "    X_example = herbe.loc[n_tweet,:]\n",
    "    coucou = np.array(X_example)\n",
    "    if one_tweet:\n",
    "        lol = np.reshape(coucou, (1, 300))\n",
    "    prediction = model.predict(lol)\n",
    "    if one_tweet:\n",
    "        deputy = y.columns[prediction.argmax()]\n",
    "        return deputy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mep_id                   197577\n",
       "name               Gilles BOYER\n",
       "country                  France\n",
       "group        Renew Europe Group\n",
       "nat_group           Indépendant\n",
       "                    ...        \n",
       "295                   -0.113138\n",
       "296                  -0.0324296\n",
       "297                    0.034569\n",
       "298                   0.0480666\n",
       "299                  -0.0243168\n",
       "Name: 85200, Length: 308, dtype: object"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries.loc[85200,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-411-83efb747edae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m85000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m85300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_tweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_countries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-410-0df779b28262>\u001b[0m in \u001b[0;36mpredict_tweet\u001b[1;34m(df, model, n_tweet, one_tweet)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mone_tweet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mdeputy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdeputy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5129\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5132\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "for i in range(85000,85300):\n",
    "    print(predict_tweet(all_countries.reset_index(), model, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.arange(0,300,1)\n",
    "herbe = all_countries.reset_index()[test]\n",
    "X_example = herbe.loc[1,:]\n",
    "coucou = np.array(X_example)\n",
    "model.predict(lol).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mep_id                                                  197490\n",
       "name                                       Magdalena ADAMOWICZ\n",
       "country                                                 Poland\n",
       "group        Group of the European People's Party (Christia...\n",
       "nat_group                                          Independent\n",
       "                                   ...                        \n",
       "295                                                 -0.0492426\n",
       "296                                                 -0.0250329\n",
       "297                                                  0.0583143\n",
       "298                                                  0.0191282\n",
       "299                                                  0.0228919\n",
       "Name: 0, Length: 308, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_countries.loc[0:300,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict created\n"
     ]
    }
   ],
   "source": [
    "languages = ['english']\n",
    "\n",
    "def load_vec(emb_path, nmax=50000):\n",
    "    vectors = []\n",
    "    word2id = {}\n",
    "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        next(f)\n",
    "        for i, line in enumerate(f):\n",
    "            word, vect = line.rstrip().split(' ', 1)\n",
    "            vect = np.fromstring(vect, sep=' ')\n",
    "            assert word not in word2id, 'word found twice'\n",
    "            vectors.append(vect)\n",
    "            word2id[word] = len(word2id)\n",
    "            if len(word2id) == nmax:\n",
    "                break\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.vstack(vectors)\n",
    "    return embeddings, id2word, word2id\n",
    "\n",
    "nmax = 100000  # maximum number of word embeddings to load\n",
    "emb_dict = {}\n",
    "for lang in languages:\n",
    "    path = f\"../../raw_data/vectors_{lang}.txt\" #Select here\n",
    "    embeddings, id2word, word2id = load_vec(path, nmax)\n",
    "    emb_dict[lang] = [embeddings, id2word, word2id]\n",
    "\n",
    "print(\"Dict created\")\n",
    "\n",
    "\n",
    "def multilang_word_vector(word, emb_dict, lang):\n",
    "    try:\n",
    "        if word in emb_dict.get(lang)[2].keys():\n",
    "            return emb_dict[lang][0][emb_dict[lang][2][word]]\n",
    "        return []\n",
    "    except:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'brazil'\n",
    "phrase = phrase.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = []\n",
    "for word in phrase.split():\n",
    "    sentence.append(multilang_word_vector(word, emb_dict, 'english'))\n",
    "sentence = pd.DataFrame(sentence)\n",
    "sentence = sentence.mean()\n",
    "coucou = np.array(sentence)\n",
    "lol = np.reshape(coucou, (1, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Clara PONSATÍ OBIOLS', 'Jordi CAÑAS', 'Ibán GARCÍA DEL BLANCO',\n",
       "       'Jonás FERNÁNDEZ', 'Diana RIBA I GINER', 'Carles PUIGDEMONT I CASAMAJÓ',\n",
       "       'Esteban GONZÁLEZ PONS', 'Isabel BENJUMEA BENJUMEA',\n",
       "       'José Ramón BAUZÁ DÍAZ', 'José Manuel GARCÍA-MARGALLO Y MARFIL',\n",
       "       'Javi LÓPEZ', 'Lina GÁLVEZ MUÑOZ', 'Franc BOGOVIČ',\n",
       "       'Antoni COMÍN I OLIVERES', 'César LUENA', 'Luis GARICANO', 'Jordi SOLÉ',\n",
       "       'Domènec RUIZ DEVESA', 'Ernest URTASUN', 'João FERREIRA',\n",
       "       'Angel DZHAMBAZKI', 'Marco ZANNI', 'Milan ZVER',\n",
       "       'Inma RODRÍGUEZ-PIÑERO', 'Stanislav POLČÁK', 'Edina TÓTH',\n",
       "       'Martina DLABAJOVÁ', 'Tiziana BEGHIN', 'Lídia PEREIRA', 'Sira REGO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(lol)\n",
    "y.columns[prediction[0].argsort()[-30:][::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1      292\n",
       " 253      1\n",
       " 201      1\n",
       " 181      1\n",
       " 176      1\n",
       " 168      1\n",
       " 92       1\n",
       " 40       1\n",
       " 12       1\n",
       "Name: content, dtype: int64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df[new_test_df['name'] == 'Clara PONSATÍ OBIOLS']['content'].str.find('europe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement de la base de données finale traduite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wonderful_df = pd.read_pickle('../../raw_data/tweets_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>thank you very much free media independent of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>the commission has adopted major pilot project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>the commission adopted my co-authored pilot pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>on this day, at this point in this hour, I am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>god does not need to be defended by anyone and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134719</th>\n",
       "      <td>197652</td>\n",
       "      <td>Angelika WINZIG</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Österreichische Volkspartei</td>\n",
       "      <td>AngelikaWinzig</td>\n",
       "      <td>italy's budget policy endangers not only italy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134720</th>\n",
       "      <td>197652</td>\n",
       "      <td>Angelika WINZIG</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Österreichische Volkspartei</td>\n",
       "      <td>AngelikaWinzig</td>\n",
       "      <td>thank you martin for organizing the eu summer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134721</th>\n",
       "      <td>197652</td>\n",
       "      <td>Angelika WINZIG</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Österreichische Volkspartei</td>\n",
       "      <td>AngelikaWinzig</td>\n",
       "      <td>tradition amp modern top companies network mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134722</th>\n",
       "      <td>197652</td>\n",
       "      <td>Angelika WINZIG</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Österreichische Volkspartei</td>\n",
       "      <td>AngelikaWinzig</td>\n",
       "      <td>Here is my statement on the budget speech by f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134723</th>\n",
       "      <td>197652</td>\n",
       "      <td>Angelika WINZIG</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Österreichische Volkspartei</td>\n",
       "      <td>AngelikaWinzig</td>\n",
       "      <td>tomorrow is the big day of our finance ministe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134724 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mep_id                 name  country  \\\n",
       "0       197490  Magdalena ADAMOWICZ   Poland   \n",
       "1       197490  Magdalena ADAMOWICZ   Poland   \n",
       "2       197490  Magdalena ADAMOWICZ   Poland   \n",
       "3       197490  Magdalena ADAMOWICZ   Poland   \n",
       "4       197490  Magdalena ADAMOWICZ   Poland   \n",
       "...        ...                  ...      ...   \n",
       "134719  197652      Angelika WINZIG  Austria   \n",
       "134720  197652      Angelika WINZIG  Austria   \n",
       "134721  197652      Angelika WINZIG  Austria   \n",
       "134722  197652      Angelika WINZIG  Austria   \n",
       "134723  197652      Angelika WINZIG  Austria   \n",
       "\n",
       "                                                    group  \\\n",
       "0       Group of the European People's Party (Christia...   \n",
       "1       Group of the European People's Party (Christia...   \n",
       "2       Group of the European People's Party (Christia...   \n",
       "3       Group of the European People's Party (Christia...   \n",
       "4       Group of the European People's Party (Christia...   \n",
       "...                                                   ...   \n",
       "134719  Group of the European People's Party (Christia...   \n",
       "134720  Group of the European People's Party (Christia...   \n",
       "134721  Group of the European People's Party (Christia...   \n",
       "134722  Group of the European People's Party (Christia...   \n",
       "134723  Group of the European People's Party (Christia...   \n",
       "\n",
       "                          nat_group          twitter  \\\n",
       "0                       Independent  Adamowicz_Magda   \n",
       "1                       Independent  Adamowicz_Magda   \n",
       "2                       Independent  Adamowicz_Magda   \n",
       "3                       Independent  Adamowicz_Magda   \n",
       "4                       Independent  Adamowicz_Magda   \n",
       "...                             ...              ...   \n",
       "134719  Österreichische Volkspartei   AngelikaWinzig   \n",
       "134720  Österreichische Volkspartei   AngelikaWinzig   \n",
       "134721  Österreichische Volkspartei   AngelikaWinzig   \n",
       "134722  Österreichische Volkspartei   AngelikaWinzig   \n",
       "134723  Österreichische Volkspartei   AngelikaWinzig   \n",
       "\n",
       "                                                  content  \n",
       "0       thank you very much free media independent of ...  \n",
       "1       the commission has adopted major pilot project...  \n",
       "2       the commission adopted my co-authored pilot pr...  \n",
       "3       on this day, at this point in this hour, I am ...  \n",
       "4       god does not need to be defended by anyone and...  \n",
       "...                                                   ...  \n",
       "134719  italy's budget policy endangers not only italy...  \n",
       "134720  thank you martin for organizing the eu summer ...  \n",
       "134721  tradition amp modern top companies network mee...  \n",
       "134722  Here is my statement on the budget speech by f...  \n",
       "134723  tomorrow is the big day of our finance ministe...  \n",
       "\n",
       "[134724 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wonderful_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dico = {name:age for name, age in zip(wonderful_df.name.unique(), age_list)}\n",
    "for name in dico.keys():\n",
    "    wonderful_df[\"age\"] = wonderful_df.name.map(dico)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dict_femme = {key:name for key,name in enumerate(tweet_df.name)}\n",
    "reel_list_femme = []\n",
    "for i in key_femme:\n",
    "    reel_list_femme.append(real_dict_femme[i])\n",
    "ll = [1] * len(key_femme)\n",
    "dict_femme = {name:key for name, key in zip(reel_list_femme,ll)}\n",
    "for name in all_countries['name'].unique():\n",
    "    if name in dict_femme.keys():\n",
    "        wonderful_df[\"sex\"] = wonderful_df['name'].map(dict_femme)\n",
    "wonderful_df['sex'] = wonderful_df['sex'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>thank you very much free media independent of ...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>the commission has adopted major pilot project...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mep_id                 name country  \\\n",
       "0  197490  Magdalena ADAMOWICZ  Poland   \n",
       "1  197490  Magdalena ADAMOWICZ  Poland   \n",
       "\n",
       "                                               group    nat_group  \\\n",
       "0  Group of the European People's Party (Christia...  Independent   \n",
       "1  Group of the European People's Party (Christia...  Independent   \n",
       "\n",
       "           twitter                                            content  age  \\\n",
       "0  Adamowicz_Magda  thank you very much free media independent of ...   47   \n",
       "1  Adamowicz_Magda  the commission has adopted major pilot project...   47   \n",
       "\n",
       "   sex  \n",
       "0  1.0  \n",
       "1  1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wonderful_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = rmurl_df(wonderful_df, 'content')\n",
    "clean_df = lower_df(clean_df, 'content')\n",
    "clean_df = rmnumbers_df(clean_df, 'content')\n",
    "clean_df = rmpunct_df(clean_df, 'content')\n",
    "clean_df = rmstopwords_df(clean_df, 'content')\n",
    "clean_df = lemmatize_df(clean_df, 'content')\n",
    "clean_df = erase_fewletter_df(clean_df, 'content')\n",
    "clean_df = rmemojis_df(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction retourne automatiquement X_train, X_test, y_train, y_test de notre base de données twitter.\n",
    "def get_train_test_objects(df, column):\n",
    "    '''\n",
    "    Les étapes que cette fonction réalise sont en commentaires.\n",
    "    '''\n",
    "    # Copie de la base de données pour éviter les problèmes d'assignation abusive.\n",
    "    df = df.copy() \n",
    "    # Récupération de tous les tweets et du nom du député qui les a posté. Création de la cible y.\n",
    "    df = df[[column, 'content']]\n",
    "    y = pd.get_dummies(df[column])\n",
    "    # Transformation des tweets en suite de mots (strings) dans une liste.\n",
    "    sentences = df['content']\n",
    "    sentences_inter = []\n",
    "    for sentence in sentences:\n",
    "        sentences_inter.append(sentence.split())\n",
    "    # Séparation des données d'entraînement et de test\n",
    "    sentences_train, sentences_test, y_train, y_test = train_test_split(sentences_inter, y, test_size = 0.3)\n",
    "    # Vectorisation des phrases\n",
    "    word2vec = Word2Vec(sentences=sentences_train)\n",
    "    # Création des données d'entrée.\n",
    "    X_train = embedding(word2vec,sentences_train)\n",
    "    X_test = embedding(word2vec,sentences_test)\n",
    "    X_train_pad = pad_sequences(X_train, padding='post',value=-1000, dtype='float32')\n",
    "    X_test_pad = pad_sequences(X_test, padding='post',value=-1000, dtype='float32')\n",
    "    # Création des données cibles.\n",
    "    y_train = y_train.values\n",
    "    y_test = y_test.values\n",
    "    # Sorties de la fonction\n",
    "    return X_train_pad, y_train, X_test_pad, y_test, word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, word2vec = get_train_test_objects(clean_df, 'country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement et évaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking(mask_value = -1000))\n",
    "    model.add(layers.LSTM(10, dropout=0.2, recurrent_dropout=0.2, activation='tanh'))\n",
    "    model.add(layers.Dense(10, activation='tanh'))\n",
    "    model.add(layers.Dense(27, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2063/2063 [==============================] - 56s 27ms/step - loss: 2.8362 - accuracy: 0.1622 - val_loss: 2.7149 - val_accuracy: 0.1898\n",
      "Epoch 2/1000\n",
      "2063/2063 [==============================] - 57s 28ms/step - loss: 2.7166 - accuracy: 0.1875 - val_loss: 2.6764 - val_accuracy: 0.1988\n",
      "Epoch 3/1000\n",
      "2063/2063 [==============================] - 55s 26ms/step - loss: 2.6901 - accuracy: 0.1931 - val_loss: 2.6558 - val_accuracy: 0.2069\n",
      "Epoch 4/1000\n",
      "2063/2063 [==============================] - 56s 27ms/step - loss: 2.6729 - accuracy: 0.1990 - val_loss: 2.6386 - val_accuracy: 0.2075\n",
      "Epoch 5/1000\n",
      "2063/2063 [==============================] - 52s 25ms/step - loss: 2.6570 - accuracy: 0.2078 - val_loss: 2.6292 - val_accuracy: 0.2171\n",
      "Epoch 6/1000\n",
      "2063/2063 [==============================] - 55s 26ms/step - loss: 2.6418 - accuracy: 0.2124 - val_loss: 2.6099 - val_accuracy: 0.2195\n",
      "Epoch 7/1000\n",
      "2063/2063 [==============================] - 51s 25ms/step - loss: 2.6282 - accuracy: 0.2135 - val_loss: 2.5997 - val_accuracy: 0.2233\n",
      "Epoch 8/1000\n",
      "2063/2063 [==============================] - 50s 24ms/step - loss: 2.6167 - accuracy: 0.2175 - val_loss: 2.5837 - val_accuracy: 0.2267\n",
      "Epoch 9/1000\n",
      "2063/2063 [==============================] - 51s 25ms/step - loss: 2.6104 - accuracy: 0.2192 - val_loss: 2.5776 - val_accuracy: 0.2289\n",
      "Epoch 10/1000\n",
      "2063/2063 [==============================] - 49s 24ms/step - loss: 2.6032 - accuracy: 0.2198 - val_loss: 2.5750 - val_accuracy: 0.2271\n",
      "Epoch 11/1000\n",
      "2063/2063 [==============================] - 50s 24ms/step - loss: 2.5990 - accuracy: 0.2221 - val_loss: 2.5689 - val_accuracy: 0.2310\n",
      "Epoch 12/1000\n",
      "2063/2063 [==============================] - 51s 25ms/step - loss: 2.5932 - accuracy: 0.2228 - val_loss: 2.5626 - val_accuracy: 0.2335\n",
      "Epoch 13/1000\n",
      "2063/2063 [==============================] - 51s 25ms/step - loss: 2.5897 - accuracy: 0.2248 - val_loss: 2.5575 - val_accuracy: 0.2349\n",
      "Epoch 14/1000\n",
      "2063/2063 [==============================] - 50s 24ms/step - loss: 2.5881 - accuracy: 0.2239 - val_loss: 2.5583 - val_accuracy: 0.2358\n",
      "Epoch 15/1000\n",
      "2063/2063 [==============================] - 50s 24ms/step - loss: 2.5840 - accuracy: 0.2247 - val_loss: 2.5564 - val_accuracy: 0.2324\n",
      "Epoch 16/1000\n",
      "2063/2063 [==============================] - 51s 25ms/step - loss: 2.5801 - accuracy: 0.2265 - val_loss: 2.5576 - val_accuracy: 0.2319\n",
      "Epoch 17/1000\n",
      "2063/2063 [==============================] - 50s 24ms/step - loss: 2.5807 - accuracy: 0.2271 - val_loss: 2.5500 - val_accuracy: 0.2370\n",
      "Epoch 18/1000\n",
      "2063/2063 [==============================] - 53s 26ms/step - loss: 2.5792 - accuracy: 0.2253 - val_loss: 2.5468 - val_accuracy: 0.2367\n",
      "Epoch 19/1000\n",
      "2063/2063 [==============================] - 52s 25ms/step - loss: 2.5779 - accuracy: 0.2248 - val_loss: 2.5486 - val_accuracy: 0.2346\n",
      "Epoch 20/1000\n",
      "2063/2063 [==============================] - 51s 25ms/step - loss: 2.5781 - accuracy: 0.2259 - val_loss: 2.5527 - val_accuracy: 0.2331\n",
      "Epoch 21/1000\n",
      "2063/2063 [==============================] - 52s 25ms/step - loss: 2.5766 - accuracy: 0.2263 - val_loss: 2.5454 - val_accuracy: 0.2351\n",
      "Epoch 22/1000\n",
      "2063/2063 [==============================] - 52s 25ms/step - loss: 2.5732 - accuracy: 0.2282 - val_loss: 2.5505 - val_accuracy: 0.2354\n",
      "Epoch 23/1000\n",
      "2063/2063 [==============================] - 53s 26ms/step - loss: 2.5736 - accuracy: 0.2273 - val_loss: 2.5436 - val_accuracy: 0.2373\n",
      "Epoch 24/1000\n",
      "2063/2063 [==============================] - 50s 24ms/step - loss: 2.5734 - accuracy: 0.2258 - val_loss: 2.5567 - val_accuracy: 0.2343\n",
      "Epoch 25/1000\n",
      "2063/2063 [==============================] - 49s 24ms/step - loss: 2.5719 - accuracy: 0.2256 - val_loss: 2.5389 - val_accuracy: 0.2355\n",
      "Epoch 26/1000\n",
      "2063/2063 [==============================] - 49s 24ms/step - loss: 2.5682 - accuracy: 0.2273 - val_loss: 2.5401 - val_accuracy: 0.2373\n",
      "Epoch 27/1000\n",
      "2063/2063 [==============================] - 51s 25ms/step - loss: 2.5697 - accuracy: 0.2282 - val_loss: 2.5395 - val_accuracy: 0.2367\n",
      "Epoch 28/1000\n",
      "2063/2063 [==============================] - 49s 24ms/step - loss: 2.5694 - accuracy: 0.2285 - val_loss: 2.5388 - val_accuracy: 0.2371\n",
      "Epoch 29/1000\n",
      "2063/2063 [==============================] - 50s 24ms/step - loss: 2.5671 - accuracy: 0.2274 - val_loss: 2.5430 - val_accuracy: 0.2343\n",
      "Epoch 30/1000\n",
      "2063/2063 [==============================] - 51s 25ms/step - loss: 2.5694 - accuracy: 0.2267 - val_loss: 2.5372 - val_accuracy: 0.2379\n",
      "Epoch 31/1000\n",
      "2063/2063 [==============================] - 52s 25ms/step - loss: 2.5660 - accuracy: 0.2284 - val_loss: 2.5396 - val_accuracy: 0.2371\n",
      "Epoch 32/1000\n",
      "2063/2063 [==============================] - 49s 24ms/step - loss: 2.5676 - accuracy: 0.2258 - val_loss: 2.5403 - val_accuracy: 0.2367\n",
      "Epoch 33/1000\n",
      "2063/2063 [==============================] - 53s 25ms/step - loss: 2.5645 - accuracy: 0.2286 - val_loss: 2.5365 - val_accuracy: 0.2343\n",
      "Epoch 34/1000\n",
      "2063/2063 [==============================] - 52s 25ms/step - loss: 2.5649 - accuracy: 0.2281 - val_loss: 2.5422 - val_accuracy: 0.2344\n",
      "Epoch 35/1000\n",
      "2063/2063 [==============================] - 54s 26ms/step - loss: 2.5623 - accuracy: 0.2295 - val_loss: 2.5368 - val_accuracy: 0.2358\n",
      "Epoch 36/1000\n",
      "2063/2063 [==============================] - 52s 25ms/step - loss: 2.5625 - accuracy: 0.2297 - val_loss: 2.5335 - val_accuracy: 0.2392\n",
      "Epoch 37/1000\n",
      "2063/2063 [==============================] - 50s 24ms/step - loss: 2.5634 - accuracy: 0.2298 - val_loss: 2.5324 - val_accuracy: 0.2386\n",
      "Epoch 38/1000\n",
      "2063/2063 [==============================] - 50s 24ms/step - loss: 2.5624 - accuracy: 0.2282 - val_loss: 2.5320 - val_accuracy: 0.2401\n",
      "Epoch 39/1000\n",
      "2063/2063 [==============================] - 51s 25ms/step - loss: 2.5610 - accuracy: 0.2286 - val_loss: 2.5382 - val_accuracy: 0.2396\n",
      "Epoch 40/1000\n",
      "2063/2063 [==============================] - 49s 24ms/step - loss: 2.5604 - accuracy: 0.2306 - val_loss: 2.5409 - val_accuracy: 0.2340\n",
      "Epoch 41/1000\n",
      "2063/2063 [==============================] - 50s 24ms/step - loss: 2.5609 - accuracy: 0.2303 - val_loss: 2.5317 - val_accuracy: 0.2416\n",
      "Epoch 42/1000\n",
      "2063/2063 [==============================] - 55s 26ms/step - loss: 2.5612 - accuracy: 0.2289 - val_loss: 2.5339 - val_accuracy: 0.2375\n",
      "Epoch 43/1000\n",
      "2063/2063 [==============================] - 52s 25ms/step - loss: 2.5608 - accuracy: 0.2293 - val_loss: 2.5323 - val_accuracy: 0.2389\n",
      "Epoch 44/1000\n",
      "2063/2063 [==============================] - 51s 25ms/step - loss: 2.5606 - accuracy: 0.2285 - val_loss: 2.5300 - val_accuracy: 0.2390\n",
      "Epoch 45/1000\n",
      " 165/2063 [=>............................] - ETA: 47s - loss: 2.5804 - accuracy: 0.2278"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-951188ac391a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience = 3, monitor='val_loss', restore_best_weights=True)\n",
    "model = init_model()\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs=1000, validation_split = 0.3, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "885/885 [==============================] - 4s 4ms/step - loss: 2.5290 - accuracy: 0.2407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5290210247039795, 0.24073943495750427]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score et sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Députés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(input1):\n",
    "    sentences_inter = []\n",
    "    for sentence in input1:\n",
    "        sentences_inter.append(sentence.split())\n",
    "    X_train = embedding(word2vec,sentences_inter)\n",
    "    formated_input = pad_sequences(X_train, padding='post',value=-1000, dtype='float32')\n",
    "    return formated_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Netherlands'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pond = np.sqrt(clean_df.groupby('country').count()['content'].values)\n",
    "result = (1000*np.mean(model.predict(format_input(['netherlands water', 'amsterdam sweden'])), axis=0)/pond).argmax()\n",
    "pd.get_dummies(clean_df['country']).columns[result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.save('word2vec_country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_country\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model_country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score maximal : 5.12%  Baseline : 0.21%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupe européen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_group = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score maximal : 33.5%\n",
    "Baseline : 12.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sex = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score maximal : 59.18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score maximal : 25.02%\n",
    "Baseline : 3.57%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédictions !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_bert.data_cls import BertDataBunch\n",
    "train = clean_df[['content', 'name']]\n",
    "train.rename(columns={\"content\":\"text\", \"name\":\"label\"}, inplace = True)\n",
    "x_train, x_test = train_test_split(train, test_size = 0.25)\n",
    "x_train, x_val = train_test_split(x_train, test_size = 0.25)\n",
    "x_train.to_csv('train.csv')\n",
    "x_val.to_csv('val.csv')\n",
    "pd.DataFrame(train['label'].unique()).to_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "databunch = BertDataBunch('.', '.',\n",
    "                          tokenizer='bert-base-uncased',\n",
    "                          train_file='train.csv',\n",
    "                          val_file='val.csv',\n",
    "                          label_file='labels.csv',\n",
    "                          text_col='text',\n",
    "                          label_col='label',\n",
    "                          batch_size_per_gpu=16,\n",
    "                          max_seq_length=100,\n",
    "                          multi_gpu=True,\n",
    "                          multi_label=True,\n",
    "                          model_type='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_bert.learner_cls import BertLearner\n",
    "from fast_bert.metrics import accuracy\n",
    "import logging\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "device_cuda = torch.device(\"cpu\")\n",
    "metrics = [{'name': 'accuracy', 'function': accuracy}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "learner = BertLearner.from_pretrained_model(\n",
    "\t\t\t\t\t\tdatabunch,\n",
    "\t\t\t\t\t\tpretrained_path='bert-base-uncased',\n",
    "\t\t\t\t\t\tmetrics=metrics,\n",
    "\t\t\t\t\t\tdevice=device_cuda,\n",
    "\t\t\t\t\t\tlogger=logger,\n",
    "\t\t\t\t\t\toutput_dir='.',\n",
    "\t\t\t\t\t\tfinetuned_wgts_path=None,\n",
    "\t\t\t\t\t\twarmup_steps=500,\n",
    "\t\t\t\t\t\tmulti_gpu=True,\n",
    "\t\t\t\t\t\tis_fp16=True,\n",
    "\t\t\t\t\t\tmulti_label=True,\n",
    "\t\t\t\t\t\tlogging_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "969a4a43b7364a14929031f87d9556a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\pytorch_lamb\\lamb.py:96: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-fc2a900ad6bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lamb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\fast_bert\\learner_cls.py\u001b[0m in \u001b[0;36mlr_find\u001b[1;34m(self, start_lr, end_lr, use_val_loss, optimizer_type, num_iter, step_mode, smooth_f, diverge_th)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0muse_val_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m             \u001b[1;31m# Update the learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\fast_bert\\learner_cls.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, quiet, loss_only)\u001b[0m\n\u001b[0;32m    480\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_type_ids\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m                 \u001b[0mtmp_eval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\fast_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, labels, position_ids, head_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         )\n\u001b[0;32m    193\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m         )\n\u001b[0;32m    837\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    488\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m                 )\n\u001b[0;32m    492\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[1;32m--> 433\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m         )\n\u001b[0;32m    435\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m   1595\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1597\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.lr_find(start_lr=1e-5,optimizer_type='lamb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/6 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='4737' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.06% [3/4737 01:10<30:42:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-e9dd20796763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Evaluate the model after each epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0mschedule_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"warmup_cosine\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \t\t\toptimizer_type=\"adamw\")\n\u001b[0m",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\fast_bert\\learner_cls.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, epochs, lr, validate, return_results, schedule_type, optimizer_type)\u001b[0m\n\u001b[0;32m    350\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_type_ids\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m                 loss = outputs[\n\u001b[0;32m    354\u001b[0m                     \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\fast_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, labels, position_ids, head_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         )\n\u001b[0;32m    193\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m         )\n\u001b[0;32m    837\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    488\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m                 )\n\u001b[0;32m    492\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[1;32m--> 433\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m         )\n\u001b[0;32m    435\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m   1595\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1597\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mgelu\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m   1367\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1369\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit(epochs=6,\n",
    "\t\t\tlr=6e-5,\n",
    "\t\t\tvalidate=True, \t# Evaluate the model after each epoch\n",
    "\t\t\tschedule_type=\"warmup_cosine\",\n",
    "\t\t\toptimizer_type=\"adamw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196.267px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
