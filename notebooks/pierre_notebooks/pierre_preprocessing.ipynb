{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression des éléments indésirables de nos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>[@danutahuebner Bardzo dziękuję @danutahuebner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189525</td>\n",
       "      <td>Asim ADEMOV</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Citizens for European Development of Bulgaria</td>\n",
       "      <td>AdemovAsim</td>\n",
       "      <td>[135 години единна и силна България. \\nЧестит ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124831</td>\n",
       "      <td>Isabella ADINOLFI</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Non-attached Members</td>\n",
       "      <td>Movimento 5 Stelle</td>\n",
       "      <td>Isa_Adinolfi</td>\n",
       "      <td>[Sembra un film, ma purtroppo è realtà: le imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>125045</td>\n",
       "      <td>Clara AGUILERA</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista Obrero Español</td>\n",
       "      <td>ClaraAguilera7</td>\n",
       "      <td>[Clara Aguilera: \"El criterio científico debe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>204335</td>\n",
       "      <td>Alviina ALAMETSÄ</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Group of the Greens/European Free Alliance</td>\n",
       "      <td>Vihreä liitto</td>\n",
       "      <td>alviinaalametsa</td>\n",
       "      <td>[@LHurttila @MariaOhisalo Kaupungilla on järje...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mep_id                 name   country  \\\n",
       "0  197490  Magdalena ADAMOWICZ    Poland   \n",
       "1  189525          Asim ADEMOV  Bulgaria   \n",
       "2  124831    Isabella ADINOLFI     Italy   \n",
       "6  125045       Clara AGUILERA     Spain   \n",
       "7  204335     Alviina ALAMETSÄ   Finland   \n",
       "\n",
       "                                               group  \\\n",
       "0  Group of the European People's Party (Christia...   \n",
       "1  Group of the European People's Party (Christia...   \n",
       "2                               Non-attached Members   \n",
       "6  Group of the Progressive Alliance of Socialist...   \n",
       "7         Group of the Greens/European Free Alliance   \n",
       "\n",
       "                                       nat_group          twitter  \\\n",
       "0                                    Independent  Adamowicz_Magda   \n",
       "1  Citizens for European Development of Bulgaria       AdemovAsim   \n",
       "2                             Movimento 5 Stelle     Isa_Adinolfi   \n",
       "6              Partido Socialista Obrero Español   ClaraAguilera7   \n",
       "7                                  Vihreä liitto  alviinaalametsa   \n",
       "\n",
       "                                             content  \n",
       "0  [@danutahuebner Bardzo dziękuję @danutahuebner...  \n",
       "1  [135 години единна и силна България. \\nЧестит ...  \n",
       "2  [Sembra un film, ma purtroppo è realtà: le imm...  \n",
       "6  [Clara Aguilera: \"El criterio científico debe ...  \n",
       "7  [@LHurttila @MariaOhisalo Kaupungilla on järje...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture et stockage de la base de données\n",
    "tweet_df = pd.read_pickle('../../delphes/data/final4_clean.csv')\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = []\n",
    "sexe = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(0, tweet_df.shape[0])\n",
    "tweet_df['index'] = y\n",
    "tweet_df.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = pd.DataFrame(columns=['mep_id', 'name', 'country', 'group', 'nat_group', 'twitter', 'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 0\n",
    "for j in range(tweet_df.shape[0]):\n",
    "    for i in range(len(tweet_df['content'][j])):\n",
    "        new_test_df.loc[k] = tweet_df.loc[j,'mep_id':'twitter']\n",
    "        new_test_df.loc[k, 'content'] = tweet_df['content'][j][i]\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the undesirable elements in the entire dataframe\n",
    "def rmurl_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the URLs, the #hashtag and the @user of a column made of strings.\n",
    "    Be careful to apply it BEFORE all the other preprocessing steps (if not it wont'\n",
    "    be recognized as a URL)\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].str.replace('http\\S+|www.\\S+|@\\S+|#\\S+', '', case=False)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase the tweet's column\n",
    "def lower_df(df, column_name):\n",
    "    '''\n",
    "    This function lowercases a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the numbers in the tweet's column\n",
    "def rmnumbers_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the digits of a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def remove_numbers(text):\n",
    "        return ''.join(word for word in text if not word.isdigit())\n",
    "    df[column_name] = df[column_name].apply(remove_numbers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the undesirable punctuations in the tweet's column\n",
    "def rmpunct_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the punctuations, all the \"rt\" and remove multiple spaces\n",
    "    of a column made of strings.\n",
    "    '''\n",
    "    punct = string.punctuation\n",
    "    df = df.copy()\n",
    "    def replace_punct(text):\n",
    "        for punctu in punct:\n",
    "            text = text.replace(punctu, ' ')\n",
    "        text = text.replace(' rt ','')\n",
    "        text = \" \".join(text.split())\n",
    "        return text\n",
    "    df[column_name] = df[column_name].apply(replace_punct)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stopwords in the tweet's column\n",
    "def rmstopwords_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the stopwords of a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    stop_words = stopwords.words('english')\n",
    "    def remove_stopwords(text):\n",
    "        for word in stop_words:\n",
    "            text = text.replace(f' {word} ', ' ')\n",
    "        return text\n",
    "    df[column_name] = df[column_name].apply(remove_stopwords)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize a column in a dataset\n",
    "def lemmatize_df(df, column_name):\n",
    "    '''\n",
    "    This function lemmatize the words of a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def lemmatize(text):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        retour = []\n",
    "        for word in text:\n",
    "            retour.append(lemmatizer.lemmatize(word))\n",
    "        text = ''.join(word for word in retour)\n",
    "        return text\n",
    "\n",
    "    df[column_name] = df[column_name].apply(lemmatize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erase all the words that are 1-letter or 2-letters long\n",
    "def erase_fewletter_df(df, column_name):\n",
    "    '''\n",
    "    One or two letters words are deleted from the dataset.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def tester(text):\n",
    "        text = ' '.join( [w for w in text.split() if len(w)>2] )\n",
    "        return text\n",
    "\n",
    "    df[column_name] = df[column_name].apply(tester)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the undesirable emojis in the entire dataframe\n",
    "def rmemojis_df(df):\n",
    "    '''\n",
    "    This function removes all the emojis of a column made of strings.\n",
    "    Be careful to translate in latin alphabet before applying this function : \n",
    "    it also removes cyrillic alphabet\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df = df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = rmurl_df(new_test_df, 'content')\n",
    "clean_df = lower_df(clean_df, 'content')\n",
    "clean_df = rmnumbers_df(clean_df, 'content')\n",
    "clean_df = rmpunct_df(clean_df, 'content')\n",
    "clean_df = rmstopwords_df(clean_df, 'content')\n",
    "clean_df = lemmatize_df(clean_df, 'content')\n",
    "clean_df = erase_fewletter_df(clean_df, 'content')\n",
    "clean_df = rmemojis_df(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24722</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>the northern ireland protocol must protected l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24723</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>member special committee beating cancer look f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>this month shining light childrens cancer parl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24725</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>yesterday told europe need keep speed amp infr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24726</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>this letter sent taoiseach clear seeking clari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mep_id           name  country  \\\n",
       "24722  124988  Deirdre CLUNE  Ireland   \n",
       "24723  124988  Deirdre CLUNE  Ireland   \n",
       "24724  124988  Deirdre CLUNE  Ireland   \n",
       "24725  124988  Deirdre CLUNE  Ireland   \n",
       "24726  124988  Deirdre CLUNE  Ireland   \n",
       "\n",
       "                                                   group        nat_group  \\\n",
       "24722  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24723  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24724  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24725  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24726  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "\n",
       "               twitter                                            content  \n",
       "24722  deirdreclunemep  the northern ireland protocol must protected l...  \n",
       "24723  deirdreclunemep  member special committee beating cancer look f...  \n",
       "24724  deirdreclunemep  this month shining light childrens cancer parl...  \n",
       "24725  deirdreclunemep  yesterday told europe need keep speed amp infr...  \n",
       "24726  deirdreclunemep  this letter sent taoiseach clear seeking clari...  "
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[clean_df['country'] == 'Ireland'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the northern ireland protocol must protected line real effort must made earnest week bridge gap talks come table many times good faith amp view securing future partnership respects standards union'"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['content'][24722]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbase_df = clean_df[clean_df['country'] == 'Ireland']\n",
    "testbase_deputy_df = tweet_df[tweet_df['country'] == 'Ireland']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction retourne automatiquement X_train, X_test, y_train, y_test de notre base de données twitter.\n",
    "def get_train_test_objects(df):\n",
    "    '''\n",
    "    Les étapes que cette fonction réalise sont en commentaires.\n",
    "    '''\n",
    "    # Copie de la base de données pour éviter les problèmes d'assignation abusive.\n",
    "    df = df.copy() \n",
    "    # Récupération de tous les tweets et du nom du député qui les a posté. Création de la cible y.\n",
    "    df = df[['name', 'content']]\n",
    "    y = pd.get_dummies(df['name'])\n",
    "    # Transformation des tweets en suite de mots (strings) dans une liste.\n",
    "    sentences = df['content']\n",
    "    sentences_inter = []\n",
    "    for sentence in sentences:\n",
    "        sentences_inter.append(sentence.split())\n",
    "    # Séparation des données d'entraînement et de test\n",
    "    sentences_train, sentences_test, y_train, y_test = train_test_split(sentences_inter, y, test_size = 0.3)\n",
    "    # Vectorisation des phrases\n",
    "    word2vec = Word2Vec(sentences=sentences_train)\n",
    "    # Création des données d'entrée.\n",
    "    X_train = embedding(word2vec,sentences_train)\n",
    "    X_test = embedding(word2vec,sentences_test)\n",
    "    X_train_pad = pad_sequences(X_train, padding='post',value=-1000, dtype='float32')\n",
    "    X_test_pad = pad_sequences(X_test, padding='post',value=-1000, dtype='float32')\n",
    "    # Création des données cibles.\n",
    "    y_train = y_train.values\n",
    "    y_test = y_test.values\n",
    "    # Sorties de la fonction\n",
    "    return X_train_pad, y_train, X_test_pad, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(word2vec, sentence):\n",
    "    y = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv.vocab.keys():\n",
    "           y.append(word2vec[word])\n",
    "    return np.array(y)\n",
    "\n",
    "def embedding(word2vec, sentences):\n",
    "    \n",
    "    y = []\n",
    "    for sentence in sentences:\n",
    "        y.append(embed_sentence(word2vec, sentence))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = get_train_test_objects(testbase_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking(mask_value = -1000))\n",
    "    model.add(layers.LSTM(13, activation='tanh'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du modèle et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1470 samples, validate on 630 samples\n",
      "Epoch 1/1000\n",
      "1470/1470 [==============================] - 9s 6ms/sample - loss: 2.3030 - acc: 0.0878 - val_loss: 2.3041 - val_acc: 0.0857\n",
      "Epoch 2/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.3019 - acc: 0.0966 - val_loss: 2.3073 - val_acc: 0.0968\n",
      "Epoch 3/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2995 - acc: 0.1150 - val_loss: 2.3057 - val_acc: 0.0857\n",
      "Epoch 4/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2958 - acc: 0.1034 - val_loss: 2.2994 - val_acc: 0.0968\n",
      "Epoch 5/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2918 - acc: 0.1177 - val_loss: 2.2964 - val_acc: 0.1206\n",
      "Epoch 6/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.2876 - acc: 0.1218 - val_loss: 2.2943 - val_acc: 0.1175\n",
      "Epoch 7/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.2844 - acc: 0.1388 - val_loss: 2.2913 - val_acc: 0.1476\n",
      "Epoch 8/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2808 - acc: 0.1456 - val_loss: 2.2873 - val_acc: 0.1333\n",
      "Epoch 9/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2779 - acc: 0.1449 - val_loss: 2.2894 - val_acc: 0.1429\n",
      "Epoch 10/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2768 - acc: 0.1463 - val_loss: 2.2808 - val_acc: 0.1333\n",
      "Epoch 11/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2729 - acc: 0.1463 - val_loss: 2.2779 - val_acc: 0.1492\n",
      "Epoch 12/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.2695 - acc: 0.1354 - val_loss: 2.2762 - val_acc: 0.1508\n",
      "Epoch 13/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.2670 - acc: 0.1476 - val_loss: 2.2767 - val_acc: 0.1397\n",
      "Epoch 14/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2652 - acc: 0.1497 - val_loss: 2.2723 - val_acc: 0.1460\n",
      "Epoch 15/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2623 - acc: 0.1565 - val_loss: 2.2773 - val_acc: 0.1429\n",
      "Epoch 16/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.2615 - acc: 0.1435 - val_loss: 2.2678 - val_acc: 0.1508\n",
      "Epoch 17/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2577 - acc: 0.1537 - val_loss: 2.2679 - val_acc: 0.1492\n",
      "Epoch 18/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2526 - acc: 0.1544 - val_loss: 2.2625 - val_acc: 0.1413\n",
      "Epoch 19/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2509 - acc: 0.1660 - val_loss: 2.2514 - val_acc: 0.1381\n",
      "Epoch 20/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2399 - acc: 0.1782 - val_loss: 2.2556 - val_acc: 0.1540\n",
      "Epoch 21/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2359 - acc: 0.1646 - val_loss: 2.2426 - val_acc: 0.1429\n",
      "Epoch 22/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2291 - acc: 0.1823 - val_loss: 2.2398 - val_acc: 0.1492\n",
      "Epoch 23/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2253 - acc: 0.1810 - val_loss: 2.2447 - val_acc: 0.1619\n",
      "Epoch 24/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2227 - acc: 0.1776 - val_loss: 2.2410 - val_acc: 0.1476\n",
      "Epoch 25/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2175 - acc: 0.1776 - val_loss: 2.2283 - val_acc: 0.1571\n",
      "Epoch 26/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2152 - acc: 0.1857 - val_loss: 2.2276 - val_acc: 0.1619\n",
      "Epoch 27/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2130 - acc: 0.1891 - val_loss: 2.2229 - val_acc: 0.1794\n",
      "Epoch 28/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2117 - acc: 0.1762 - val_loss: 2.2268 - val_acc: 0.1651\n",
      "Epoch 29/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2084 - acc: 0.1939 - val_loss: 2.2186 - val_acc: 0.1762\n",
      "Epoch 30/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2063 - acc: 0.1844 - val_loss: 2.2191 - val_acc: 0.1746\n",
      "Epoch 31/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2017 - acc: 0.1796 - val_loss: 2.2152 - val_acc: 0.1778\n",
      "Epoch 32/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.2020 - acc: 0.1823 - val_loss: 2.2205 - val_acc: 0.1667\n",
      "Epoch 33/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1947 - acc: 0.1925 - val_loss: 2.2223 - val_acc: 0.1730\n",
      "Epoch 34/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1941 - acc: 0.2007 - val_loss: 2.2162 - val_acc: 0.1857\n",
      "Epoch 35/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1915 - acc: 0.1925 - val_loss: 2.2183 - val_acc: 0.1762\n",
      "Epoch 36/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1926 - acc: 0.1905 - val_loss: 2.2152 - val_acc: 0.1825\n",
      "Epoch 37/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1862 - acc: 0.1857 - val_loss: 2.2160 - val_acc: 0.1889\n",
      "Epoch 38/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1835 - acc: 0.1959 - val_loss: 2.2218 - val_acc: 0.1730\n",
      "Epoch 39/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1836 - acc: 0.1993 - val_loss: 2.2225 - val_acc: 0.1778\n",
      "Epoch 40/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1860 - acc: 0.1946 - val_loss: 2.2202 - val_acc: 0.1825\n",
      "Epoch 41/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1820 - acc: 0.1905 - val_loss: 2.2135 - val_acc: 0.1825\n",
      "Epoch 42/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1842 - acc: 0.1898 - val_loss: 2.2202 - val_acc: 0.1730\n",
      "Epoch 43/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1784 - acc: 0.1986 - val_loss: 2.2248 - val_acc: 0.1746\n",
      "Epoch 44/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1785 - acc: 0.2014 - val_loss: 2.2217 - val_acc: 0.1778\n",
      "Epoch 45/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1774 - acc: 0.1932 - val_loss: 2.2158 - val_acc: 0.1810\n",
      "Epoch 46/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1802 - acc: 0.1912 - val_loss: 2.2159 - val_acc: 0.1873\n",
      "Epoch 47/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1773 - acc: 0.1973 - val_loss: 2.2192 - val_acc: 0.1810\n",
      "Epoch 48/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1753 - acc: 0.1946 - val_loss: 2.2194 - val_acc: 0.1778\n",
      "Epoch 49/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1756 - acc: 0.1980 - val_loss: 2.2151 - val_acc: 0.1857\n",
      "Epoch 50/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1760 - acc: 0.1966 - val_loss: 2.2148 - val_acc: 0.1794\n",
      "Epoch 51/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1715 - acc: 0.2020 - val_loss: 2.2185 - val_acc: 0.1905\n",
      "Epoch 52/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1724 - acc: 0.1918 - val_loss: 2.2121 - val_acc: 0.1810\n",
      "Epoch 53/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1712 - acc: 0.2034 - val_loss: 2.2211 - val_acc: 0.1762\n",
      "Epoch 54/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1697 - acc: 0.1980 - val_loss: 2.2212 - val_acc: 0.1762\n",
      "Epoch 55/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1710 - acc: 0.1932 - val_loss: 2.2122 - val_acc: 0.1873\n",
      "Epoch 56/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1698 - acc: 0.2041 - val_loss: 2.2199 - val_acc: 0.1730\n",
      "Epoch 57/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1717 - acc: 0.2048 - val_loss: 2.2180 - val_acc: 0.1714\n",
      "Epoch 58/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1690 - acc: 0.1952 - val_loss: 2.2235 - val_acc: 0.1698\n",
      "Epoch 59/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1675 - acc: 0.1912 - val_loss: 2.2161 - val_acc: 0.1794\n",
      "Epoch 60/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1659 - acc: 0.1986 - val_loss: 2.2170 - val_acc: 0.1841\n",
      "Epoch 61/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1705 - acc: 0.1925 - val_loss: 2.2219 - val_acc: 0.1746\n",
      "Epoch 62/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1634 - acc: 0.2000 - val_loss: 2.2192 - val_acc: 0.1746 loss\n",
      "Epoch 63/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1670 - acc: 0.1939 - val_loss: 2.2180 - val_acc: 0.1746\n",
      "Epoch 64/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1647 - acc: 0.2020 - val_loss: 2.2143 - val_acc: 0.1905\n",
      "Epoch 65/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1621 - acc: 0.1891 - val_loss: 2.2113 - val_acc: 0.1905\n",
      "Epoch 66/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1611 - acc: 0.2014 - val_loss: 2.2260 - val_acc: 0.1857\n",
      "Epoch 67/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1624 - acc: 0.1959 - val_loss: 2.2225 - val_acc: 0.1730\n",
      "Epoch 68/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1589 - acc: 0.2061 - val_loss: 2.2243 - val_acc: 0.1698\n",
      "Epoch 69/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1603 - acc: 0.2020 - val_loss: 2.2237 - val_acc: 0.1683\n",
      "Epoch 70/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1613 - acc: 0.1986 - val_loss: 2.2129 - val_acc: 0.1794\n",
      "Epoch 71/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1601 - acc: 0.1918 - val_loss: 2.2107 - val_acc: 0.1889\n",
      "Epoch 72/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1581 - acc: 0.2088 - val_loss: 2.2154 - val_acc: 0.1825\n",
      "Epoch 73/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1574 - acc: 0.2088 - val_loss: 2.2145 - val_acc: 0.1825\n",
      "Epoch 74/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1549 - acc: 0.2014 - val_loss: 2.2140 - val_acc: 0.1873\n",
      "Epoch 75/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1532 - acc: 0.2007 - val_loss: 2.2198 - val_acc: 0.1762\n",
      "Epoch 76/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1547 - acc: 0.2007 - val_loss: 2.2252 - val_acc: 0.1730\n",
      "Epoch 77/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1558 - acc: 0.2082 - val_loss: 2.2245 - val_acc: 0.1730\n",
      "Epoch 78/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1528 - acc: 0.2088 - val_loss: 2.2154 - val_acc: 0.1762\n",
      "Epoch 79/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1518 - acc: 0.2075 - val_loss: 2.2213 - val_acc: 0.1794\n",
      "Epoch 80/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1483 - acc: 0.2082 - val_loss: 2.2250 - val_acc: 0.1794\n",
      "Epoch 81/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1474 - acc: 0.2156 - val_loss: 2.2203 - val_acc: 0.1778\n",
      "Epoch 82/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1487 - acc: 0.2150 - val_loss: 2.2192 - val_acc: 0.1873\n",
      "Epoch 83/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1477 - acc: 0.1986 - val_loss: 2.2160 - val_acc: 0.1889\n",
      "Epoch 84/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1498 - acc: 0.1912 - val_loss: 2.2183 - val_acc: 0.1810\n",
      "Epoch 85/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1473 - acc: 0.2027 - val_loss: 2.2302 - val_acc: 0.1698\n",
      "Epoch 86/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1472 - acc: 0.2088 - val_loss: 2.2163 - val_acc: 0.1841\n",
      "Epoch 87/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1453 - acc: 0.2048 - val_loss: 2.2370 - val_acc: 0.1746\n",
      "Epoch 88/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1446 - acc: 0.2170 - val_loss: 2.2293 - val_acc: 0.1778\n",
      "Epoch 89/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1440 - acc: 0.2034 - val_loss: 2.2229 - val_acc: 0.1778\n",
      "Epoch 90/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1422 - acc: 0.1939 - val_loss: 2.2175 - val_acc: 0.1794\n",
      "Epoch 91/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1408 - acc: 0.2088 - val_loss: 2.2229 - val_acc: 0.1746\n",
      "Epoch 92/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1432 - acc: 0.2156 - val_loss: 2.2388 - val_acc: 0.1810\n",
      "Epoch 93/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1386 - acc: 0.1980 - val_loss: 2.2276 - val_acc: 0.1857\n",
      "Epoch 94/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1405 - acc: 0.2136 - val_loss: 2.2247 - val_acc: 0.1794\n",
      "Epoch 95/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1341 - acc: 0.2136 - val_loss: 2.2325 - val_acc: 0.1778\n",
      "Epoch 96/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1420 - acc: 0.2109 - val_loss: 2.2177 - val_acc: 0.1810\n",
      "Epoch 97/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1376 - acc: 0.2109 - val_loss: 2.2231 - val_acc: 0.1810\n",
      "Epoch 98/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1391 - acc: 0.2143 - val_loss: 2.2225 - val_acc: 0.1841\n",
      "Epoch 99/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1362 - acc: 0.2150 - val_loss: 2.2421 - val_acc: 0.1778\n",
      "Epoch 100/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1398 - acc: 0.2136 - val_loss: 2.2273 - val_acc: 0.1841\n",
      "Epoch 101/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1306 - acc: 0.2116 - val_loss: 2.2230 - val_acc: 0.1746\n",
      "Epoch 102/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1318 - acc: 0.2095 - val_loss: 2.2314 - val_acc: 0.1810\n",
      "Epoch 103/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1293 - acc: 0.2095 - val_loss: 2.2160 - val_acc: 0.1873\n",
      "Epoch 104/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1282 - acc: 0.2224 - val_loss: 2.2369 - val_acc: 0.1841\n",
      "Epoch 105/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1284 - acc: 0.2061 - val_loss: 2.2258 - val_acc: 0.1841\n",
      "Epoch 106/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1256 - acc: 0.2156 - val_loss: 2.2379 - val_acc: 0.1825\n",
      "Epoch 107/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1271 - acc: 0.2197 - val_loss: 2.2199 - val_acc: 0.1905\n",
      "Epoch 108/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1254 - acc: 0.2122 - val_loss: 2.2321 - val_acc: 0.1746\n",
      "Epoch 109/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1240 - acc: 0.2224 - val_loss: 2.2273 - val_acc: 0.1810\n",
      "Epoch 110/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1190 - acc: 0.2245 - val_loss: 2.2274 - val_acc: 0.1857\n",
      "Epoch 111/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1211 - acc: 0.2197 - val_loss: 2.2348 - val_acc: 0.1825\n",
      "Epoch 112/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1182 - acc: 0.2204 - val_loss: 2.2334 - val_acc: 0.1857\n",
      "Epoch 113/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1176 - acc: 0.2238 - val_loss: 2.2261 - val_acc: 0.1825\n",
      "Epoch 114/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1200 - acc: 0.2163 - val_loss: 2.2321 - val_acc: 0.1778\n",
      "Epoch 115/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1151 - acc: 0.2245 - val_loss: 2.2294 - val_acc: 0.1730\n",
      "Epoch 116/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1159 - acc: 0.2109 - val_loss: 2.2250 - val_acc: 0.1746\n",
      "Epoch 117/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1124 - acc: 0.2184 - val_loss: 2.2379 - val_acc: 0.1857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1065 - acc: 0.2218 - val_loss: 2.2352 - val_acc: 0.1635\n",
      "Epoch 119/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1124 - acc: 0.2259 - val_loss: 2.2278 - val_acc: 0.1746\n",
      "Epoch 120/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1117 - acc: 0.2197 - val_loss: 2.2276 - val_acc: 0.1762\n",
      "Epoch 121/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1072 - acc: 0.2184 - val_loss: 2.2346 - val_acc: 0.1825\n",
      "Epoch 122/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1029 - acc: 0.2272 - val_loss: 2.2244 - val_acc: 0.1841\n",
      "Epoch 123/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1072 - acc: 0.2231 - val_loss: 2.2351 - val_acc: 0.1810\n",
      "Epoch 124/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1019 - acc: 0.2293 - val_loss: 2.2390 - val_acc: 0.1778\n",
      "Epoch 125/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.1016 - acc: 0.2306 - val_loss: 2.2418 - val_acc: 0.1810\n",
      "Epoch 126/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.0952 - acc: 0.2245 - val_loss: 2.2490 - val_acc: 0.1778\n",
      "Epoch 127/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.0952 - acc: 0.2245 - val_loss: 2.2283 - val_acc: 0.1810\n",
      "Epoch 128/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.0973 - acc: 0.2327 - val_loss: 2.2433 - val_acc: 0.1746\n",
      "Epoch 129/1000\n",
      "1470/1470 [==============================] - 5s 3ms/sample - loss: 2.1003 - acc: 0.2211 - val_loss: 2.2459 - val_acc: 0.1714\n",
      "Epoch 130/1000\n",
      " 656/1470 [============>.................] - ETA: 2s - loss: 2.1101 - acc: 0.2256"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-466-241b3d862987>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience = 100, monitor='val_loss', restore_best_weights=True)\n",
    "model = init_model()\n",
    "model.fit(X_train, y_train, batch_size = 8, epochs=1000, validation_split = 0.3, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 249us/sample - loss: 2.1847 - acc: 0.1967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1847495693630643, 0.19666667]"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renvoie le député le plus proche de votre tweet\n",
    "def predict_deputy(df, model, tweet, by_tweet = False):\n",
    "    '''\n",
    "    La fonction prend la base de données originale (par député), un modèle entraîné et un texte en entrée.\n",
    "    Elle renvoie le député le plus proche du texte proposé.\n",
    "    Attention : le texte en entrée doit être une liste d'au moins deux éléments (strings).\n",
    "    Quand by_tweet = False, on ressort le député le plus proche de l'ENSEMBLE des tweets.\n",
    "    Quand by_tweet = True, on sort le député le plus proche POUR CHAQUE tweet.\n",
    "    '''\n",
    "    tweet_inter = []\n",
    "    for tw in tweet:\n",
    "        tweet_inter.append(tw.split())\n",
    "    X_example = embedding(word2vec,tweet_inter)\n",
    "    X_example_pad = pad_sequences(X_example, padding='post',value=-1000, dtype='float32')\n",
    "    prediction = model.predict(X_example_pad)\n",
    "    if not by_tweet:\n",
    "        deputy = list(df['name'])[prediction.sum(axis=0).argmax()]\n",
    "        return deputy\n",
    "    else:\n",
    "        deputies_by_tweet = []\n",
    "        for element in prediction:\n",
    "            deputies_by_tweet.append(list(df['name'])[element.argmax()])\n",
    "        return deputies_by_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_deputy(testbase_deputy_df,\n",
    "                            model, \n",
    "                            ['the northern ireland protocol must protected line real effort must made earnest week bridge gap talks come table many times good faith amp view securing future partnership respects standards union', \n",
    "                             'member special committee beating cancer look forward working members contributing important fight cancer',\n",
    "                             'this month shining light childrens cancer parliament buildings lit gold highlight survivors childrens cancer well diagnosed cancer'], \n",
    "                            by_tweet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maria WALSH'"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this month shining light childrens cancer parliament buildings lit gold highlight survivors childrens cancer well diagnosed cancer'"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbase_df['content'][24724]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24722</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>the northern ireland protocol must protected l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24723</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>member special committee beating cancer look f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>this month shining light childrens cancer parl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24725</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>yesterday told europe need keep speed amp infr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24726</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>this letter sent taoiseach clear seeking clari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130490</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>brendan its favourite item desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130491</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>monday mornings mean tidy desk chaos ahead wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130492</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>fergal post kick new week thank folks like mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130493</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>it took rare vision unique leadership see beyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130494</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>took mins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mep_id           name  country  \\\n",
       "24722   124988  Deirdre CLUNE  Ireland   \n",
       "24723   124988  Deirdre CLUNE  Ireland   \n",
       "24724   124988  Deirdre CLUNE  Ireland   \n",
       "24725   124988  Deirdre CLUNE  Ireland   \n",
       "24726   124988  Deirdre CLUNE  Ireland   \n",
       "...        ...            ...      ...   \n",
       "130490  197863    Maria WALSH  Ireland   \n",
       "130491  197863    Maria WALSH  Ireland   \n",
       "130492  197863    Maria WALSH  Ireland   \n",
       "130493  197863    Maria WALSH  Ireland   \n",
       "130494  197863    Maria WALSH  Ireland   \n",
       "\n",
       "                                                    group        nat_group  \\\n",
       "24722   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24723   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24724   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24725   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24726   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "...                                                   ...              ...   \n",
       "130490  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130491  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130492  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130493  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130494  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "\n",
       "                twitter                                            content  \n",
       "24722   deirdreclunemep  the northern ireland protocol must protected l...  \n",
       "24723   deirdreclunemep  member special committee beating cancer look f...  \n",
       "24724   deirdreclunemep  this month shining light childrens cancer parl...  \n",
       "24725   deirdreclunemep  yesterday told europe need keep speed amp infr...  \n",
       "24726   deirdreclunemep  this letter sent taoiseach clear seeking clari...  \n",
       "...                 ...                                                ...  \n",
       "130490     mariawalsheu                    brendan its favourite item desk  \n",
       "130491     mariawalsheu  monday mornings mean tidy desk chaos ahead wee...  \n",
       "130492     mariawalsheu  fergal post kick new week thank folks like mak...  \n",
       "130493     mariawalsheu  it took rare vision unique leadership see beyo...  \n",
       "130494     mariawalsheu                                          took mins  \n",
       "\n",
       "[3000 rows x 7 columns]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbase_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196.267px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
