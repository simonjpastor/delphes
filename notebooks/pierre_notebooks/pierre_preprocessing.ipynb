{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression des éléments indésirables de nos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lecture et stockage de la base de données\n",
    "tweet_df = pd.read_pickle('../../delphes/data/final4_clean.csv')\n",
    "tweet_df.head()\n",
    "new_test_df = pd.read_pickle('../../delphes/data/extended_tweet_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(0, tweet_df.shape[0])\n",
    "tweet_df['index'] = y\n",
    "tweet_df.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the undesirable elements in the entire dataframe\n",
    "def rmurl_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the URLs, the #hashtag and the @user of a column made of strings.\n",
    "    Be careful to apply it BEFORE all the other preprocessing steps (if not it wont'\n",
    "    be recognized as a URL)\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].str.replace('http\\S+|www.\\S+|@\\S+|#\\S+', '', case=False)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase the tweet's column\n",
    "def lower_df(df, column_name):\n",
    "    '''\n",
    "    This function lowercases a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the numbers in the tweet's column\n",
    "def rmnumbers_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the digits of a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def remove_numbers(text):\n",
    "        return ''.join(word for word in text if not word.isdigit())\n",
    "    df[column_name] = df[column_name].apply(remove_numbers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the undesirable punctuations in the tweet's column\n",
    "def rmpunct_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the punctuations, all the \"rt\" and remove multiple spaces\n",
    "    of a column made of strings.\n",
    "    '''\n",
    "    punct = string.punctuation\n",
    "    df = df.copy()\n",
    "    def replace_punct(text):\n",
    "        for punctu in punct:\n",
    "            text = text.replace(punctu, ' ')\n",
    "        text = text.replace(' rt ','')\n",
    "        text = \" \".join(text.split())\n",
    "        return text\n",
    "    df[column_name] = df[column_name].apply(replace_punct)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stopwords in the tweet's column\n",
    "def rmstopwords_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the stopwords of a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    stop_words = stopwords.words('english')\n",
    "    def remove_stopwords(text):\n",
    "        for word in stop_words:\n",
    "            text = text.replace(f' {word} ', ' ')\n",
    "        return text\n",
    "    df[column_name] = df[column_name].apply(remove_stopwords)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize a column in a dataset\n",
    "def lemmatize_df(df, column_name):\n",
    "    '''\n",
    "    This function lemmatize the words of a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def lemmatize(text):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        retour = []\n",
    "        for word in text:\n",
    "            retour.append(lemmatizer.lemmatize(word))\n",
    "        text = ''.join(word for word in retour)\n",
    "        return text\n",
    "\n",
    "    df[column_name] = df[column_name].apply(lemmatize)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erase all the words that are 1-letter or 2-letters long\n",
    "def erase_fewletter_df(df, column_name):\n",
    "    '''\n",
    "    One or two letters words are deleted from the dataset.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def tester(text):\n",
    "        text = ' '.join( [w for w in text.split() if len(w)>2] )\n",
    "        return text\n",
    "\n",
    "    df[column_name] = df[column_name].apply(tester)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the undesirable emojis in the entire dataframe\n",
    "def rmemojis_df(df):\n",
    "    '''\n",
    "    This function removes all the emojis of a column made of strings.\n",
    "    Be careful to translate in latin alphabet before applying this function : \n",
    "    it also removes cyrillic alphabet\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df = df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>[@danutahuebner Bardzo dziękuję @danutahuebner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189525</td>\n",
       "      <td>Asim ADEMOV</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Citizens for European Development of Bulgaria</td>\n",
       "      <td>AdemovAsim</td>\n",
       "      <td>[135 години единна и силна България. \\nЧестит ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124831</td>\n",
       "      <td>Isabella ADINOLFI</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Non-attached Members</td>\n",
       "      <td>Movimento 5 Stelle</td>\n",
       "      <td>Isa_Adinolfi</td>\n",
       "      <td>[Sembra un film, ma purtroppo è realtà: le imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125045</td>\n",
       "      <td>Clara AGUILERA</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista Obrero Español</td>\n",
       "      <td>ClaraAguilera7</td>\n",
       "      <td>[Clara Aguilera: \"El criterio científico debe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204335</td>\n",
       "      <td>Alviina ALAMETSÄ</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Group of the Greens/European Free Alliance</td>\n",
       "      <td>Vihreä liitto</td>\n",
       "      <td>alviinaalametsa</td>\n",
       "      <td>[@LHurttila @MariaOhisalo Kaupungilla on järje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>124884</td>\n",
       "      <td>Kosma ZŁOTOWSKI</td>\n",
       "      <td>Poland</td>\n",
       "      <td>European Conservatives and Reformists Group</td>\n",
       "      <td>Prawo i Sprawiedliwość</td>\n",
       "      <td>KosmaZlotowski</td>\n",
       "      <td>[https://t.co/7NnVzDXmis, Dziś inauguracja!\\nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>197621</td>\n",
       "      <td>Juan Ignacio ZOIDO ÁLVAREZ</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Partido Popular</td>\n",
       "      <td>zoidoji</td>\n",
       "      <td>[Desde @ppegrupo reclamamos una mayor segurida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>124739</td>\n",
       "      <td>Carlos ZORRINHO</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Partido Socialista</td>\n",
       "      <td>czorrinho</td>\n",
       "      <td>[@sofiaferreira57 O meu mail profissional é pú...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>185341</td>\n",
       "      <td>Željana ZOVKO</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Hrvatska demokratska zajednica</td>\n",
       "      <td>ZovkoEU</td>\n",
       "      <td>[Svim učenicima, a naročito prvašićima te njih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>[Genialno! https://t.co/7L2cpVkVJn, “@Europarl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mep_id                        name   country  \\\n",
       "index                                                 \n",
       "0      197490         Magdalena ADAMOWICZ    Poland   \n",
       "1      189525                 Asim ADEMOV  Bulgaria   \n",
       "2      124831           Isabella ADINOLFI     Italy   \n",
       "3      125045              Clara AGUILERA     Spain   \n",
       "4      204335            Alviina ALAMETSÄ   Finland   \n",
       "...       ...                         ...       ...   \n",
       "470    124884             Kosma ZŁOTOWSKI    Poland   \n",
       "471    197621  Juan Ignacio ZOIDO ÁLVAREZ     Spain   \n",
       "472    124739             Carlos ZORRINHO  Portugal   \n",
       "473    185341               Željana ZOVKO   Croatia   \n",
       "474     96933                  Milan ZVER  Slovenia   \n",
       "\n",
       "                                                   group  \\\n",
       "index                                                      \n",
       "0      Group of the European People's Party (Christia...   \n",
       "1      Group of the European People's Party (Christia...   \n",
       "2                                   Non-attached Members   \n",
       "3      Group of the Progressive Alliance of Socialist...   \n",
       "4             Group of the Greens/European Free Alliance   \n",
       "...                                                  ...   \n",
       "470          European Conservatives and Reformists Group   \n",
       "471    Group of the European People's Party (Christia...   \n",
       "472    Group of the Progressive Alliance of Socialist...   \n",
       "473    Group of the European People's Party (Christia...   \n",
       "474    Group of the European People's Party (Christia...   \n",
       "\n",
       "                                           nat_group          twitter  \\\n",
       "index                                                                   \n",
       "0                                        Independent  Adamowicz_Magda   \n",
       "1      Citizens for European Development of Bulgaria       AdemovAsim   \n",
       "2                                 Movimento 5 Stelle     Isa_Adinolfi   \n",
       "3                  Partido Socialista Obrero Español   ClaraAguilera7   \n",
       "4                                      Vihreä liitto  alviinaalametsa   \n",
       "...                                              ...              ...   \n",
       "470                           Prawo i Sprawiedliwość   KosmaZlotowski   \n",
       "471                                  Partido Popular          zoidoji   \n",
       "472                               Partido Socialista        czorrinho   \n",
       "473                   Hrvatska demokratska zajednica          ZovkoEU   \n",
       "474                    Slovenska demokratska stranka        MilanZver   \n",
       "\n",
       "                                                 content  \n",
       "index                                                     \n",
       "0      [@danutahuebner Bardzo dziękuję @danutahuebner...  \n",
       "1      [135 години единна и силна България. \\nЧестит ...  \n",
       "2      [Sembra un film, ma purtroppo è realtà: le imm...  \n",
       "3      [Clara Aguilera: \"El criterio científico debe ...  \n",
       "4      [@LHurttila @MariaOhisalo Kaupungilla on järje...  \n",
       "...                                                  ...  \n",
       "470    [https://t.co/7NnVzDXmis, Dziś inauguracja!\\nh...  \n",
       "471    [Desde @ppegrupo reclamamos una mayor segurida...  \n",
       "472    [@sofiaferreira57 O meu mail profissional é pú...  \n",
       "473    [Svim učenicima, a naročito prvašićima te njih...  \n",
       "474    [Genialno! https://t.co/7L2cpVkVJn, “@Europarl...  \n",
       "\n",
       "[475 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = rmurl_df(new_test_df, 'content')\n",
    "clean_df = lower_df(clean_df, 'content')\n",
    "clean_df = rmnumbers_df(clean_df, 'content')\n",
    "clean_df = rmpunct_df(clean_df, 'content')\n",
    "clean_df = rmstopwords_df(clean_df, 'content')\n",
    "clean_df = lemmatize_df(clean_df, 'content')\n",
    "clean_df = erase_fewletter_df(clean_df, 'content')\n",
    "clean_df = rmemojis_df(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_pickle('BDD smooth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>bardzo dzikuj niezalene wadzy wolne media daj ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>komisja przyja arcywane projekty pilotaowe aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>komisja przyja projekty pilotaowe mojego wspau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>tym dniu tym miejscu tej godzinie prosz jedno ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>bg nie potrzebuje by przez nikogo broniony nie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137295</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>tedenska akcija etrtka srede zbornik bela knji...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137296</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>strong amp way forward european future read eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137297</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>date noted worrying state danger ends special ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137298</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>vsi vedo nekaj noro strahu pred nasilnimi levi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137299</th>\n",
       "      <td>96933</td>\n",
       "      <td>Milan ZVER</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Slovenska demokratska stranka</td>\n",
       "      <td>MilanZver</td>\n",
       "      <td>tota ekipa tak gre kranja najlepim navijakim p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mep_id                 name   country  \\\n",
       "0       197490  Magdalena ADAMOWICZ    Poland   \n",
       "1       197490  Magdalena ADAMOWICZ    Poland   \n",
       "2       197490  Magdalena ADAMOWICZ    Poland   \n",
       "3       197490  Magdalena ADAMOWICZ    Poland   \n",
       "4       197490  Magdalena ADAMOWICZ    Poland   \n",
       "...        ...                  ...       ...   \n",
       "137295   96933           Milan ZVER  Slovenia   \n",
       "137296   96933           Milan ZVER  Slovenia   \n",
       "137297   96933           Milan ZVER  Slovenia   \n",
       "137298   96933           Milan ZVER  Slovenia   \n",
       "137299   96933           Milan ZVER  Slovenia   \n",
       "\n",
       "                                                    group  \\\n",
       "0       Group of the European People's Party (Christia...   \n",
       "1       Group of the European People's Party (Christia...   \n",
       "2       Group of the European People's Party (Christia...   \n",
       "3       Group of the European People's Party (Christia...   \n",
       "4       Group of the European People's Party (Christia...   \n",
       "...                                                   ...   \n",
       "137295  Group of the European People's Party (Christia...   \n",
       "137296  Group of the European People's Party (Christia...   \n",
       "137297  Group of the European People's Party (Christia...   \n",
       "137298  Group of the European People's Party (Christia...   \n",
       "137299  Group of the European People's Party (Christia...   \n",
       "\n",
       "                            nat_group          twitter  \\\n",
       "0                         Independent  Adamowicz_Magda   \n",
       "1                         Independent  Adamowicz_Magda   \n",
       "2                         Independent  Adamowicz_Magda   \n",
       "3                         Independent  Adamowicz_Magda   \n",
       "4                         Independent  Adamowicz_Magda   \n",
       "...                               ...              ...   \n",
       "137295  Slovenska demokratska stranka        MilanZver   \n",
       "137296  Slovenska demokratska stranka        MilanZver   \n",
       "137297  Slovenska demokratska stranka        MilanZver   \n",
       "137298  Slovenska demokratska stranka        MilanZver   \n",
       "137299  Slovenska demokratska stranka        MilanZver   \n",
       "\n",
       "                                                  content  \n",
       "0       bardzo dzikuj niezalene wadzy wolne media daj ...  \n",
       "1       komisja przyja arcywane projekty pilotaowe aut...  \n",
       "2       komisja przyja projekty pilotaowe mojego wspau...  \n",
       "3       tym dniu tym miejscu tej godzinie prosz jedno ...  \n",
       "4       bg nie potrzebuje by przez nikogo broniony nie...  \n",
       "...                                                   ...  \n",
       "137295  tedenska akcija etrtka srede zbornik bela knji...  \n",
       "137296  strong amp way forward european future read eu...  \n",
       "137297  date noted worrying state danger ends special ...  \n",
       "137298  vsi vedo nekaj noro strahu pred nasilnimi levi...  \n",
       "137299  tota ekipa tak gre kranja najlepim navijakim p...  \n",
       "\n",
       "[137300 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbase_df = clean_df[clean_df['country'] == 'Ireland']\n",
    "testbase_deputy_df = tweet_df[tweet_df['country'] == 'Ireland']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction retourne automatiquement X_train, X_test, y_train, y_test de notre base de données twitter.\n",
    "def get_train_test_objects(df):\n",
    "    '''\n",
    "    Les étapes que cette fonction réalise sont en commentaires.\n",
    "    '''\n",
    "    # Copie de la base de données pour éviter les problèmes d'assignation abusive.\n",
    "    df = df.copy() \n",
    "    # Récupération de tous les tweets et du nom du député qui les a posté. Création de la cible y.\n",
    "    df = df[['name', 'content']]\n",
    "    y = pd.get_dummies(df['name'])\n",
    "    # Transformation des tweets en suite de mots (strings) dans une liste.\n",
    "    sentences = df['content']\n",
    "    sentences_inter = []\n",
    "    for sentence in sentences:\n",
    "        sentences_inter.append(sentence.split())\n",
    "    # Séparation des données d'entraînement et de test\n",
    "    sentences_train, sentences_test, y_train, y_test = train_test_split(sentences_inter, y, test_size = 0.3)\n",
    "    # Vectorisation des phrases\n",
    "    word2vec = Word2Vec(sentences=sentences_train)\n",
    "    # Création des données d'entrée.\n",
    "    X_train = embedding(word2vec,sentences_train)\n",
    "    X_test = embedding(word2vec,sentences_test)\n",
    "    X_train_pad = pad_sequences(X_train, padding='post',value=-1000, dtype='float32')\n",
    "    X_test_pad = pad_sequences(X_test, padding='post',value=-1000, dtype='float32')\n",
    "    # Création des données cibles.\n",
    "    y_train = y_train.values\n",
    "    y_test = y_test.values\n",
    "    # Sorties de la fonction\n",
    "    return X_train_pad, y_train, X_test_pad, y_test, word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(word2vec, sentence):\n",
    "    y = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv.vocab.keys():\n",
    "           y.append(word2vec[word])\n",
    "    return np.array(y)\n",
    "\n",
    "def embedding(word2vec, sentences):\n",
    "    \n",
    "    y = []\n",
    "    for sentence in sentences:\n",
    "        y.append(embed_sentence(word2vec, sentence))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, word2vec = get_train_test_objects(testbase_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 27, 100)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking(mask_value = -1000))\n",
    "    model.add(layers.LSTM(13, activation='tanh'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du modèle et évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 1470 samples, validate on 630 samples\n",
      "Epoch 1/1000\n",
      "1470/1470 [==============================] - 8s 6ms/sample - loss: 2.3025 - acc: 0.1061 - val_loss: 2.3024 - val_acc: 0.0889\n",
      "Epoch 2/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2993 - acc: 0.1034 - val_loss: 2.2971 - val_acc: 0.0905\n",
      "Epoch 3/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2879 - acc: 0.1252 - val_loss: 2.2920 - val_acc: 0.1540\n",
      "Epoch 4/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2735 - acc: 0.1381 - val_loss: 2.2675 - val_acc: 0.1238\n",
      "Epoch 5/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2617 - acc: 0.1435 - val_loss: 2.2535 - val_acc: 0.1381\n",
      "Epoch 6/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2527 - acc: 0.1469 - val_loss: 2.2486 - val_acc: 0.1381\n",
      "Epoch 7/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2444 - acc: 0.1401 - val_loss: 2.2491 - val_acc: 0.1413\n",
      "Epoch 8/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2409 - acc: 0.1422 - val_loss: 2.2418 - val_acc: 0.1397\n",
      "Epoch 9/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2373 - acc: 0.1367 - val_loss: 2.2498 - val_acc: 0.1492\n",
      "Epoch 10/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2351 - acc: 0.1367 - val_loss: 2.2388 - val_acc: 0.1397\n",
      "Epoch 11/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2348 - acc: 0.1510 - val_loss: 2.2424 - val_acc: 0.1333\n",
      "Epoch 12/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2326 - acc: 0.1435 - val_loss: 2.2383 - val_acc: 0.1381\n",
      "Epoch 13/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2317 - acc: 0.1456 - val_loss: 2.2433 - val_acc: 0.1444\n",
      "Epoch 14/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2304 - acc: 0.1408 - val_loss: 2.2375 - val_acc: 0.1397\n",
      "Epoch 15/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2246 - acc: 0.1429 - val_loss: 2.2425 - val_acc: 0.1476\n",
      "Epoch 16/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2234 - acc: 0.1456 - val_loss: 2.2426 - val_acc: 0.1397\n",
      "Epoch 17/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2233 - acc: 0.1510 - val_loss: 2.2407 - val_acc: 0.1683\n",
      "Epoch 18/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2219 - acc: 0.1544 - val_loss: 2.2361 - val_acc: 0.1794\n",
      "Epoch 19/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2170 - acc: 0.1592 - val_loss: 2.2387 - val_acc: 0.1698\n",
      "Epoch 20/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2149 - acc: 0.1748 - val_loss: 2.2356 - val_acc: 0.1651\n",
      "Epoch 21/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.2125 - acc: 0.1639 - val_loss: 2.2295 - val_acc: 0.1825\n",
      "Epoch 22/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2073 - acc: 0.1796 - val_loss: 2.2441 - val_acc: 0.1730\n",
      "Epoch 23/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.2040 - acc: 0.1776 - val_loss: 2.2267 - val_acc: 0.1841\n",
      "Epoch 24/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1966 - acc: 0.1830 - val_loss: 2.2256 - val_acc: 0.1778\n",
      "Epoch 25/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1950 - acc: 0.1857 - val_loss: 2.2199 - val_acc: 0.1873\n",
      "Epoch 26/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1923 - acc: 0.1952 - val_loss: 2.2202 - val_acc: 0.1921\n",
      "Epoch 27/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1872 - acc: 0.1986 - val_loss: 2.2193 - val_acc: 0.1825\n",
      "Epoch 28/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1819 - acc: 0.1837 - val_loss: 2.2140 - val_acc: 0.1825\n",
      "Epoch 29/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1855 - acc: 0.1959 - val_loss: 2.2511 - val_acc: 0.1698\n",
      "Epoch 30/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1851 - acc: 0.1966 - val_loss: 2.2228 - val_acc: 0.1825\n",
      "Epoch 31/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1804 - acc: 0.1932 - val_loss: 2.2159 - val_acc: 0.1698\n",
      "Epoch 32/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1770 - acc: 0.2000 - val_loss: 2.2383 - val_acc: 0.1810\n",
      "Epoch 33/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1773 - acc: 0.1932 - val_loss: 2.2254 - val_acc: 0.1730\n",
      "Epoch 34/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1733 - acc: 0.2007 - val_loss: 2.2121 - val_acc: 0.1937\n",
      "Epoch 35/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1739 - acc: 0.2068 - val_loss: 2.2100 - val_acc: 0.1810\n",
      "Epoch 36/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1722 - acc: 0.2007 - val_loss: 2.2146 - val_acc: 0.1667\n",
      "Epoch 37/1000\n",
      "1470/1470 [==============================] - 7s 4ms/sample - loss: 2.1732 - acc: 0.1912 - val_loss: 2.2520 - val_acc: 0.1667\n",
      "Epoch 38/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1686 - acc: 0.2007 - val_loss: 2.2258 - val_acc: 0.1730\n",
      "Epoch 39/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1743 - acc: 0.1952 - val_loss: 2.2158 - val_acc: 0.1921\n",
      "Epoch 40/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1699 - acc: 0.1980 - val_loss: 2.2287 - val_acc: 0.1889\n",
      "Epoch 41/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1649 - acc: 0.2061 - val_loss: 2.2385 - val_acc: 0.1778\n",
      "Epoch 42/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1620 - acc: 0.2088 - val_loss: 2.2101 - val_acc: 0.1905\n",
      "Epoch 43/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1694 - acc: 0.1959 - val_loss: 2.2159 - val_acc: 0.1905\n",
      "Epoch 44/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1583 - acc: 0.2054 - val_loss: 2.2170 - val_acc: 0.1857\n",
      "Epoch 45/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1663 - acc: 0.2075 - val_loss: 2.2271 - val_acc: 0.1873\n",
      "Epoch 46/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1620 - acc: 0.2095 - val_loss: 2.2196 - val_acc: 0.1683\n",
      "Epoch 47/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1588 - acc: 0.2068 - val_loss: 2.2298 - val_acc: 0.1889\n",
      "Epoch 48/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1577 - acc: 0.2075 - val_loss: 2.2267 - val_acc: 0.1746\n",
      "Epoch 49/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1589 - acc: 0.2082 - val_loss: 2.2181 - val_acc: 0.1730\n",
      "Epoch 50/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1545 - acc: 0.1986 - val_loss: 2.2315 - val_acc: 0.1841\n",
      "Epoch 51/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1601 - acc: 0.1966 - val_loss: 2.2635 - val_acc: 0.1714\n",
      "Epoch 52/1000\n",
      "1470/1470 [==============================] - 7s 4ms/sample - loss: 2.1547 - acc: 0.2095 - val_loss: 2.2350 - val_acc: 0.1810\n",
      "Epoch 53/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1504 - acc: 0.2102 - val_loss: 2.2528 - val_acc: 0.1730\n",
      "Epoch 54/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.1506 - acc: 0.2034 - val_loss: 2.2213 - val_acc: 0.1794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.1492 - acc: 0.2102 - val_loss: 2.2284 - val_acc: 0.1841\n",
      "Epoch 56/1000\n",
      "1470/1470 [==============================] - 8s 5ms/sample - loss: 2.1510 - acc: 0.2027 - val_loss: 2.2547 - val_acc: 0.1714\n",
      "Epoch 57/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1466 - acc: 0.2163 - val_loss: 2.2573 - val_acc: 0.1841\n",
      "Epoch 58/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1480 - acc: 0.2054 - val_loss: 2.2201 - val_acc: 0.1746\n",
      "Epoch 59/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1446 - acc: 0.2048 - val_loss: 2.2430 - val_acc: 0.1651\n",
      "Epoch 60/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1484 - acc: 0.2014 - val_loss: 2.2225 - val_acc: 0.1810\n",
      "Epoch 61/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1407 - acc: 0.2136 - val_loss: 2.2437 - val_acc: 0.1698 loss: 2.1440 - ac\n",
      "Epoch 62/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1394 - acc: 0.2095 - val_loss: 2.2272 - val_acc: 0.1794\n",
      "Epoch 63/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1430 - acc: 0.2150 - val_loss: 2.2277 - val_acc: 0.1730\n",
      "Epoch 64/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1439 - acc: 0.2136 - val_loss: 2.2355 - val_acc: 0.1714\n",
      "Epoch 65/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1363 - acc: 0.2116 - val_loss: 2.2576 - val_acc: 0.1698\n",
      "Epoch 66/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1376 - acc: 0.2170 - val_loss: 2.2373 - val_acc: 0.1825\n",
      "Epoch 67/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1382 - acc: 0.2136 - val_loss: 2.2333 - val_acc: 0.1714\n",
      "Epoch 68/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1387 - acc: 0.2177 - val_loss: 2.2258 - val_acc: 0.1873\n",
      "Epoch 69/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1347 - acc: 0.2095 - val_loss: 2.2333 - val_acc: 0.1857\n",
      "Epoch 70/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1312 - acc: 0.2143 - val_loss: 2.2615 - val_acc: 0.1651\n",
      "Epoch 71/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1352 - acc: 0.2265 - val_loss: 2.2460 - val_acc: 0.1841\n",
      "Epoch 72/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1325 - acc: 0.2224 - val_loss: 2.2919 - val_acc: 0.1667\n",
      "Epoch 73/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1311 - acc: 0.2190 - val_loss: 2.2287 - val_acc: 0.1762\n",
      "Epoch 74/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1332 - acc: 0.2170 - val_loss: 2.2411 - val_acc: 0.1762\n",
      "Epoch 75/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1297 - acc: 0.2190 - val_loss: 2.2426 - val_acc: 0.1762\n",
      "Epoch 76/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1267 - acc: 0.2231 - val_loss: 2.2611 - val_acc: 0.1778\n",
      "Epoch 77/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1261 - acc: 0.2265 - val_loss: 2.2601 - val_acc: 0.1698\n",
      "Epoch 78/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1315 - acc: 0.2184 - val_loss: 2.2298 - val_acc: 0.1714\n",
      "Epoch 79/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1276 - acc: 0.2170 - val_loss: 2.2288 - val_acc: 0.1762\n",
      "Epoch 80/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1217 - acc: 0.2184 - val_loss: 2.2468 - val_acc: 0.1746\n",
      "Epoch 81/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1326 - acc: 0.2177 - val_loss: 2.2464 - val_acc: 0.1667\n",
      "Epoch 82/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.1281 - acc: 0.2170 - val_loss: 2.2222 - val_acc: 0.1714\n",
      "Epoch 83/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.1267 - acc: 0.2150 - val_loss: 2.2472 - val_acc: 0.1778\n",
      "Epoch 84/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1198 - acc: 0.2245 - val_loss: 2.2861 - val_acc: 0.1698\n",
      "Epoch 85/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1245 - acc: 0.2224 - val_loss: 2.2741 - val_acc: 0.1746\n",
      "Epoch 86/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1237 - acc: 0.2238 - val_loss: 2.2397 - val_acc: 0.1730\n",
      "Epoch 87/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1191 - acc: 0.2238 - val_loss: 2.2484 - val_acc: 0.1810\n",
      "Epoch 88/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1151 - acc: 0.2252 - val_loss: 2.2423 - val_acc: 0.1714\n",
      "Epoch 89/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1154 - acc: 0.2238 - val_loss: 2.2625 - val_acc: 0.1714\n",
      "Epoch 90/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1193 - acc: 0.2245 - val_loss: 2.2401 - val_acc: 0.1762\n",
      "Epoch 91/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1162 - acc: 0.2259 - val_loss: 2.2680 - val_acc: 0.1651\n",
      "Epoch 92/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1139 - acc: 0.2306 - val_loss: 2.2426 - val_acc: 0.1746\n",
      "Epoch 93/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1166 - acc: 0.2265 - val_loss: 2.2569 - val_acc: 0.1825\n",
      "Epoch 94/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1121 - acc: 0.2177 - val_loss: 2.2539 - val_acc: 0.1746\n",
      "Epoch 95/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1180 - acc: 0.2218 - val_loss: 2.2389 - val_acc: 0.1810\n",
      "Epoch 96/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1081 - acc: 0.2320 - val_loss: 2.2250 - val_acc: 0.1857\n",
      "Epoch 97/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1110 - acc: 0.2245 - val_loss: 2.2789 - val_acc: 0.1778\n",
      "Epoch 98/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1100 - acc: 0.2259 - val_loss: 2.2576 - val_acc: 0.1698\n",
      "Epoch 99/1000\n",
      "1470/1470 [==============================] - 8s 5ms/sample - loss: 2.1056 - acc: 0.2293 - val_loss: 2.2329 - val_acc: 0.1921\n",
      "Epoch 100/1000\n",
      "1470/1470 [==============================] - 8s 5ms/sample - loss: 2.1045 - acc: 0.2422 - val_loss: 2.2640 - val_acc: 0.1762\n",
      "Epoch 101/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1044 - acc: 0.2259 - val_loss: 2.2314 - val_acc: 0.1841\n",
      "Epoch 102/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1072 - acc: 0.2238 - val_loss: 2.2376 - val_acc: 0.1778\n",
      "Epoch 103/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.1096 - acc: 0.2286 - val_loss: 2.2572 - val_acc: 0.1714\n",
      "Epoch 104/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0990 - acc: 0.2279 - val_loss: 2.2469 - val_acc: 0.1825\n",
      "Epoch 105/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0986 - acc: 0.2354 - val_loss: 2.2916 - val_acc: 0.1746\n",
      "Epoch 106/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0999 - acc: 0.2395 - val_loss: 2.2576 - val_acc: 0.1794\n",
      "Epoch 107/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1003 - acc: 0.2333 - val_loss: 2.2614 - val_acc: 0.1730\n",
      "Epoch 108/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.1023 - acc: 0.2354 - val_loss: 2.2968 - val_acc: 0.1730\n",
      "Epoch 109/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0990 - acc: 0.2299 - val_loss: 2.2453 - val_acc: 0.1810\n",
      "Epoch 110/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0977 - acc: 0.2333 - val_loss: 2.2457 - val_acc: 0.1746\n",
      "Epoch 111/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0970 - acc: 0.2333 - val_loss: 2.3022 - val_acc: 0.1698\n",
      "Epoch 112/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0912 - acc: 0.2286 - val_loss: 2.2835 - val_acc: 0.1714\n",
      "Epoch 113/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0893 - acc: 0.2347 - val_loss: 2.2942 - val_acc: 0.1698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0899 - acc: 0.2333 - val_loss: 2.2601 - val_acc: 0.1762\n",
      "Epoch 115/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0861 - acc: 0.2395 - val_loss: 2.2712 - val_acc: 0.1778\n",
      "Epoch 116/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0879 - acc: 0.2293 - val_loss: 2.3003 - val_acc: 0.1794\n",
      "Epoch 117/1000\n",
      "1470/1470 [==============================] - 7s 5ms/sample - loss: 2.0894 - acc: 0.2340 - val_loss: 2.2726 - val_acc: 0.1794\n",
      "Epoch 118/1000\n",
      "1470/1470 [==============================] - 8s 5ms/sample - loss: 2.0880 - acc: 0.2333 - val_loss: 2.2890 - val_acc: 0.1873\n",
      "Epoch 119/1000\n",
      "1470/1470 [==============================] - 8s 5ms/sample - loss: 2.0847 - acc: 0.2320 - val_loss: 2.2643 - val_acc: 0.1714\n",
      "Epoch 120/1000\n",
      "1470/1470 [==============================] - 7s 4ms/sample - loss: 2.0907 - acc: 0.2442 - val_loss: 2.2782 - val_acc: 0.1683\n",
      "Epoch 121/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0851 - acc: 0.2361 - val_loss: 2.2970 - val_acc: 0.1746\n",
      "Epoch 122/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0778 - acc: 0.2354 - val_loss: 2.2872 - val_acc: 0.1778\n",
      "Epoch 123/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0854 - acc: 0.2367 - val_loss: 2.2734 - val_acc: 0.1730\n",
      "Epoch 124/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0805 - acc: 0.2442 - val_loss: 2.3038 - val_acc: 0.1667\n",
      "Epoch 125/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0815 - acc: 0.2374 - val_loss: 2.2732 - val_acc: 0.1778\n",
      "Epoch 126/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0770 - acc: 0.2231 - val_loss: 2.2946 - val_acc: 0.1556\n",
      "Epoch 127/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0827 - acc: 0.2374 - val_loss: 2.3058 - val_acc: 0.1651\n",
      "Epoch 128/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0748 - acc: 0.2469 - val_loss: 2.2772 - val_acc: 0.1841\n",
      "Epoch 129/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0775 - acc: 0.2354 - val_loss: 2.3022 - val_acc: 0.1683\n",
      "Epoch 130/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0751 - acc: 0.2531 - val_loss: 2.2461 - val_acc: 0.1968\n",
      "Epoch 131/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0806 - acc: 0.2313 - val_loss: 2.3212 - val_acc: 0.1714\n",
      "Epoch 132/1000\n",
      "1470/1470 [==============================] - 6s 4ms/sample - loss: 2.0792 - acc: 0.2259 - val_loss: 2.2792 - val_acc: 0.1841\n",
      "Epoch 133/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0662 - acc: 0.2401 - val_loss: 2.3151 - val_acc: 0.1698\n",
      "Epoch 134/1000\n",
      "1470/1470 [==============================] - 5s 4ms/sample - loss: 2.0704 - acc: 0.2571 - val_loss: 2.2953 - val_acc: 0.1603\n",
      "Epoch 135/1000\n",
      "1470/1470 [==============================] - 4s 3ms/sample - loss: 2.0761 - acc: 0.2463 - val_loss: 2.3523 - val_acc: 0.1667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x215e7c38a08>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience = 100, monitor='val_loss', restore_best_weights=True)\n",
    "model = init_model()\n",
    "model.fit(X_train, y_train, batch_size = 8, epochs=1000, validation_split = 0.3, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 0s 122us/sample - loss: 2.2132 - acc: 0.1800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.213210598627726, 0.18]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renvoie le député le plus proche de votre tweet\n",
    "def predict_deputy(df, model, tweet, by_tweet = False):\n",
    "    '''\n",
    "    La fonction prend la base de données originale (par député), un modèle entraîné et un texte en entrée.\n",
    "    Elle renvoie le député le plus proche du texte proposé.\n",
    "    Attention : le texte en entrée doit être une liste d'au moins deux éléments (strings).\n",
    "    Quand by_tweet = False, on ressort le député le plus proche de l'ENSEMBLE des tweets.\n",
    "    Quand by_tweet = True, on sort le député le plus proche POUR CHAQUE tweet.\n",
    "    '''\n",
    "    tweet_inter = []\n",
    "    for tw in tweet:\n",
    "        tweet_inter.append(tw.split())\n",
    "    X_example = embedding(word2vec,tweet_inter)\n",
    "    X_example_pad = pad_sequences(X_example, padding='post',value=-1000, dtype='float32')\n",
    "    prediction = model.predict(X_example_pad)\n",
    "    if not by_tweet:\n",
    "        deputy = list(df['name'])[prediction.sum(axis=0).argmax()]\n",
    "        return deputy\n",
    "    else:\n",
    "        deputies_by_tweet = []\n",
    "        for element in prediction:\n",
    "            deputies_by_tweet.append(list(df['name'])[element.argmax()])\n",
    "        return deputies_by_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_deputy(testbase_deputy_df,\n",
    "                            model, \n",
    "                            ['the northern ireland protocol must protected line real effort must made earnest week bridge gap talks come table many times good faith amp view securing future partnership respects standards union', \n",
    "                             'member special committee beating cancer look forward working members contributing important fight cancer',\n",
    "                             'this month shining light childrens cancer parliament buildings lit gold highlight survivors childrens cancer well diagnosed cancer'], \n",
    "                            by_tweet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Luke Ming FLANAGAN'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this month shining light childrens cancer parliament buildings lit gold highlight survivors childrens cancer well diagnosed cancer'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbase_df['content'][24724]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24722</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>the northern ireland protocol must protected l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24723</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>member special committee beating cancer look f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24724</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>this month shining light childrens cancer parl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24725</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>yesterday told europe need keep speed amp infr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24726</th>\n",
       "      <td>124988</td>\n",
       "      <td>Deirdre CLUNE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>deirdreclunemep</td>\n",
       "      <td>this letter sent taoiseach clear seeking clari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130490</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>brendan its favourite item desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130491</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>monday mornings mean tidy desk chaos ahead wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130492</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>fergal post kick new week thank folks like mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130493</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>it took rare vision unique leadership see beyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130494</th>\n",
       "      <td>197863</td>\n",
       "      <td>Maria WALSH</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Fine Gael Party</td>\n",
       "      <td>mariawalsheu</td>\n",
       "      <td>took mins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mep_id           name  country  \\\n",
       "24722   124988  Deirdre CLUNE  Ireland   \n",
       "24723   124988  Deirdre CLUNE  Ireland   \n",
       "24724   124988  Deirdre CLUNE  Ireland   \n",
       "24725   124988  Deirdre CLUNE  Ireland   \n",
       "24726   124988  Deirdre CLUNE  Ireland   \n",
       "...        ...            ...      ...   \n",
       "130490  197863    Maria WALSH  Ireland   \n",
       "130491  197863    Maria WALSH  Ireland   \n",
       "130492  197863    Maria WALSH  Ireland   \n",
       "130493  197863    Maria WALSH  Ireland   \n",
       "130494  197863    Maria WALSH  Ireland   \n",
       "\n",
       "                                                    group        nat_group  \\\n",
       "24722   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24723   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24724   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24725   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "24726   Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "...                                                   ...              ...   \n",
       "130490  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130491  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130492  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130493  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "130494  Group of the European People's Party (Christia...  Fine Gael Party   \n",
       "\n",
       "                twitter                                            content  \n",
       "24722   deirdreclunemep  the northern ireland protocol must protected l...  \n",
       "24723   deirdreclunemep  member special committee beating cancer look f...  \n",
       "24724   deirdreclunemep  this month shining light childrens cancer parl...  \n",
       "24725   deirdreclunemep  yesterday told europe need keep speed amp infr...  \n",
       "24726   deirdreclunemep  this letter sent taoiseach clear seeking clari...  \n",
       "...                 ...                                                ...  \n",
       "130490     mariawalsheu                    brendan its favourite item desk  \n",
       "130491     mariawalsheu  monday mornings mean tidy desk chaos ahead wee...  \n",
       "130492     mariawalsheu  fergal post kick new week thank folks like mak...  \n",
       "130493     mariawalsheu  it took rare vision unique leadership see beyo...  \n",
       "130494     mariawalsheu                                          took mins  \n",
       "\n",
       "[3000 rows x 7 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbase_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bac à sable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "danish_df = pd.read_pickle('../../delphes/data/merger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = danish_df[['name','content_y']].dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>content_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Margrete AUKEN</td>\n",
       "      <td>[False, [0.101227, -0.00355242, -0.0613298, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Margrete AUKEN</td>\n",
       "      <td>[[-0.0540806, 0.0168135, 0.0596281, 0.0681775,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Margrete AUKEN</td>\n",
       "      <td>[[0.00612917, 0.0156791, -0.0486738, 0.0480299...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Margrete AUKEN</td>\n",
       "      <td>[False, [-0.0484475, 0.011017, -0.0737066, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Margrete AUKEN</td>\n",
       "      <td>[[-0.0989527, 0.0149615, 0.0241871, 0.0582589,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11178</th>\n",
       "      <td>11225</td>\n",
       "      <td>Lara WOLTERS</td>\n",
       "      <td>[[0.0495577, 0.129444, -0.0491547, 0.00429166,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11179</th>\n",
       "      <td>11226</td>\n",
       "      <td>Lara WOLTERS</td>\n",
       "      <td>[False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11180</th>\n",
       "      <td>11227</td>\n",
       "      <td>Lara WOLTERS</td>\n",
       "      <td>[[-0.0972181, -0.0736294, 0.00087396, 0.063221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11181</th>\n",
       "      <td>11228</td>\n",
       "      <td>Lara WOLTERS</td>\n",
       "      <td>[[-0.0196253, -0.00134424, -0.035015, -0.01173...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11182</th>\n",
       "      <td>11229</td>\n",
       "      <td>Lara WOLTERS</td>\n",
       "      <td>[[-0.0603085, -0.00909752, -0.0233168, 0.00935...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11183 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index            name  \\\n",
       "0          0  Margrete AUKEN   \n",
       "1          2  Margrete AUKEN   \n",
       "2          3  Margrete AUKEN   \n",
       "3          4  Margrete AUKEN   \n",
       "4          5  Margrete AUKEN   \n",
       "...      ...             ...   \n",
       "11178  11225    Lara WOLTERS   \n",
       "11179  11226    Lara WOLTERS   \n",
       "11180  11227    Lara WOLTERS   \n",
       "11181  11228    Lara WOLTERS   \n",
       "11182  11229    Lara WOLTERS   \n",
       "\n",
       "                                               content_y  \n",
       "0      [False, [0.101227, -0.00355242, -0.0613298, 0....  \n",
       "1      [[-0.0540806, 0.0168135, 0.0596281, 0.0681775,...  \n",
       "2      [[0.00612917, 0.0156791, -0.0486738, 0.0480299...  \n",
       "3      [False, [-0.0484475, 0.011017, -0.0737066, 0.0...  \n",
       "4      [[-0.0989527, 0.0149615, 0.0241871, 0.0582589,...  \n",
       "...                                                  ...  \n",
       "11178  [[0.0495577, 0.129444, -0.0491547, 0.00429166,...  \n",
       "11179                                            [False]  \n",
       "11180  [[-0.0972181, -0.0736294, 0.00087396, 0.063221...  \n",
       "11181  [[-0.0196253, -0.00134424, -0.035015, -0.01173...  \n",
       "11182  [[-0.0603085, -0.00909752, -0.0233168, 0.00935...  \n",
       "\n",
       "[11183 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11183"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df['content_y'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(working_df['content_y'][0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_items = [x if type(x) == np.ndarray else np.array([-1000]*100) for x in working_df['content_y'][4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.0989527 ,  0.0149615 ,  0.0241871 ,  0.0582589 , -0.0471224 ,\n",
       "        -0.0545909 ,  0.00883459, -0.0963067 , -0.0200379 ,  0.0645213 ,\n",
       "         0.00059959, -0.0359953 ,  0.0905238 , -0.019637  , -0.119255  ,\n",
       "        -0.0085331 , -0.0910109 , -0.0317265 ,  0.0437045 ,  0.042118  ,\n",
       "        -0.0413337 ,  0.0793529 , -0.0958057 , -0.0859956 , -0.070275  ,\n",
       "         0.0277338 ,  0.0245911 , -0.0532877 ,  0.0901591 , -0.0341724 ,\n",
       "        -0.0523973 ,  0.06913   , -0.0358292 ,  0.0490628 , -0.0533377 ,\n",
       "        -0.0590526 , -0.018908  , -0.0680928 ,  0.0428848 ,  0.00446642,\n",
       "         0.0254242 ,  0.029823  , -0.022389  , -0.0298494 , -0.00220434,\n",
       "         0.0236405 , -0.0202339 ,  0.071565  ,  0.00653942,  0.04787   ,\n",
       "         0.0241135 , -0.00861419, -0.072192  , -0.0061101 , -0.0421144 ,\n",
       "        -0.0441334 ,  0.0284948 ,  0.0101265 ,  0.0494711 ,  0.123695  ,\n",
       "         0.00318411, -0.147268  ,  0.0619475 , -0.0521131 , -0.0270893 ,\n",
       "        -0.183071  , -0.121067  , -0.0656926 , -0.0165341 , -0.0223939 ,\n",
       "        -0.10311   , -0.0083929 , -0.0333061 , -0.0526112 ,  0.0165277 ,\n",
       "        -0.0327824 ,  0.0616622 ,  0.0594702 ,  0.0993909 , -0.0510955 ,\n",
       "         0.0830312 ,  0.0582175 ,  0.0153089 ,  0.0289257 ,  0.0362474 ,\n",
       "        -0.0191453 , -0.0215853 ,  0.0261856 , -0.0631056 , -0.0648426 ,\n",
       "         0.0558779 , -0.0445291 ,  0.135379  , -0.101287  ,  0.038438  ,\n",
       "        -0.0827063 , -0.0383208 , -0.0152323 , -0.0476188 , -0.0468658 ,\n",
       "        -0.0542656 , -0.0580748 ,  0.0420483 , -0.00439419, -0.0731066 ,\n",
       "        -0.0091356 ,  0.0121853 ,  0.0480795 ,  0.0349566 ,  0.0547057 ,\n",
       "         0.00998852, -0.0271251 , -0.0449232 , -0.0426174 ,  0.0352922 ,\n",
       "        -0.0287318 ,  0.0376553 ,  0.0320618 ,  0.0285692 ,  0.0178084 ,\n",
       "         0.048407  ,  0.0619917 , -0.055055  ,  0.106647  ,  0.0253918 ,\n",
       "         0.0525802 ,  0.0197148 , -0.00890542,  0.00598656,  0.0194034 ,\n",
       "        -0.0292739 ,  0.0368715 , -0.0179568 , -0.0300122 , -0.0650559 ,\n",
       "        -0.0651834 , -0.0387895 , -0.0621967 ,  0.0158234 ,  0.0659579 ,\n",
       "         0.00352722,  0.0852522 ,  0.066211  ,  0.0203579 , -0.0173361 ,\n",
       "         0.139383  , -0.00422552,  0.0189374 , -0.0169705 ,  0.00273325,\n",
       "        -0.0442308 ,  0.0745956 , -0.151366  , -0.0568039 ,  0.00567732,\n",
       "         0.00544129,  0.0264759 ,  0.0289792 ,  0.0637003 , -0.0340715 ,\n",
       "        -0.0776681 ,  0.112011  , -0.0153073 , -0.0437699 ,  0.0194354 ,\n",
       "         0.0231005 , -0.0357128 ,  0.0147792 ,  0.0550848 , -0.0891493 ,\n",
       "        -0.0424517 , -0.046213  , -0.00379674, -0.0229303 ,  0.0516334 ,\n",
       "         0.0646947 ,  0.0558348 ,  0.0355651 , -0.0481125 , -0.0485657 ,\n",
       "        -0.0154253 ,  0.0328468 ,  0.0445518 ,  0.0749986 , -0.0339969 ,\n",
       "         0.154216  ,  0.0551831 , -0.0970186 ,  0.0443259 ,  0.0116251 ,\n",
       "         0.0257857 , -0.170752  ,  0.00925622,  0.134997  ,  0.0145736 ,\n",
       "         0.00019884, -0.0451669 ,  0.0446348 , -0.120604  ,  0.00221411,\n",
       "        -0.0205539 ,  0.0731385 ,  0.0257906 ,  0.0764174 ,  0.0182389 ,\n",
       "        -0.161208  ,  0.0243736 , -0.10047   ,  0.00418342,  0.0429216 ,\n",
       "         0.068634  ,  0.0529642 ,  0.016401  , -0.0597428 ,  0.00065305,\n",
       "        -0.0978475 , -0.0302689 , -0.136625  , -0.0490717 , -0.0345632 ,\n",
       "         0.010944  , -0.0208777 ,  0.0088573 ,  0.0806433 ,  0.0149538 ,\n",
       "         0.00849751, -0.0719297 ,  0.023299  ,  0.0688159 , -0.0189077 ,\n",
       "         0.0705483 ,  0.00521012, -0.00081658,  0.026251  , -0.037198  ,\n",
       "         0.0668471 , -0.0535837 ,  0.00407454,  0.0130824 ,  0.0131746 ,\n",
       "         0.0209254 , -0.0638355 ,  0.0411621 , -0.0119615 ,  0.113764  ,\n",
       "         0.061355  ,  0.0508187 ,  0.0519696 ,  0.075192  , -0.0443278 ,\n",
       "         0.011108  ,  0.0223647 ,  0.0175076 , -0.0102293 , -0.020679  ,\n",
       "         0.0626609 , -0.118095  , -0.00371076, -0.0218424 ,  0.0262696 ,\n",
       "         0.00848937,  0.031513  , -0.0130209 , -0.0483868 , -0.0288906 ,\n",
       "        -0.0292638 ,  0.0112484 , -0.00444829,  0.00038752, -0.106706  ,\n",
       "        -0.122625  ,  0.00201625,  0.0395312 ,  0.120658  , -0.0315547 ,\n",
       "        -0.0437861 ,  0.096311  , -0.0171364 ,  0.0265467 , -0.0452086 ,\n",
       "        -0.0779524 ,  0.0788463 ,  0.0140948 ,  0.0442783 ,  0.07378   ,\n",
       "        -0.130531  , -0.0267014 ,  0.0930394 , -0.0488607 , -0.0123103 ,\n",
       "         0.00466786, -0.0449691 , -0.0239102 ,  0.053504  , -0.0242141 ,\n",
       "         0.0098897 , -0.023659  ,  0.0688187 ,  0.0284441 ,  0.0703361 ]),\n",
       " array([ 0.0347711 ,  0.0227996 ,  0.00855035,  0.0783043 ,  0.00131476,\n",
       "         0.0388395 , -0.0875899 , -0.00080729, -0.10943   ,  0.0485488 ,\n",
       "        -0.0772942 , -0.0150722 ,  0.00085707,  0.0157414 , -0.0264702 ,\n",
       "         0.0282836 , -0.029815  , -0.101515  ,  0.058424  ,  0.153964  ,\n",
       "        -0.108267  ,  0.0392746 , -0.0225626 , -0.0532319 , -0.0228943 ,\n",
       "         0.052138  ,  0.00347159, -0.00408953,  0.0810915 ,  0.1033    ,\n",
       "        -0.00320205, -0.0176746 , -0.0318655 ,  0.078651  ,  0.0604852 ,\n",
       "        -0.0841896 ,  0.044248  ,  0.0317206 ,  0.0583819 , -0.0570812 ,\n",
       "         0.0367215 , -0.00317002, -0.0430813 , -0.0145921 ,  0.0732543 ,\n",
       "        -0.0993289 , -0.0734331 , -0.0385835 ,  0.00241049, -0.0319251 ,\n",
       "        -0.0455528 ,  0.0448849 ,  0.0205504 ,  0.0525264 ,  0.0158019 ,\n",
       "         0.0707358 ,  0.0795654 ,  0.0655425 , -0.0715358 ,  0.0252856 ,\n",
       "        -0.0296636 , -0.0356076 ,  0.143652  , -0.0162504 ,  0.0486293 ,\n",
       "        -0.0896489 , -0.0908472 , -0.110488  , -0.156478  , -0.0772053 ,\n",
       "        -0.0529639 , -0.0888112 ,  0.0510788 , -0.0506636 , -0.0133846 ,\n",
       "         0.0308765 ,  0.0834933 ,  0.0760958 , -0.107865  , -0.14771   ,\n",
       "         0.0468751 , -0.0211803 ,  0.0002769 , -0.0330242 ,  0.00291464,\n",
       "        -0.0639546 ,  0.018149  ,  0.134127  , -0.019309  ,  0.00097367,\n",
       "         0.0720716 , -0.0805658 ,  0.0442723 , -0.0516359 ,  0.0496802 ,\n",
       "         0.0403421 , -0.06288   , -0.0424109 , -0.029929  , -0.0579152 ,\n",
       "        -0.120474  , -0.0512309 ,  0.0298952 ,  0.0447403 , -0.0548078 ,\n",
       "        -0.0563935 , -0.0461025 ,  0.0476901 ,  0.033032  , -0.0325125 ,\n",
       "         0.0316212 ,  0.00727299, -0.0533828 , -0.0854316 , -0.00476678,\n",
       "         0.170572  ,  0.0206913 ,  0.00131424, -0.0380568 ,  0.0339842 ,\n",
       "         0.0431223 , -0.0347859 , -0.0676187 ,  0.0888351 ,  0.103961  ,\n",
       "        -0.0940784 ,  0.0555548 ,  0.155061  ,  0.0610037 ,  0.104869  ,\n",
       "         0.0191174 , -0.00771662,  0.00174603, -0.0468458 ,  0.00137538,\n",
       "         0.0220087 ,  0.0587733 , -0.101938  ,  0.0560244 ,  0.0156604 ,\n",
       "         0.0325219 ,  0.0145222 ,  0.0571052 , -0.0172024 , -0.0598572 ,\n",
       "         0.0451231 , -0.0135101 ,  0.0341934 , -0.0721206 , -0.0333464 ,\n",
       "        -0.00512272, -0.0598136 , -0.0568441 , -0.012002  , -0.0450925 ,\n",
       "        -0.0116736 , -0.077133  , -0.0770892 ,  0.0633587 , -0.0370646 ,\n",
       "        -0.0101501 ,  0.0250233 ,  0.0532541 , -0.0520365 ,  0.0543121 ,\n",
       "         0.0206047 ,  0.0250953 ,  0.00253758,  0.114038  , -0.0558835 ,\n",
       "        -0.0422695 ,  0.0152061 , -0.0406124 , -0.076119  ,  0.0808858 ,\n",
       "         0.0697352 , -0.0114248 ,  0.0199487 , -0.055883  , -0.0119196 ,\n",
       "         0.026646  ,  0.0164262 , -0.0446601 ,  0.0293039 , -0.00826557,\n",
       "         0.00617807, -0.0461447 , -0.0433977 , -0.0278192 , -0.1197    ,\n",
       "        -0.0129556 , -0.135333  , -0.00985945,  0.00191902,  0.0247244 ,\n",
       "         0.041724  , -0.0188061 , -0.057998  , -0.0456102 , -0.0385027 ,\n",
       "         0.0860021 ,  0.036962  ,  0.0077301 ,  0.0401672 ,  0.0281805 ,\n",
       "        -0.077249  ,  0.00217825, -0.102859  ,  0.0182379 ,  0.0906881 ,\n",
       "         0.0926598 ,  0.0315605 ,  0.0361539 , -0.120955  , -0.0370319 ,\n",
       "        -0.0816854 ,  0.074265  , -0.032299  , -0.0383132 , -0.0347018 ,\n",
       "         0.0128217 ,  0.0218368 , -0.00391326, -0.0497475 , -0.0502783 ,\n",
       "         0.0957744 ,  0.00621955, -0.0162952 , -0.00674259, -0.0272048 ,\n",
       "        -0.100022  ,  0.015768  ,  0.0146565 ,  0.0789095 ,  0.00234354,\n",
       "         0.0253455 ,  0.00388011,  0.06083   , -0.0270716 ,  0.0075315 ,\n",
       "         0.0177912 , -0.044131  ,  0.0811396 ,  0.0721519 , -0.0409683 ,\n",
       "         0.0494527 , -0.0891722 ,  0.052078  ,  0.0406678 ,  0.0590905 ,\n",
       "         0.0284624 , -0.0104101 , -0.0228498 ,  0.0118247 ,  0.019693  ,\n",
       "         0.072924  , -0.0062186 , -0.0193636 ,  0.0984221 ,  0.0836411 ,\n",
       "        -0.0128665 ,  0.0233717 , -0.012775  , -0.0400703 , -0.110051  ,\n",
       "        -0.0554305 ,  0.0185338 ,  0.0471855 ,  0.00867597, -0.137953  ,\n",
       "        -0.099696  , -0.0547292 , -0.015932  , -0.0187441 , -0.00590911,\n",
       "        -0.0216038 ,  0.0186498 ,  0.0858231 , -0.0169013 ,  0.0866194 ,\n",
       "        -0.0428208 , -0.0297438 , -0.0466037 , -0.0212096 , -0.0149572 ,\n",
       "         0.00936094, -0.0606338 ,  0.0529017 , -0.0427373 ,  0.0600113 ,\n",
       "        -0.00453712,  0.0275925 ,  0.0183311 ,  0.0156186 , -0.00632284,\n",
       "        -0.067181  , -0.0781795 , -0.0187208 , -0.0279505 , -0.0450697 ]),\n",
       " array([-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000]),\n",
       " array([-0.0288281 ,  0.031716  ,  0.00725148,  0.0618517 , -0.0243452 ,\n",
       "         0.0878935 ,  0.0642076 , -0.0777458 , -0.0420356 ,  0.0601743 ,\n",
       "         0.0615396 ,  0.0285634 ,  0.0338225 , -0.0304442 , -0.0779993 ,\n",
       "        -0.00689596, -0.0334651 , -0.0454384 , -0.00922865,  0.0449786 ,\n",
       "        -0.0300909 ,  0.0560769 , -0.0718671 , -0.0850078 ,  0.0147975 ,\n",
       "         0.0116956 , -0.00987429,  0.0320368 , -0.0239584 ,  0.0392115 ,\n",
       "        -0.0942317 ,  0.112172  , -0.0737616 ,  0.0143143 ,  0.0196827 ,\n",
       "         0.00529284, -0.0808358 ,  0.0370192 ,  0.0154157 , -0.00422819,\n",
       "        -0.0171222 , -0.0412087 , -0.064022  ,  0.0570985 , -0.00376178,\n",
       "         0.106083  ,  0.0210085 ,  0.0401841 , -0.0448797 ,  0.0089958 ,\n",
       "        -0.00499336, -0.0381341 ,  0.0595323 , -0.00914405, -0.0326699 ,\n",
       "         0.0661888 ,  0.0420419 , -0.0146143 , -0.0101231 ,  0.109048  ,\n",
       "         0.0524824 , -0.0234702 ,  0.0380769 , -0.0711049 , -0.00295414,\n",
       "         0.00082622, -0.0608179 , -0.0442488 , -0.0136326 , -0.0183623 ,\n",
       "        -0.0274119 , -0.0274128 ,  0.0406236 , -0.0200173 , -0.109212  ,\n",
       "         0.00301042,  0.049797  ,  0.0934577 ,  0.0553296 , -0.0162443 ,\n",
       "        -0.0389703 ,  0.0259375 ,  0.0335823 , -0.104438  , -0.00348169,\n",
       "        -0.058841  , -0.0244972 ,  0.0672499 ,  0.00099778, -0.0445876 ,\n",
       "         0.0820142 ,  0.0703423 ,  0.026889  , -0.0662685 ,  0.0317469 ,\n",
       "        -0.050458  ,  0.138296  ,  0.0253227 ,  0.0114763 ,  0.00124745,\n",
       "        -0.066002  , -0.00172386,  0.101854  ,  0.028856  ,  0.0112037 ,\n",
       "        -0.0522591 , -0.112127  ,  0.0364444 ,  0.0474421 ,  0.00543501,\n",
       "        -0.0272122 ,  0.0395188 , -0.132018  , -0.00895856, -0.0120558 ,\n",
       "        -0.0484297 ,  0.0591631 ,  0.0565298 ,  0.0630075 ,  0.0606816 ,\n",
       "         0.0499608 ,  0.0452477 , -0.0439122 ,  0.151559  ,  0.0469507 ,\n",
       "         0.0392316 ,  0.0223148 ,  0.0935061 ,  0.0743853 , -0.021528  ,\n",
       "        -0.0107965 ,  0.100054  ,  0.0401965 ,  0.0491676 ,  0.0619648 ,\n",
       "        -0.0374043 ,  0.0205187 , -0.00724998,  0.00402663,  0.0710748 ,\n",
       "        -0.0417345 , -0.0591578 ,  0.0954673 , -0.0278512 ,  0.0257411 ,\n",
       "         0.0804795 , -0.0620717 ,  0.0094351 ,  0.0249983 ,  0.0474099 ,\n",
       "        -0.0182933 ,  0.0203465 , -0.0268009 , -0.0144965 , -0.0556057 ,\n",
       "         0.0255894 ,  0.0358908 , -0.0501891 ,  0.221124  ,  0.0401539 ,\n",
       "         0.0143576 ,  0.107301  , -0.127317  , -0.061268  ,  0.119575  ,\n",
       "        -0.034056  , -0.0671675 , -0.0377969 ,  0.0848058 ,  0.049791  ,\n",
       "        -0.0361733 , -0.0672862 ,  0.020245  ,  0.0794945 , -0.0508342 ,\n",
       "        -0.064378  ,  0.0737403 ,  0.0257486 , -0.0457456 , -0.0348088 ,\n",
       "        -0.0355723 ,  0.0530199 ,  0.0603588 ,  0.133343  ,  0.0624235 ,\n",
       "         0.0681521 ,  0.0885685 ,  0.044057  ,  0.0531987 , -0.056283  ,\n",
       "        -0.0119502 , -0.120083  ,  0.0130079 ,  0.0507809 ,  0.00305322,\n",
       "        -0.0815332 , -0.0392352 ,  0.0603222 , -0.0885471 , -0.011678  ,\n",
       "        -0.00331032, -0.060794  , -0.0793153 ,  0.0780425 , -0.112934  ,\n",
       "        -0.0655813 , -0.0377306 ,  0.0742229 ,  0.04807   , -0.00559028,\n",
       "         0.101504  ,  0.015519  , -0.00414267,  0.085512  , -0.0530611 ,\n",
       "        -0.0359842 , -0.0806188 , -0.0844296 , -0.0584793 , -0.0361393 ,\n",
       "        -0.0138337 , -0.00212838, -0.0152093 ,  0.0181534 ,  0.104925  ,\n",
       "         0.0468872 , -0.00374042,  0.0169769 , -0.0328377 ,  0.0246554 ,\n",
       "        -0.00964085,  0.0181563 , -0.0804316 ,  0.00053832, -0.0793149 ,\n",
       "         0.012011  , -0.0287345 , -0.0546993 ,  0.014776  ,  0.0119826 ,\n",
       "        -0.0936956 ,  0.0568836 ,  0.0425031 , -0.0807147 ,  0.11395   ,\n",
       "         0.103636  ,  0.0954982 ,  0.0050942 ,  0.0106802 , -0.0456168 ,\n",
       "         0.0079316 ,  0.0789593 , -0.0311908 , -0.0150342 , -0.0499112 ,\n",
       "         0.0246751 ,  0.0637675 , -0.0347172 ,  0.0424063 , -0.0164976 ,\n",
       "         0.0122291 ,  0.0463949 ,  0.0288876 , -0.0612486 , -0.0655882 ,\n",
       "        -0.0446632 , -0.0910001 ,  0.0761109 ,  0.00041088, -0.0300199 ,\n",
       "        -0.0338654 ,  0.109991  , -0.0043411 ,  0.0609306 ,  0.0323229 ,\n",
       "        -0.137706  ,  0.111895  ,  0.0533578 ,  0.0177069 , -0.0057116 ,\n",
       "         0.0723879 ,  0.0862748 , -0.0324197 ,  0.0187267 ,  0.0377177 ,\n",
       "        -0.0214782 , -0.00540344,  0.0616448 , -0.0754744 ,  0.0839065 ,\n",
       "        -0.00519861, -0.119222  ,  0.0230272 ,  0.018233  ,  0.0136431 ,\n",
       "        -0.0113487 , -0.0125661 , -0.00345394,  0.0734877 , -0.0208766 ]),\n",
       " array([-0.00279156, -0.0280951 , -0.00304171,  0.0515634 , -0.0831943 ,\n",
       "         0.0628178 , -0.00274107, -0.0397045 , -0.0211414 ,  0.136668  ,\n",
       "         0.0484429 , -0.034999  ,  0.0796449 , -0.0612746 , -0.0124574 ,\n",
       "        -0.0829766 , -0.0376883 , -0.0021093 ,  0.0393827 ,  0.0461007 ,\n",
       "        -0.0534278 ,  0.00866077, -0.0598213 , -0.0468718 , -0.10585   ,\n",
       "        -0.00644523,  0.0257553 , -0.0759231 ,  0.00884306,  0.0389429 ,\n",
       "        -0.0929501 ,  0.0662797 , -0.0404273 ,  0.0670257 ,  0.0658686 ,\n",
       "        -0.0985728 ,  0.00812874, -0.0209049 ,  0.106985  , -0.0169837 ,\n",
       "        -0.0087748 , -0.015718  ,  0.0037105 , -0.0239729 ,  0.0588756 ,\n",
       "        -0.0189209 ,  0.0122937 ,  0.0705626 , -0.0172505 , -0.0495768 ,\n",
       "         0.0228928 , -0.0166273 , -0.0179576 ,  0.0357296 , -0.0395255 ,\n",
       "         0.0150112 ,  0.00449113,  0.0582424 , -0.0203982 ,  0.0713682 ,\n",
       "        -0.0268818 , -0.0675197 ,  0.100137  , -0.0451476 , -0.0794716 ,\n",
       "        -0.0777905 , -0.103455  , -0.0230804 , -0.0911122 , -0.0200578 ,\n",
       "        -0.0862986 , -0.0115235 ,  0.00490226,  0.00754014, -0.0354914 ,\n",
       "         0.0110549 ,  0.0909583 ,  0.138524  , -0.0674072 ,  0.0309809 ,\n",
       "         0.0372476 ,  0.0989108 , -0.0905849 , -0.0202245 ,  0.00105112,\n",
       "        -0.0028463 , -0.0928727 , -0.0867577 ,  0.0264914 , -0.106458  ,\n",
       "        -0.0439139 ,  0.0172539 ,  0.118574  , -0.0405029 ,  0.0255637 ,\n",
       "        -0.0804809 ,  0.0614293 ,  0.102938  , -0.0579522 , -0.0138782 ,\n",
       "        -0.0431367 , -0.0117709 ,  0.0604258 ,  0.0255783 , -0.108815  ,\n",
       "        -0.0194799 , -0.142725  ,  0.0672619 , -0.0287627 ,  0.0748881 ,\n",
       "         0.0440381 ,  0.00920816,  0.00689482, -0.0528897 ,  0.00732972,\n",
       "        -0.0249019 ,  0.0323344 ,  0.0465389 ,  0.0702806 ,  0.0614941 ,\n",
       "         0.0932174 ,  0.0688896 , -0.0245698 ,  0.1515    , -0.00202552,\n",
       "        -0.0492271 ,  0.0753233 ,  0.00519548,  0.031079  ,  0.0479918 ,\n",
       "        -0.0405335 , -0.0068863 , -0.0334654 , -0.00902021, -0.0951454 ,\n",
       "         0.0572022 , -0.0315747 ,  0.0473014 , -0.057337  ,  0.1056    ,\n",
       "         0.00434139,  0.0343492 ,  0.0375236 ,  0.0648972 ,  0.029834  ,\n",
       "         0.168884  ,  0.040122  ,  0.00985438, -0.0201612 ,  0.0727969 ,\n",
       "        -0.00117466, -0.0744453 , -0.0216403 , -0.020443  , -0.0103446 ,\n",
       "        -0.0309552 ,  0.0186594 , -0.0493299 ,  0.0702438 , -0.00671413,\n",
       "        -0.0847846 ,  0.113338  , -0.132008  ,  0.070772  ,  0.0405604 ,\n",
       "         0.00326973, -0.0315601 , -0.0029274 ,  0.0716994 , -0.0471976 ,\n",
       "        -0.043039  , -0.0102339 , -0.0338621 , -0.0111148 , -0.0181239 ,\n",
       "         0.0459305 ,  0.0734375 ,  0.112315  , -0.0972663 , -0.0116795 ,\n",
       "         0.0428916 , -0.0892118 , -0.0421549 ,  0.102544  , -0.0216351 ,\n",
       "         0.0535444 ,  0.00239312,  0.0368682 ,  0.0354505 ,  0.0344736 ,\n",
       "         0.0365149 , -0.042439  ,  0.0310305 ,  0.0277794 ,  0.0077778 ,\n",
       "         0.0598859 , -0.0184123 ,  0.0370431 , -0.0338199 , -0.128509  ,\n",
       "        -0.00185295,  0.0133198 , -0.0665074 ,  0.0708151 ,  0.029096  ,\n",
       "        -0.0404977 , -0.0485742 , -0.0312872 ,  0.0119067 ,  0.0922824 ,\n",
       "         0.0794716 , -0.0304346 , -0.114248  ,  0.014847  , -0.0592935 ,\n",
       "        -0.0155661 , -0.00934147, -0.0799001 , -0.0500005 , -0.0318373 ,\n",
       "        -0.0255586 , -0.0609893 , -0.054885  ,  0.0462822 ,  0.0584899 ,\n",
       "         0.036807  , -0.0404648 ,  0.0138775 ,  0.1195    ,  0.0434308 ,\n",
       "         0.0599267 ,  0.0208246 , -0.0681929 ,  0.0247341 , -0.040354  ,\n",
       "         0.0307674 , -0.00514784, -0.0797213 , -0.00172349,  0.0333862 ,\n",
       "        -0.0328915 , -0.00689007,  0.0372407 , -0.0212228 , -0.00634546,\n",
       "         0.0130125 ,  0.10893   , -0.0151748 ,  0.0205017 ,  0.0244288 ,\n",
       "         0.00722475, -0.00903156,  0.0206554 , -0.115947  , -0.103465  ,\n",
       "         0.0612103 , -0.051864  , -0.0369781 ,  0.037308  ,  0.0440254 ,\n",
       "        -0.0210021 ,  0.116849  ,  0.0171627 , -0.0974104 , -0.0115791 ,\n",
       "         0.0446114 ,  0.010237  ,  0.00234069,  0.0221204 , -0.00900106,\n",
       "        -0.0616891 ,  0.0497139 , -0.0112089 ,  0.0794581 , -0.0535343 ,\n",
       "        -0.12763   ,  0.0900876 ,  0.0737426 ,  0.0952571 , -0.0513558 ,\n",
       "         0.0132397 ,  0.0728892 , -0.0185739 ,  0.051437  ,  0.0681919 ,\n",
       "         0.0439963 , -0.0586288 ,  0.0180393 , -0.0690226 , -0.00288014,\n",
       "         0.0540176 , -0.0133696 ,  0.0619024 ,  0.0805066 , -0.0583195 ,\n",
       "         0.0240672 , -0.122463  , -0.0413398 , -0.00136014,  0.0574583 ]),\n",
       " array([-0.039416  , -0.0282507 , -0.0737265 ,  0.0270041 , -0.0133747 ,\n",
       "         0.0323145 , -0.0399308 , -0.115104  , -0.0292737 , -0.145221  ,\n",
       "         0.0244139 ,  0.0280312 ,  0.0035551 , -0.063452  , -0.077725  ,\n",
       "        -0.0534146 , -0.0527696 ,  0.0180981 , -0.0435484 ,  0.06791   ,\n",
       "        -0.042111  , -0.086516  , -0.0591839 , -0.0751708 , -0.0755636 ,\n",
       "        -0.102007  ,  0.0279757 , -0.0254434 , -0.103506  ,  0.00396549,\n",
       "        -0.00892348,  0.0965829 ,  0.0244337 , -0.0862316 , -0.0273887 ,\n",
       "        -0.00448042,  0.0871104 , -0.0546948 ,  0.0436205 ,  0.0427268 ,\n",
       "        -0.00809433,  0.0445293 , -0.0155797 ,  0.0303014 ,  0.00231543,\n",
       "         0.0449084 , -0.0473794 , -0.00304056,  0.0178736 , -0.0242829 ,\n",
       "        -0.0208573 , -0.0823699 ,  0.0089181 , -0.0679178 ,  0.0656624 ,\n",
       "        -0.0227185 ,  0.0113326 ,  0.0244495 , -0.101894  , -0.0047501 ,\n",
       "        -0.0275223 , -0.101573  ,  0.0754425 , -0.0449827 ,  0.0798561 ,\n",
       "        -0.0529006 ,  0.0525974 , -0.0878376 ,  0.00145824,  0.0109211 ,\n",
       "         0.0909607 , -0.00213549,  0.124874  ,  0.00607755, -0.0422842 ,\n",
       "         0.0296349 ,  0.0591308 ,  0.0492407 , -0.104152  ,  0.00258118,\n",
       "         0.086773  ,  0.0149519 ,  0.0233536 , -0.0177117 , -0.00596852,\n",
       "        -0.0139779 ,  0.0098356 ,  0.0281285 ,  0.0373594 , -0.0742081 ,\n",
       "        -0.0113806 ,  0.00732723, -0.098504  , -0.0963427 ,  0.0651562 ,\n",
       "         0.00485334, -0.0763964 ,  0.00989916,  0.0328271 , -0.097701  ,\n",
       "         0.0442007 , -0.010656  , -0.112508  , -0.0604506 ,  0.0801568 ,\n",
       "        -0.00743724,  0.0522918 , -0.0166598 ,  0.0239759 ,  0.0442374 ,\n",
       "         0.0682573 ,  0.0119434 , -0.171915  ,  0.0402638 ,  0.00216991,\n",
       "         0.0270733 ,  0.0236776 , -0.0120248 , -0.00194608,  0.00665628,\n",
       "         0.0606928 , -0.0367698 , -0.119002  , -0.0377469 ,  0.0119355 ,\n",
       "        -0.0233706 , -0.101137  ,  0.0379971 , -0.028185  ,  0.068948  ,\n",
       "         0.0657692 ,  0.0462996 , -0.0254282 ,  0.0721748 , -0.0481518 ,\n",
       "         0.0189898 , -0.0107946 ,  0.0696024 , -0.0150461 ,  0.103338  ,\n",
       "        -0.0455622 , -0.00985861,  0.0498582 , -0.0106932 , -0.0670459 ,\n",
       "         0.0325172 , -0.0114043 , -0.0642663 , -0.0854225 ,  0.0237198 ,\n",
       "         0.0592072 , -0.00983155, -0.103813  ,  0.0438079 , -0.0214493 ,\n",
       "        -0.0284629 , -0.0473708 ,  0.0545316 , -0.0179931 , -0.0449464 ,\n",
       "         0.0882803 , -0.0379578 ,  0.0120112 ,  0.0359889 ,  0.0472534 ,\n",
       "        -0.0620705 , -0.0811227 , -0.0500405 , -0.0314433 , -0.0448364 ,\n",
       "        -0.0618271 , -0.0299008 , -0.0394957 , -0.0961465 ,  0.0112519 ,\n",
       "         0.0968805 ,  0.0145129 , -0.0130089 ,  0.0700265 , -0.068754  ,\n",
       "        -0.0398066 , -0.0409247 ,  0.0307936 ,  0.0890397 , -0.0377774 ,\n",
       "         0.0740648 , -0.0914554 , -0.0196941 , -0.0332712 , -0.0351288 ,\n",
       "        -0.037544  , -0.0318957 ,  0.0343498 , -0.14389   , -0.0343774 ,\n",
       "        -0.0609655 ,  0.0599601 ,  0.0634991 , -0.103212  , -0.0880753 ,\n",
       "         0.0893933 ,  0.0454613 ,  0.0800986 ,  0.013805  , -0.0686369 ,\n",
       "        -0.0826461 , -0.0932061 , -0.0368774 ,  0.109985  , -0.0367654 ,\n",
       "         0.0521705 ,  0.0321236 , -0.0167859 , -0.029652  , -0.0895624 ,\n",
       "        -0.0234356 , -0.0467305 , -0.0962093 , -0.0204421 , -0.0863054 ,\n",
       "         0.0881734 ,  0.0915388 ,  0.0452718 ,  0.0284642 , -0.00899053,\n",
       "         0.0288613 , -0.0400554 , -0.048739  , -0.0186331 , -0.0777224 ,\n",
       "         0.0902966 ,  0.016051  , -0.00874243, -0.103061  ,  0.00455255,\n",
       "        -0.0600491 , -0.0704607 , -0.0255695 , -0.0583866 ,  0.00513891,\n",
       "        -0.013391  ,  0.0569094 , -0.0335914 , -0.0274625 ,  0.0424431 ,\n",
       "         0.0675369 ,  0.0310496 , -0.00149255,  0.00792774, -0.0814978 ,\n",
       "         0.0640154 , -0.065419  , -0.0847726 ,  0.0924182 , -0.0494803 ,\n",
       "         0.0467627 , -0.009559  , -0.0628398 , -0.0220153 , -0.0225469 ,\n",
       "        -0.032891  , -0.0187858 , -0.0856698 ,  0.0736816 , -0.0785995 ,\n",
       "         0.00620523,  0.0990645 , -0.0688421 , -0.0225713 , -0.0479619 ,\n",
       "        -0.0352953 ,  0.029767  , -0.0518525 ,  0.0413065 , -0.0176196 ,\n",
       "        -0.0610358 ,  0.0759018 ,  0.0883462 ,  0.0110145 ,  0.0831175 ,\n",
       "         0.0410506 , -0.0138545 ,  0.0395239 , -0.0912905 ,  0.0445067 ,\n",
       "        -0.0185282 , -0.0265105 , -0.0494874 , -0.0753016 , -0.00123403,\n",
       "         0.101721  , -0.0565929 ,  0.0390351 ,  0.0882894 ,  0.0160722 ,\n",
       "        -0.037249  , -0.10291   ,  0.017008  ,  0.0969133 ,  0.0711211 ]),\n",
       " array([-1.94344e-02, -4.48178e-02, -5.61464e-02,  5.27557e-02,\n",
       "         6.67050e-03,  4.68471e-02,  6.26116e-02, -7.94104e-02,\n",
       "         3.54571e-02,  9.45010e-02,  2.74679e-03, -3.37387e-02,\n",
       "         4.88677e-03, -3.67419e-02, -1.52473e-02, -7.19187e-02,\n",
       "         7.40123e-02,  2.62846e-02, -3.19554e-02,  5.74156e-02,\n",
       "        -1.13573e-01,  5.10024e-02, -1.01881e-01,  5.04641e-02,\n",
       "        -3.66363e-02,  4.34223e-02,  3.02128e-02, -4.69666e-02,\n",
       "         2.23849e-02,  8.43679e-03, -3.27584e-03,  3.87261e-02,\n",
       "        -4.92890e-02,  8.84542e-02, -6.10170e-02, -1.50929e-02,\n",
       "         6.25319e-02, -9.55344e-03,  7.02468e-02,  2.61737e-02,\n",
       "         7.94538e-03, -1.64873e-02,  2.63088e-02, -1.31350e-01,\n",
       "         3.32704e-02, -3.04135e-02,  1.28188e-02,  6.93824e-03,\n",
       "         1.51623e-02, -1.73080e-02,  7.51831e-02,  7.21098e-03,\n",
       "        -4.81458e-02,  7.84785e-02, -9.38109e-02, -4.42589e-02,\n",
       "        -4.58189e-02,  4.98005e-02, -1.23387e-01,  1.46824e-01,\n",
       "         1.01029e-02, -1.94510e-01,  1.06631e-01,  1.39608e-02,\n",
       "         3.79829e-02, -3.81219e-02, -7.67974e-02, -5.08078e-03,\n",
       "        -8.17091e-02, -1.01886e-02, -4.51737e-02, -2.92933e-02,\n",
       "        -4.95788e-02, -8.24891e-02,  1.18625e-02, -6.02040e-02,\n",
       "         1.19574e-01,  3.46965e-02,  3.18108e-02, -4.62476e-02,\n",
       "        -6.47905e-04,  1.78784e-02, -1.02044e-01,  1.57761e-01,\n",
       "        -5.36381e-03, -7.52449e-02, -1.79051e-02,  3.05337e-02,\n",
       "         7.33184e-02, -6.89978e-02, -5.24929e-02, -3.02040e-02,\n",
       "         1.42103e-01, -7.82106e-02,  6.86045e-02,  9.05985e-02,\n",
       "         7.88559e-02, -1.01017e-02,  5.35772e-02, -1.04297e-02,\n",
       "         4.63045e-02, -5.57105e-02,  4.24057e-02, -9.85910e-02,\n",
       "        -7.33198e-02, -4.08827e-02, -2.57086e-02, -2.19458e-02,\n",
       "         5.66485e-03, -5.23806e-02,  3.14361e-02, -4.38050e-02,\n",
       "         4.86111e-02,  3.70484e-02,  3.03399e-02,  4.38183e-04,\n",
       "         2.79609e-02,  1.33781e-02,  4.32128e-03, -1.18269e-02,\n",
       "        -4.08164e-02,  2.79487e-02, -3.34913e-02,  5.45967e-02,\n",
       "         3.57314e-02, -3.59383e-02, -9.48147e-03,  8.81314e-02,\n",
       "         5.86352e-02,  1.20353e-01,  4.01873e-02, -4.14088e-03,\n",
       "        -4.68725e-02,  1.09326e-02, -7.59732e-03, -2.54494e-02,\n",
       "        -7.46979e-02,  3.85149e-02, -1.57573e-02,  8.19743e-02,\n",
       "         7.61526e-02,  1.20219e-01,  1.63663e-02,  3.26691e-02,\n",
       "         2.89834e-02,  5.96910e-02, -8.71610e-02, -7.37936e-03,\n",
       "         6.32426e-03,  1.35523e-02, -6.57561e-03, -1.34494e-01,\n",
       "        -4.71614e-02,  4.52313e-03,  1.20856e-02, -4.56192e-02,\n",
       "        -1.83972e-02,  4.16603e-02,  6.41641e-02,  4.88170e-02,\n",
       "        -1.03072e-01,  1.05685e-01, -4.13646e-03, -1.86667e-03,\n",
       "         7.47701e-02,  3.21551e-02, -1.90140e-02,  3.39404e-02,\n",
       "         5.30244e-02,  8.11557e-02, -2.59887e-02, -5.02858e-02,\n",
       "        -6.50088e-02,  3.69309e-02, -7.09948e-03,  8.23255e-02,\n",
       "        -4.73950e-02,  1.31883e-01,  4.33718e-02, -5.67612e-02,\n",
       "        -1.04527e-02,  2.76982e-02,  4.01417e-02,  9.25488e-02,\n",
       "         4.00278e-02,  3.17842e-02, -2.32077e-02, -5.48565e-02,\n",
       "         1.22780e-01, -1.83584e-02,  4.56342e-02, -9.42321e-02,\n",
       "        -4.73505e-03,  1.04852e-01, -2.16838e-02,  4.50292e-02,\n",
       "         2.12671e-03,  6.22416e-02, -1.15178e-01,  7.87719e-03,\n",
       "         8.26144e-03,  1.08777e-02,  9.78824e-02,  1.48280e-02,\n",
       "        -8.09188e-04, -9.72367e-02, -4.51285e-02, -1.97972e-02,\n",
       "         1.94662e-02,  1.57423e-01,  6.36521e-02, -3.64481e-02,\n",
       "         2.44843e-02, -2.39986e-03, -9.78230e-03, -5.25028e-02,\n",
       "         9.16398e-03, -8.77424e-02, -2.42955e-02, -3.43093e-02,\n",
       "         1.24874e-02,  7.45746e-02,  3.63302e-02,  3.61871e-02,\n",
       "         9.97642e-03,  6.13333e-02, -6.60821e-02, -1.19086e-02,\n",
       "         1.00879e-01, -1.24587e-02,  5.43202e-02,  3.92542e-04,\n",
       "         1.90612e-03, -3.01022e-02, -1.00469e-01,  2.95835e-02,\n",
       "        -1.91512e-02, -2.30354e-03, -4.27482e-03,  3.51920e-02,\n",
       "         2.71478e-03, -6.48801e-02,  5.75861e-02,  6.83104e-03,\n",
       "         3.15740e-02,  1.28658e-01,  6.37603e-02,  8.72037e-04,\n",
       "         6.60389e-03,  2.31406e-02, -4.58070e-02,  7.52095e-03,\n",
       "        -3.14628e-02, -4.71940e-02, -5.16040e-02,  4.41451e-02,\n",
       "        -7.51420e-02, -5.71987e-02, -4.12828e-02, -4.69900e-02,\n",
       "         2.74633e-02,  5.11111e-03, -6.51730e-02, -6.92691e-03,\n",
       "        -8.52223e-02, -1.80234e-02, -1.65291e-01,  2.71541e-02,\n",
       "        -2.28419e-02, -9.56711e-03, -2.71252e-02,  2.25450e-02,\n",
       "         8.22343e-02, -2.16681e-02, -3.58076e-03, -3.35844e-02,\n",
       "        -2.28582e-02, -1.83802e-03, -4.78792e-02,  1.53763e-02,\n",
       "        -7.50699e-02,  7.16610e-02,  1.80202e-05,  4.55481e-02,\n",
       "         5.12572e-02,  7.09376e-03,  2.78004e-02,  4.46948e-02,\n",
       "        -7.80588e-02,  7.79618e-02, -4.69381e-02, -4.02576e-02,\n",
       "        -2.11493e-02,  1.29054e-01,  5.24191e-02,  3.77576e-02,\n",
       "        -7.55819e-02,  4.17209e-02,  9.95817e-02,  2.19906e-02]),\n",
       " array([-8.73058e-02,  6.79089e-02,  4.52076e-02, -6.92154e-02,\n",
       "         3.46322e-02, -1.45304e-05, -6.12521e-02, -4.28629e-02,\n",
       "        -4.77176e-02,  4.03377e-02, -1.01372e-02,  4.84826e-02,\n",
       "         4.46496e-02,  1.25070e-01, -6.41341e-03, -2.90207e-02,\n",
       "        -3.05044e-02, -2.37305e-02, -1.44539e-02,  4.53414e-02,\n",
       "        -1.56352e-02, -3.76602e-02,  1.79422e-02, -1.49571e-01,\n",
       "         3.01187e-02, -7.65515e-02, -1.72739e-02,  9.09595e-02,\n",
       "        -3.15540e-02,  2.28539e-02,  3.68922e-02,  1.26895e-02,\n",
       "        -1.30844e-01,  1.42048e-02,  2.48081e-02, -4.68538e-03,\n",
       "        -3.70400e-03, -4.85658e-02, -5.91181e-02, -4.87330e-02,\n",
       "         5.51436e-02,  3.69915e-03, -2.92415e-04, -3.89687e-02,\n",
       "        -1.68514e-02, -3.94389e-02,  6.29584e-02,  1.37441e-02,\n",
       "        -1.45403e-03,  5.65176e-03, -1.78923e-02, -2.65042e-02,\n",
       "         1.71541e-03,  3.23898e-02,  5.34083e-02,  7.29530e-02,\n",
       "        -2.92737e-02,  4.03809e-02, -1.16379e-02, -6.78748e-03,\n",
       "        -4.25144e-02,  3.62835e-03,  2.83168e-02, -1.01843e-01,\n",
       "        -1.07668e-01, -1.55967e-02, -6.68925e-02,  6.84921e-02,\n",
       "        -6.39659e-02,  1.51808e-01,  6.72611e-03,  9.00652e-02,\n",
       "         3.98428e-02, -4.95757e-02, -4.51319e-02,  6.33558e-03,\n",
       "         1.11010e-01,  5.09098e-02,  4.28033e-02, -3.71816e-02,\n",
       "         7.60831e-02,  6.36479e-03, -8.87201e-02, -1.02490e-02,\n",
       "        -1.02868e-02, -9.41566e-02, -9.08533e-03, -6.52055e-02,\n",
       "         9.62869e-03, -1.45918e-02,  2.50045e-02, -8.49325e-02,\n",
       "         1.07936e-01, -3.19504e-02, -2.58478e-02,  8.06747e-02,\n",
       "         4.62657e-03,  8.22537e-02, -8.19541e-03, -1.44019e-03,\n",
       "         1.12652e-01, -4.26768e-02,  8.88261e-02, -1.15079e-01,\n",
       "        -7.31567e-02, -1.52535e-02, -1.67597e-02,  8.54273e-02,\n",
       "         1.73722e-02,  1.07588e-01,  2.52350e-03, -2.68993e-02,\n",
       "        -4.37481e-02, -7.85750e-02,  2.65576e-02,  2.05068e-02,\n",
       "        -1.60015e-02,  1.59693e-01,  4.66757e-03,  3.42475e-02,\n",
       "         1.87191e-01, -3.39588e-02, -3.13855e-02,  6.80667e-02,\n",
       "         3.66478e-02, -3.18398e-03,  2.92170e-02,  1.19491e-01,\n",
       "         3.46656e-02,  4.90819e-02, -5.59954e-02,  1.17458e-01,\n",
       "         6.62156e-02, -2.38337e-02,  1.35974e-01,  6.93669e-02,\n",
       "        -5.78147e-02, -7.48627e-02,  1.16230e-02, -6.68456e-02,\n",
       "         1.56519e-02,  4.32248e-03,  2.34362e-02, -3.04662e-03,\n",
       "        -3.29098e-02,  9.85365e-02,  1.75853e-02,  7.00036e-02,\n",
       "        -2.44156e-02,  2.76624e-02,  2.45450e-03, -4.45793e-02,\n",
       "         5.76747e-02, -1.30577e-02, -1.04216e-03,  1.08143e-02,\n",
       "        -3.89675e-02, -1.15171e-01,  2.29495e-02,  7.86887e-02,\n",
       "        -8.52867e-03,  2.67955e-02,  5.98196e-02,  3.10752e-02,\n",
       "         5.10455e-02, -6.00270e-02,  6.07056e-02,  6.43563e-02,\n",
       "        -1.72588e-02, -2.67817e-02, -6.47681e-02, -5.79886e-02,\n",
       "        -5.78566e-02,  3.18105e-02, -1.63821e-02,  7.82692e-02,\n",
       "         7.89661e-03,  1.09033e-01, -3.33500e-03, -7.23418e-02,\n",
       "        -5.27728e-02, -1.79474e-02, -4.34345e-02,  8.91200e-02,\n",
       "        -3.78221e-02,  6.88315e-02,  5.82803e-02, -2.36724e-02,\n",
       "         6.70503e-02,  1.72625e-02, -6.16274e-02, -9.93783e-02,\n",
       "        -3.13151e-02,  1.05413e-01,  4.92753e-02,  4.70274e-02,\n",
       "        -9.73475e-02,  4.40146e-02, -4.06452e-03,  3.35115e-02,\n",
       "         8.21964e-02,  1.58955e-02, -2.42505e-02,  5.58688e-02,\n",
       "         1.02100e-01, -1.01033e-01, -7.45930e-02,  4.15594e-02,\n",
       "         9.99683e-03,  1.14450e-01,  7.82232e-02, -1.04330e-01,\n",
       "         1.35913e-02, -1.11087e-01,  9.47127e-03, -4.80732e-02,\n",
       "        -3.64928e-02, -1.00588e-01,  4.07184e-02,  7.16016e-03,\n",
       "        -3.27016e-02,  2.49364e-02, -5.13616e-03,  1.24008e-01,\n",
       "        -6.49529e-02,  3.30015e-02, -7.04155e-02,  3.70941e-02,\n",
       "        -7.99129e-04, -5.21569e-02,  3.01957e-02,  5.96910e-02,\n",
       "        -2.42168e-02,  1.00367e-01,  3.93337e-02,  1.15558e-02,\n",
       "         4.15668e-02,  7.30546e-02,  1.93403e-02, -2.74499e-02,\n",
       "         4.90664e-02, -8.11798e-03, -2.02285e-02,  2.23952e-02,\n",
       "         1.08654e-01,  2.79722e-02,  1.09320e-02,  7.14566e-02,\n",
       "         3.32586e-02,  3.23635e-02,  6.88407e-02,  1.66031e-02,\n",
       "        -6.73976e-02,  1.20147e-02, -4.96880e-02,  2.69701e-02,\n",
       "        -9.51651e-02,  4.85344e-02,  4.08837e-02,  3.29894e-02,\n",
       "         2.23363e-02, -8.04543e-02, -4.68953e-02, -4.23861e-02,\n",
       "        -5.58463e-02, -1.13218e-01, -1.39996e-02,  4.54325e-02,\n",
       "         3.42498e-03, -4.85929e-02, -1.04967e-01, -3.40358e-02,\n",
       "        -2.53016e-02,  2.85800e-03, -1.11136e-01,  4.16749e-04,\n",
       "        -2.10693e-02,  3.82438e-02,  1.72917e-02, -3.43033e-02,\n",
       "        -6.09743e-02,  2.36959e-03,  8.95852e-02,  4.38180e-02,\n",
       "        -1.43994e-02, -2.32751e-02,  2.16001e-02, -1.54481e-02,\n",
       "        -2.98843e-02,  4.58638e-02,  3.73566e-02, -1.26467e-03,\n",
       "         1.14704e-01,  5.01389e-02,  1.08686e-02, -1.78334e-02,\n",
       "         9.18221e-03,  1.02770e-02,  3.27578e-02, -8.07839e-02]),\n",
       " array([-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000]),\n",
       " array([ 1.00872e-01, -8.60220e-02, -7.68737e-02,  1.29790e-01,\n",
       "        -5.71349e-02,  1.25315e-01, -1.11830e-02, -5.13201e-02,\n",
       "         2.79874e-02,  4.38474e-04,  1.15551e-01,  3.73603e-02,\n",
       "         4.39168e-02,  4.36616e-02,  6.65132e-02,  1.61783e-02,\n",
       "        -9.94873e-02,  2.95094e-02,  6.64881e-03,  2.89244e-02,\n",
       "        -3.79603e-02,  7.14880e-02, -3.55488e-02, -1.27412e-01,\n",
       "         5.02649e-03, -6.16928e-02,  1.29700e-02, -3.39155e-02,\n",
       "        -1.17506e-01,  3.40406e-02, -1.46617e-02,  1.36961e-01,\n",
       "         1.22086e-02,  2.59650e-02, -1.66099e-02, -4.31559e-02,\n",
       "        -3.32733e-02,  5.53122e-02, -2.50300e-02, -4.48013e-02,\n",
       "         1.12502e-02, -3.07876e-02, -6.88056e-02, -6.84450e-02,\n",
       "        -3.57381e-03,  9.90929e-02,  8.61033e-02,  6.00882e-03,\n",
       "        -3.17166e-03, -6.79100e-02, -5.75802e-03, -4.02081e-02,\n",
       "         3.46609e-03, -1.55229e-01,  1.68630e-02,  1.33094e-01,\n",
       "         2.01303e-02,  1.98676e-02, -2.67062e-02,  2.00392e-01,\n",
       "        -5.79930e-03,  2.29413e-02,  2.99145e-03,  1.70962e-02,\n",
       "        -2.44474e-02,  4.03859e-02,  1.16739e-02,  3.89273e-02,\n",
       "         8.48445e-04, -1.16155e-01,  7.77912e-03,  4.66154e-02,\n",
       "         4.01052e-02, -3.84269e-02, -1.80347e-02,  7.84995e-02,\n",
       "         1.31506e-02,  2.90956e-02,  1.73035e-02, -1.97318e-02,\n",
       "         4.95522e-02,  1.89664e-03,  1.94088e-02, -2.23482e-02,\n",
       "         4.52408e-02,  4.91483e-02, -8.95328e-02, -1.54735e-02,\n",
       "         2.74737e-02, -4.51704e-02,  5.85241e-02,  6.01301e-03,\n",
       "         5.84400e-02, -1.59398e-02,  2.25675e-02, -2.21644e-02,\n",
       "         4.55275e-02,  5.67106e-02,  1.92913e-02,  1.30895e-02,\n",
       "        -3.43528e-02, -1.00437e-01,  8.21185e-02,  1.10911e-02,\n",
       "        -3.67944e-02, -7.37985e-02, -9.30820e-02,  3.90900e-02,\n",
       "         3.33063e-02,  1.28111e-02,  9.80865e-03, -1.82627e-02,\n",
       "        -2.78911e-02,  2.72774e-02, -4.25392e-03, -8.73518e-02,\n",
       "         4.44429e-03,  5.18273e-02, -7.87780e-03,  1.78559e-02,\n",
       "        -4.71049e-03, -1.61416e-02,  5.94463e-02,  7.91355e-02,\n",
       "         1.14480e-01, -6.95872e-04,  2.10801e-02, -1.02280e-02,\n",
       "         5.32915e-02,  3.61282e-02, -7.60924e-03, -3.21617e-02,\n",
       "        -2.35367e-02, -3.80029e-02,  6.79987e-02, -1.92992e-02,\n",
       "         8.97098e-02, -5.34886e-03,  2.81352e-02,  8.33527e-02,\n",
       "        -9.06679e-03,  2.63591e-02, -2.06746e-02, -1.06353e-02,\n",
       "        -4.73193e-03,  4.01606e-02, -2.22885e-02, -1.09407e-02,\n",
       "        -6.44246e-02, -6.70081e-02,  5.96873e-02, -3.65012e-04,\n",
       "         9.14825e-03,  5.51205e-02,  2.46144e-02,  1.88400e-02,\n",
       "         1.54990e-03, -2.10722e-03,  1.25201e-01,  4.63787e-02,\n",
       "         8.43718e-02,  1.06635e-02, -6.62377e-02,  1.92449e-02,\n",
       "         2.52632e-03,  5.08807e-02, -5.10696e-02, -1.40733e-01,\n",
       "         1.21708e-01,  8.09221e-02, -8.33950e-02, -1.30688e-02,\n",
       "        -1.27672e-01, -4.16927e-02, -1.01373e-02,  1.78646e-02,\n",
       "         1.02738e-01, -1.37893e-04, -4.67055e-02, -6.86428e-02,\n",
       "         2.74984e-02, -7.04822e-02,  8.04097e-02,  2.60181e-02,\n",
       "         3.07137e-02,  1.32911e-02,  3.99418e-02, -6.51680e-02,\n",
       "         5.83106e-02, -5.49625e-02,  6.83255e-02, -1.43220e-01,\n",
       "         4.05437e-02,  1.40018e-01,  1.52222e-03, -3.40934e-02,\n",
       "        -2.14198e-02,  3.83619e-04, -8.18958e-02, -7.46216e-03,\n",
       "         5.87178e-02, -3.83959e-02,  1.46606e-02,  5.88999e-02,\n",
       "         3.32699e-02, -6.22187e-02, -7.31497e-02, -8.36490e-03,\n",
       "        -2.74745e-02,  2.36317e-02,  1.31995e-01,  1.10992e-02,\n",
       "         4.74186e-02,  7.15299e-03,  2.33758e-02, -4.43709e-02,\n",
       "        -4.06680e-02, -1.04685e-01, -1.06354e-01, -5.81072e-02,\n",
       "        -5.17345e-02,  8.85537e-03,  2.62729e-02, -5.46838e-02,\n",
       "         2.41364e-02,  9.79795e-02, -1.17911e-01,  7.76755e-02,\n",
       "         3.84336e-02,  3.44166e-02, -2.74770e-02,  1.17494e-01,\n",
       "        -1.79600e-02,  4.75127e-02, -5.94272e-02,  8.32603e-02,\n",
       "         7.29357e-03,  3.44825e-03,  3.92220e-02, -1.78780e-02,\n",
       "        -4.56164e-02,  3.58951e-02,  5.80283e-02,  2.71995e-05,\n",
       "        -3.21684e-02,  1.11874e-01, -8.01805e-03,  8.63206e-02,\n",
       "         6.81340e-02, -6.53819e-02, -8.10082e-03, -7.19612e-02,\n",
       "        -9.38454e-02,  2.93756e-02,  3.29257e-02, -8.92293e-03,\n",
       "         2.46009e-02, -5.93784e-02, -3.68839e-02,  2.47505e-02,\n",
       "        -2.00415e-03,  3.36472e-02, -6.58799e-02, -3.48712e-02,\n",
       "        -1.03882e-01, -7.71351e-02, -1.00783e-01, -1.68873e-02,\n",
       "         6.58950e-03, -2.12425e-02, -8.58952e-03,  4.55787e-02,\n",
       "         9.03199e-02,  7.67679e-02, -5.21504e-02, -5.44687e-02,\n",
       "         9.37090e-02, -2.83591e-03, -1.30624e-02,  2.43806e-02,\n",
       "         1.80190e-02,  3.62176e-02, -7.73076e-03,  1.36767e-02,\n",
       "         4.70485e-02,  2.07193e-02,  8.07993e-02,  1.66928e-01,\n",
       "         3.54630e-02,  5.72368e-02,  2.61245e-03,  6.24941e-02,\n",
       "         1.71773e-02,  1.02392e-02,  6.92125e-02, -2.28919e-02,\n",
       "         9.60816e-02, -1.04823e-02,  8.83862e-03,  1.63640e-03]),\n",
       " array([-9.54181e-02,  6.70252e-03, -7.05051e-02,  7.81464e-02,\n",
       "        -4.27970e-02,  3.63326e-02,  7.60507e-02, -1.08972e-01,\n",
       "         6.27581e-02,  1.36074e-01,  2.08594e-02,  7.17231e-02,\n",
       "        -2.34237e-02, -5.89353e-04,  2.80114e-02, -9.96826e-02,\n",
       "        -7.61164e-02, -3.23257e-02,  4.55607e-02,  6.70066e-02,\n",
       "         4.96994e-02, -2.50594e-02, -8.72851e-02,  4.81529e-02,\n",
       "        -5.75718e-02,  5.01231e-02,  2.13446e-02,  5.62739e-02,\n",
       "         8.30538e-03, -5.07536e-03, -3.98845e-02,  1.10020e-01,\n",
       "        -1.18749e-01,  7.24587e-02,  6.51214e-02,  4.58103e-02,\n",
       "        -6.22802e-02, -8.22426e-03, -1.06652e-01, -1.90757e-02,\n",
       "         4.38328e-02, -6.07040e-03, -1.12153e-02, -1.37141e-02,\n",
       "        -5.10499e-02,  5.61813e-02,  5.13637e-02,  8.63827e-03,\n",
       "         5.07866e-02, -3.36993e-02, -8.95109e-02, -6.61581e-02,\n",
       "         5.31646e-02, -1.10383e-03, -6.80358e-02,  4.62227e-02,\n",
       "         5.89252e-02, -3.86468e-02, -3.90740e-02,  3.43174e-02,\n",
       "        -6.07438e-02, -6.34495e-02,  5.78918e-02, -2.21927e-03,\n",
       "         7.72510e-02, -1.15213e-01, -3.96468e-02, -4.01121e-02,\n",
       "         7.15858e-02, -2.18495e-02, -5.49032e-02,  3.70152e-02,\n",
       "         5.20101e-03, -9.86718e-02, -5.47162e-02,  7.99001e-02,\n",
       "         1.00660e-01,  1.10426e-01,  6.15213e-03,  4.74795e-03,\n",
       "        -1.87138e-03,  2.92046e-02,  1.27260e-02, -4.28848e-03,\n",
       "         2.96273e-02,  1.99797e-02, -1.12596e-02,  5.44686e-02,\n",
       "        -2.75612e-02,  1.71659e-02, -2.60935e-03,  3.09903e-02,\n",
       "         5.94528e-02, -1.33829e-01,  6.13129e-02, -9.50930e-03,\n",
       "         1.35418e-01,  4.82927e-02, -4.21232e-02, -9.78043e-03,\n",
       "        -4.24003e-02, -2.28135e-02,  1.44852e-01,  2.43510e-02,\n",
       "        -3.75505e-02, -1.28328e-01, -7.27047e-02,  3.77134e-02,\n",
       "         4.22306e-02, -4.83684e-02,  5.84410e-03,  1.69627e-02,\n",
       "        -5.40502e-02, -5.19074e-02,  9.63069e-02, -4.89743e-03,\n",
       "        -5.40621e-02,  4.91823e-02, -3.51211e-02,  1.85713e-02,\n",
       "         5.54149e-02, -4.71473e-03,  4.73480e-02,  1.82139e-01,\n",
       "         5.70293e-02,  6.89765e-02,  2.02980e-02, -6.42671e-02,\n",
       "        -5.72187e-02,  1.20108e-01, -1.50273e-02,  1.20666e-01,\n",
       "        -1.35426e-01, -3.12968e-02, -9.41315e-02, -4.05875e-04,\n",
       "         4.35216e-02,  5.98801e-02, -4.09028e-02,  1.01872e-02,\n",
       "        -8.62473e-03,  6.18833e-03,  4.95592e-02, -8.41468e-03,\n",
       "        -7.28042e-02,  4.12685e-03, -5.86131e-02, -6.34483e-03,\n",
       "         1.31717e-02, -7.42246e-02,  3.79334e-02, -7.86527e-02,\n",
       "        -4.05237e-02, -6.98937e-02, -1.38263e-02, -1.29800e-01,\n",
       "        -5.36272e-02, -5.17587e-02,  8.33854e-02,  2.53675e-02,\n",
       "         3.73555e-02,  1.22362e-01, -2.29699e-02,  9.76012e-03,\n",
       "         3.36063e-02,  8.48819e-02, -8.10260e-04, -1.44010e-02,\n",
       "         7.28493e-02,  3.76554e-02, -4.18189e-03, -7.30725e-03,\n",
       "        -2.47935e-02,  3.71676e-03,  3.44987e-02,  3.73497e-02,\n",
       "        -7.20914e-02,  2.69563e-02,  2.40648e-02, -5.98300e-02,\n",
       "         1.64834e-01,  6.35592e-03,  6.92050e-02, -3.67247e-02,\n",
       "         3.01934e-02,  5.44124e-02,  4.80226e-03,  1.34342e-03,\n",
       "         7.44632e-02, -3.12432e-02, -6.23424e-02, -1.19091e-01,\n",
       "         4.22063e-02,  7.42911e-02, -4.75850e-02, -4.63982e-02,\n",
       "         3.25196e-02,  5.71056e-02, -6.89790e-02, -1.75837e-02,\n",
       "         3.02967e-02, -2.20722e-02,  7.66456e-02, -5.06798e-03,\n",
       "        -7.31399e-02, -4.90026e-02, -1.12055e-01,  1.77457e-02,\n",
       "         4.47101e-02,  2.31769e-02,  9.72985e-02, -2.20632e-02,\n",
       "         3.92597e-02, -3.93997e-02, -3.15362e-03, -4.35424e-02,\n",
       "        -4.79621e-02, -7.06060e-02, -1.40861e-03,  1.74171e-02,\n",
       "        -2.48010e-02, -2.94464e-02, -1.44960e-02,  7.31824e-03,\n",
       "         3.31031e-02, -3.84732e-02, -3.50216e-02, -1.12897e-02,\n",
       "        -7.59267e-03,  7.45782e-02, -5.84242e-02,  4.66225e-02,\n",
       "        -3.43010e-02, -4.04679e-02, -7.92384e-02,  6.25727e-02,\n",
       "         1.03979e-01, -2.89792e-02, -3.37175e-02,  9.39724e-02,\n",
       "         6.12049e-02,  5.64990e-02,  6.41415e-02,  7.59170e-03,\n",
       "        -4.41446e-05,  5.68895e-02,  1.12618e-02, -2.07786e-02,\n",
       "        -5.36773e-02, -3.69806e-02,  5.56771e-03,  1.18463e-03,\n",
       "        -1.91288e-03,  4.70846e-02, -8.47255e-03, -6.40874e-02,\n",
       "        -3.13524e-02, -9.86168e-03,  5.44919e-02,  7.23272e-02,\n",
       "         3.01297e-02, -2.55428e-03,  2.71317e-02, -3.98664e-02,\n",
       "        -1.22336e-01, -1.88993e-02, -3.72497e-02,  4.04497e-02,\n",
       "        -3.89971e-02, -2.07110e-02, -1.05143e-01,  1.23867e-02,\n",
       "         3.02766e-02,  4.56866e-02,  7.01947e-03, -8.79643e-02,\n",
       "         3.51153e-02,  4.88219e-02, -7.42916e-02, -4.69535e-02,\n",
       "         1.52157e-01, -2.53888e-02,  1.88749e-02, -2.85612e-02,\n",
       "        -4.46339e-02, -3.42235e-02, -2.39562e-02,  6.85015e-02,\n",
       "        -3.59031e-02, -1.58192e-02, -2.99238e-02,  3.91993e-02,\n",
       "         2.21662e-02,  2.12753e-02,  1.51598e-02, -4.71508e-02,\n",
       "        -2.48815e-02,  5.54509e-02,  1.40170e-01, -8.93479e-03]),\n",
       " array([-1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000, -1000,\n",
       "        -1000]),\n",
       " array([-3.83132e-03, -2.58047e-02, -6.14736e-02,  1.07410e-01,\n",
       "        -4.00333e-02,  4.50391e-02,  3.34977e-02, -8.66423e-02,\n",
       "        -1.94456e-02,  7.49135e-02,  3.90551e-02, -5.78951e-02,\n",
       "        -3.30254e-02, -7.45894e-02,  6.93057e-02, -3.83271e-02,\n",
       "         1.33110e-02,  1.50969e-02,  1.08054e-02,  3.46523e-02,\n",
       "        -5.36225e-02, -3.94613e-02, -8.91233e-02, -6.20784e-02,\n",
       "         2.54731e-02, -1.18684e-01,  1.28665e-02,  3.85654e-02,\n",
       "        -4.44046e-02,  6.05237e-02, -2.11153e-02,  1.17050e-01,\n",
       "        -5.78700e-02,  7.51172e-02,  6.64824e-02, -2.40338e-02,\n",
       "        -6.42407e-03, -8.23577e-03,  1.10011e-01, -6.73804e-02,\n",
       "        -1.63880e-02, -3.91546e-03, -5.57175e-02, -5.73600e-02,\n",
       "         7.05460e-03,  7.69470e-02,  6.71919e-02,  9.72681e-03,\n",
       "        -1.57867e-02, -9.35757e-03,  2.06032e-02, -6.17166e-02,\n",
       "        -6.69372e-02, -1.07409e-01,  3.79420e-02,  2.09445e-02,\n",
       "        -1.09255e-01,  1.28549e-01,  4.43265e-02,  1.07107e-01,\n",
       "        -6.72018e-02, -1.34548e-01,  1.02858e-01, -2.48139e-02,\n",
       "         2.08196e-02, -3.87519e-02, -1.33655e-01, -2.06849e-04,\n",
       "        -3.94814e-03, -2.12127e-02, -6.40762e-02,  5.81140e-02,\n",
       "         1.11482e-02, -9.45129e-02, -6.60808e-02,  7.93944e-02,\n",
       "         1.11151e-01, -2.94205e-02, -6.28069e-02, -1.04407e-01,\n",
       "        -5.03569e-06, -3.22977e-02,  6.83007e-03, -8.86690e-04,\n",
       "        -3.31721e-03,  5.18862e-02, -3.31410e-02, -6.66270e-02,\n",
       "         3.85011e-02, -2.12442e-02, -2.99542e-02,  5.05831e-02,\n",
       "         7.05707e-02, -7.60082e-02,  7.89528e-03,  1.03455e-01,\n",
       "         2.81968e-02,  2.48545e-02,  5.10625e-02,  1.73997e-02,\n",
       "        -1.98010e-02,  7.56455e-04,  9.83372e-02,  6.69455e-02,\n",
       "        -7.41373e-03, -7.05065e-03, -3.81824e-02, -1.88554e-02,\n",
       "         5.41828e-02,  4.52589e-02,  3.88271e-03,  1.65910e-02,\n",
       "         7.68969e-02,  7.99350e-02,  1.72461e-02, -5.29479e-02,\n",
       "         2.26686e-02,  2.88408e-02,  8.15451e-03,  5.36058e-02,\n",
       "         8.68256e-02,  6.93682e-02, -3.61066e-02,  9.46340e-02,\n",
       "         8.42391e-02, -3.21834e-02,  6.43219e-02, -1.97668e-02,\n",
       "         9.78858e-02,  2.77932e-02, -5.11128e-03, -9.14553e-02,\n",
       "         1.68775e-02, -1.83203e-02, -2.05991e-03, -2.80077e-02,\n",
       "         6.08071e-02,  1.94242e-02, -7.64356e-03,  1.12618e-02,\n",
       "         7.07386e-02,  6.68285e-02,  2.51588e-02, -9.47567e-02,\n",
       "         4.47648e-02,  2.93866e-02,  3.80550e-02,  1.08682e-01,\n",
       "        -2.54817e-02, -1.78554e-03,  3.87383e-02, -8.05509e-02,\n",
       "        -5.97858e-02,  3.47252e-02,  5.82051e-02,  1.86131e-02,\n",
       "        -1.75380e-02, -3.92044e-02,  8.70146e-02,  2.86275e-03,\n",
       "         4.39857e-02,  4.65844e-02, -1.47757e-02,  9.34367e-02,\n",
       "        -2.80181e-02, -9.84360e-03, -4.00732e-02, -1.35327e-01,\n",
       "        -1.89461e-02,  5.70364e-03, -3.73608e-02, -1.08681e-01,\n",
       "         8.63683e-03,  9.94520e-03, -1.18352e-01,  1.18209e-01,\n",
       "         6.49232e-02,  4.43166e-02, -5.07443e-02,  3.12552e-02,\n",
       "         5.63221e-02, -1.08116e-01,  4.14045e-03, -1.03778e-02,\n",
       "        -2.91191e-02,  8.61911e-02,  6.47505e-02,  5.65023e-02,\n",
       "         6.30690e-03, -7.63782e-03,  5.94550e-02, -5.75698e-02,\n",
       "         7.11859e-02,  8.80969e-02,  5.60532e-03, -9.31545e-02,\n",
       "         2.28902e-02,  1.14363e-01, -7.05004e-02, -8.54059e-02,\n",
       "        -6.43801e-02,  7.01060e-02, -4.00480e-02, -2.64300e-02,\n",
       "        -4.38111e-02, -6.10810e-02, -4.98175e-02,  2.42491e-02,\n",
       "        -6.76994e-02, -1.82722e-02,  7.29184e-02,  2.84240e-02,\n",
       "        -2.18176e-02, -7.55070e-03,  5.05640e-02, -7.40672e-02,\n",
       "        -3.88795e-02, -1.48644e-01,  8.47331e-02, -2.65636e-02,\n",
       "        -1.14324e-02, -2.24915e-02,  8.27914e-02,  3.63228e-02,\n",
       "        -6.27353e-02,  2.10865e-03, -8.40999e-02,  1.00061e-02,\n",
       "         4.47985e-02,  6.11126e-02,  3.96651e-02,  9.53284e-02,\n",
       "         5.47156e-02,  7.64431e-03, -5.59800e-02,  4.26928e-02,\n",
       "        -1.27517e-02,  7.68237e-03,  6.56776e-03, -4.68811e-02,\n",
       "         2.64815e-02, -4.26420e-02,  8.61861e-02,  1.23461e-01,\n",
       "         4.04486e-03,  6.55510e-02, -3.93254e-02,  7.44856e-02,\n",
       "         2.68138e-02, -7.56866e-03,  8.09181e-02,  2.63648e-02,\n",
       "        -4.05775e-02, -5.19216e-02,  2.24503e-02,  5.75337e-02,\n",
       "         5.66713e-02, -5.06409e-02, -2.84758e-02,  6.38291e-03,\n",
       "        -3.44199e-03,  9.17020e-02,  3.88094e-02, -6.02719e-02,\n",
       "        -6.85335e-02, -1.32749e-01,  2.03042e-02, -3.45769e-02,\n",
       "         9.42341e-03, -5.60641e-02, -6.96088e-02,  1.26341e-02,\n",
       "         2.90201e-02, -1.15099e-02, -1.09516e-01, -3.54029e-02,\n",
       "         3.70542e-02,  7.01307e-02, -3.91162e-02, -8.09440e-02,\n",
       "         9.31792e-02,  9.28816e-02, -6.49816e-03, -1.08887e-02,\n",
       "         5.40334e-02,  5.52987e-02,  6.55148e-02,  3.33592e-02,\n",
       "         2.74411e-02,  3.74533e-02, -6.72479e-03, -3.11734e-03,\n",
       "        -6.12883e-02,  3.70001e-02,  4.13496e-02, -6.53588e-02,\n",
       "        -3.25205e-02, -4.52313e-02, -4.82714e-04,  3.63631e-02])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(working_df['content_y'].shape[0]):\n",
    "    working_df['content_y'][i] = [x if type(x) == np.ndarray else np.array([-1000.5]*300) for x in working_df['content_y'][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\pandas\\core\\frame.py:4301: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "working_df = working_df[['name', 'content_y']]\n",
    "working_df.rename(columns={\"content_y\": \"content\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = working_df[['content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(working_df['name'])\n",
    "X_train2, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "# Création des données cibles.\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treating_X(X):\n",
    "    X = X.reset_index().drop('index', axis=1)\n",
    "    maxi = 0\n",
    "    for i in range(len(X['content'])):\n",
    "        if len(X['content'][i]) > maxi:\n",
    "            maxi = len(X['content'][i])\n",
    "    c = np.zeros((X.shape[0], maxi, 300))\n",
    "    i = 0\n",
    "    for element in X['content']:\n",
    "        a_len = len(element)\n",
    "        a = np.array(element)\n",
    "        c[i][:a_len] = a\n",
    "        i+=1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = treating_X(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "def init_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking(mask_value = 0))\n",
    "    model.add(layers.LSTM(150, dropout=0.3, recurrent_dropout=0.3, activation='tanh'))\n",
    "    model.add(layers.Dense(128, activation='tanh'))\n",
    "    model.add(layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7828, 57, 300)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5479 samples, validate on 2349 samples\n",
      "Epoch 1/1000\n",
      "5479/5479 [==============================] - 243s 44ms/sample - loss: 3.4488 - acc: 0.0485 - val_loss: 3.2229 - val_acc: 0.0664\n",
      "Epoch 2/1000\n",
      "5479/5479 [==============================] - 249s 45ms/sample - loss: 3.2154 - acc: 0.0783 - val_loss: 3.1360 - val_acc: 0.0830\n",
      "Epoch 3/1000\n",
      "5479/5479 [==============================] - 251s 46ms/sample - loss: 3.1465 - acc: 0.0854 - val_loss: 3.1272 - val_acc: 0.0754\n",
      "Epoch 4/1000\n",
      "5479/5479 [==============================] - 253s 46ms/sample - loss: 3.1114 - acc: 0.0986 - val_loss: 3.0512 - val_acc: 0.1056\n",
      "Epoch 5/1000\n",
      "5479/5479 [==============================] - 255s 46ms/sample - loss: 3.0808 - acc: 0.1048 - val_loss: 3.0412 - val_acc: 0.1026\n",
      "Epoch 6/1000\n",
      "5479/5479 [==============================] - 258s 47ms/sample - loss: 3.0275 - acc: 0.1247 - val_loss: 3.0140 - val_acc: 0.1145\n",
      "Epoch 7/1000\n",
      "5479/5479 [==============================] - 259s 47ms/sample - loss: 2.9861 - acc: 0.1289 - val_loss: 3.0056 - val_acc: 0.1192\n",
      "Epoch 8/1000\n",
      "5479/5479 [==============================] - 260s 47ms/sample - loss: 2.9346 - acc: 0.1444 - val_loss: 3.0444 - val_acc: 0.1081\n",
      "Epoch 9/1000\n",
      "5479/5479 [==============================] - 261s 48ms/sample - loss: 2.8948 - acc: 0.1535 - val_loss: 2.9866 - val_acc: 0.1281\n",
      "Epoch 10/1000\n",
      "5479/5479 [==============================] - 263s 48ms/sample - loss: 2.8480 - acc: 0.1690 - val_loss: 2.9696 - val_acc: 0.1256\n",
      "Epoch 11/1000\n",
      "5479/5479 [==============================] - 260s 47ms/sample - loss: 2.7932 - acc: 0.1876 - val_loss: 2.9671 - val_acc: 0.1303\n",
      "Epoch 12/1000\n",
      "5479/5479 [==============================] - 277s 51ms/sample - loss: 2.7467 - acc: 0.1920 - val_loss: 2.9721 - val_acc: 0.1379\n",
      "Epoch 13/1000\n",
      "5479/5479 [==============================] - 300s 55ms/sample - loss: 2.7000 - acc: 0.2044 - val_loss: 2.9557 - val_acc: 0.1516\n",
      "Epoch 14/1000\n",
      "5479/5479 [==============================] - 262s 48ms/sample - loss: 2.6194 - acc: 0.2280 - val_loss: 2.9828 - val_acc: 0.1558\n",
      "Epoch 15/1000\n",
      "5479/5479 [==============================] - 261s 48ms/sample - loss: 2.5637 - acc: 0.2373 - val_loss: 3.0157 - val_acc: 0.1545\n",
      "Epoch 16/1000\n",
      "5479/5479 [==============================] - 264s 48ms/sample - loss: 2.5013 - acc: 0.2592 - val_loss: 3.0490 - val_acc: 0.1396\n",
      "Epoch 17/1000\n",
      "5479/5479 [==============================] - 260s 47ms/sample - loss: 2.4491 - acc: 0.2729 - val_loss: 3.0596 - val_acc: 0.1422\n",
      "Epoch 18/1000\n",
      "5479/5479 [==============================] - 261s 48ms/sample - loss: 2.4074 - acc: 0.2873 - val_loss: 3.0662 - val_acc: 0.1379\n",
      "Epoch 19/1000\n",
      "1536/5479 [=======>......................] - ETA: 2:38 - loss: 2.3382 - acc: 0.3027"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-308-ced82b9e9539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\users\\psmag\\.venvs\\delphes\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience = 10, monitor='val_loss', restore_best_weights=True)\n",
    "model = init_model()\n",
    "model.fit(c, y_train, batch_size = 8, epochs=1000, validation_split = 0.3, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3355/3355 [==============================] - 8s 2ms/sample - loss: 2.9406 - acc: 0.1556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9405613182909263, 0.15558867]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(c_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record à 16.36% avec ce modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "def init_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking(mask_value = 0))\n",
    "    model.add(layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2, activation='tanh'))\n",
    "    model.add(layers.Dense(128, activation='tanh'))\n",
    "    model.add(layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_record = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "196.267px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
