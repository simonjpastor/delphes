{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectoring Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:32:27.921461Z",
     "start_time": "2020-09-09T09:32:27.916956Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from googletrans import Translator, LANGUAGES\n",
    "from time import sleep\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:32:29.273337Z",
     "start_time": "2020-09-09T09:32:29.264478Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_vec(emb_path, nmax=50000):\n",
    "    vectors = []\n",
    "    word2id = {}\n",
    "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        next(f)\n",
    "        for i, line in enumerate(f):\n",
    "            word, vect = line.rstrip().split(' ', 1)\n",
    "            vect = np.fromstring(vect, sep=' ')\n",
    "            assert word not in word2id, 'word found twice'\n",
    "            vectors.append(vect)\n",
    "            word2id[word] = len(word2id)\n",
    "            if len(word2id) == nmax:\n",
    "                break\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.vstack(vectors)\n",
    "    return embeddings, id2word, word2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select Languages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:32:30.365477Z",
     "start_time": "2020-09-09T09:32:30.361439Z"
    }
   },
   "outputs": [],
   "source": [
    "languages = [\"english\", \"french\", \"german\", \"italian\", \"polish\", \"portuguese\", \"spanish\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select path to languages embedding txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:04.221407Z",
     "start_time": "2020-09-09T09:32:31.389495Z"
    }
   },
   "outputs": [],
   "source": [
    "nmax = 100000  # maximum number of word embeddings to load\n",
    "emb_dict = {}\n",
    "for lang in languages:\n",
    "    path = f\"../../raw_data/vectors_{lang}.txt\" #Select here\n",
    "    embeddings, id2word, word2id = load_vec(path, nmax)\n",
    "    emb_dict[lang] = [embeddings, id2word, word2id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:04.615278Z",
     "start_time": "2020-09-09T09:33:04.611807Z"
    }
   },
   "outputs": [],
   "source": [
    "def multilang_word_vector(word, emb_dict, lang=None):\n",
    "    translator = Translator()\n",
    "    if lang == None: lang = LANGUAGES[translator.detect(word).lang]\n",
    "    lang_val = LANGUAGES.values()\n",
    "    if lang in lang_val and word in emb_dict.get(lang)[2].keys():\n",
    "        return emb_dict[lang][0][emb_dict[lang][2][word]]\n",
    "    return False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:05.004476Z",
     "start_time": "2020-09-09T09:33:05.001242Z"
    }
   },
   "outputs": [],
   "source": [
    "def vect_tweet(tweet):\n",
    "    translator = Translator()\n",
    "    if translator.detect(tweet).lang in LANGUAGES.keys():\n",
    "        lang = LANGUAGES[translator.detect(tweet).lang]\n",
    "        words = tweet.split(\" \")\n",
    "        res = []\n",
    "        for i in words:\n",
    "            res.append(multilang_word_vector(i, emb_dict, lang))\n",
    "        return res\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select path to df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:05.505298Z",
     "start_time": "2020-09-09T09:33:05.385546Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_pickle(\"../../delphes/data/extended_tweet_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select countries including the first value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:05.960910Z",
     "start_time": "2020-09-09T09:33:05.931021Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_full[df_full[\"country\"] == \"Ireland\"]\n",
    "for i in [\"Poland\", \"Spain\"]:\n",
    "    df = pd.concat([df, df_full[df_full[\"country\"] == i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:06.381441Z",
     "start_time": "2020-09-09T09:33:06.378541Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rmurl_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the URLs, the #hashtag and the @user of a column made of strings.\n",
    "    Be careful to apply it BEFORE all the other preprocessing steps (if not it wont'\n",
    "    be recognized as a URL)\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].str.replace('http\\S+|www.\\S+|@\\S+|#\\S+', '', case=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:06.797167Z",
     "start_time": "2020-09-09T09:33:06.794579Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def lower_df(df, column_name):\n",
    "    '''\n",
    "    This function lowercases a column made of strings and return the dataframe.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df[column_name] = df[column_name].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:07.207192Z",
     "start_time": "2020-09-09T09:33:07.203942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rmnumbers_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the digits of a column made of strings.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    def remove_numbers(text):\n",
    "        return ''.join(word for word in text if not word.isdigit())\n",
    "    df[column_name] = df[column_name].apply(remove_numbers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:07.624174Z",
     "start_time": "2020-09-09T09:33:07.620682Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rmpunct_df(df, column_name):\n",
    "    '''\n",
    "    This function removes all the punctuations, all the \"rt\" and remove multiple spaces\n",
    "    of a column made of strings.\n",
    "    '''\n",
    "    punct = string.punctuation\n",
    "    df = df.copy()\n",
    "    def replace_punct(text):\n",
    "        for punctu in punct:\n",
    "            text = text.replace(punctu, ' ')\n",
    "            text = text.replace(' rt ','')\n",
    "            text = \" \".join(text.split())\n",
    "        return text\n",
    "    df[column_name] = df[column_name].apply(replace_punct)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:08.035638Z",
     "start_time": "2020-09-09T09:33:08.032627Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rmemojis_df(df):\n",
    "    '''\n",
    "    This function removes all the emojis of a column made of strings.\n",
    "    Be careful to translate in latin alphabet before applying this function :\n",
    "    it also removes cyrillic alphabet.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df = df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:33:10.865791Z",
     "start_time": "2020-09-09T09:33:08.451979Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nw_df = rmurl_df(df, \"content\")\n",
    "nw_df = lower_df(nw_df, \"content\")\n",
    "nw_df = rmnumbers_df(nw_df, \"content\")\n",
    "nw_df = rmpunct_df(nw_df, \"content\")\n",
    "nw_df = rmemojis_df(nw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:36:06.313666Z",
     "start_time": "2020-09-09T09:36:03.397022Z"
    }
   },
   "outputs": [],
   "source": [
    "vecs = nw_df.content.map(vect_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T09:37:48.360426Z",
     "start_time": "2020-09-09T09:37:48.220672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24722    [[-0.0324474, -0.0462027, -0.00872643, 0.09936...\n",
       "24723    [[-0.0436824, -0.0149531, -0.0435268, 0.025988...\n",
       "24724    [[-0.0736414, 0.0313968, -0.0203576, 0.048477,...\n",
       "24725    [[0.009955, -0.0243541, -0.0476052, -0.0398301...\n",
       "24726    [[-0.0736414, 0.0313968, -0.0203576, 0.048477,...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
