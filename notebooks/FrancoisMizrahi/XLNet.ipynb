{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:03:48.136610Z",
     "start_time": "2020-09-14T14:03:47.935398Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:03:48.967557Z",
     "start_time": "2020-09-14T14:03:48.801415Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../../delphes/data/cleaned_tweet_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:03:53.057345Z",
     "start_time": "2020-09-14T14:03:53.030427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mep_id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>group</th>\n",
       "      <th>nat_group</th>\n",
       "      <th>twitter</th>\n",
       "      <th>content</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>thank much free media independent authorities ...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>the commission adopted major pilot projects fu...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>the commission adopted authored pilot projects...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>day point hour asking one empty slogans unders...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197490</td>\n",
       "      <td>Magdalena ADAMOWICZ</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Independent</td>\n",
       "      <td>Adamowicz_Magda</td>\n",
       "      <td>god need defended anyone want name used terror...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mep_id                 name country  \\\n",
       "0  197490  Magdalena ADAMOWICZ  Poland   \n",
       "1  197490  Magdalena ADAMOWICZ  Poland   \n",
       "2  197490  Magdalena ADAMOWICZ  Poland   \n",
       "3  197490  Magdalena ADAMOWICZ  Poland   \n",
       "4  197490  Magdalena ADAMOWICZ  Poland   \n",
       "\n",
       "                                               group    nat_group  \\\n",
       "0  Group of the European People's Party (Christia...  Independent   \n",
       "1  Group of the European People's Party (Christia...  Independent   \n",
       "2  Group of the European People's Party (Christia...  Independent   \n",
       "3  Group of the European People's Party (Christia...  Independent   \n",
       "4  Group of the European People's Party (Christia...  Independent   \n",
       "\n",
       "           twitter                                            content age  sex  \n",
       "0  Adamowicz_Magda  thank much free media independent authorities ...  47  1.0  \n",
       "1  Adamowicz_Magda  the commission adopted major pilot projects fu...  47  1.0  \n",
       "2  Adamowicz_Magda  the commission adopted authored pilot projects...  47  1.0  \n",
       "3  Adamowicz_Magda  day point hour asking one empty slogans unders...  47  1.0  \n",
       "4  Adamowicz_Magda  god need defended anyone want name used terror...  47  1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:03:53.812559Z",
     "start_time": "2020-09-14T14:03:53.800666Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data = df[[ \"group\", \"content\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:03:55.349021Z",
     "start_time": "2020-09-14T14:03:55.344575Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data.columns = [\"labels\", \"texts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:03:58.182694Z",
     "start_time": "2020-09-14T14:03:58.155080Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Group of the European People's Party (Christian Democrats)\",\n",
       "       'Group of the Progressive Alliance of Socialists and Democrats in the European Parliament',\n",
       "       'European Conservatives and Reformists Group',\n",
       "       'Renew Europe Group', 'Non-attached Members',\n",
       "       'Identity and Democracy Group',\n",
       "       'Group of the European United Left - Nordic Green Left',\n",
       "       'Group of the Greens/European Free Alliance'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:03:59.481695Z",
     "start_time": "2020-09-14T14:03:59.463111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group of the European People's Party (Christian Democrats)                                  44252\n",
       "Group of the Progressive Alliance of Socialists and Democrats in the European Parliament    24519\n",
       "Renew Europe Group                                                                          18192\n",
       "Group of the Greens/European Free Alliance                                                  14247\n",
       "Identity and Democracy Group                                                                10086\n",
       "European Conservatives and Reformists Group                                                  9438\n",
       "Group of the European United Left - Nordic Green Left                                        8553\n",
       "Non-attached Members                                                                         5437\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:04:00.782739Z",
     "start_time": "2020-09-14T14:04:00.450072Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data[[\"texts\"]], df_data[\"labels\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T12:46:55.358878Z",
     "start_time": "2020-09-14T12:46:55.070202Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.txt', sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:55:18.333639Z",
     "start_time": "2020-09-14T14:55:17.187647Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer\n",
    "from transformers import TFAutoModelWithLMHead\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:55:23.038795Z",
     "start_time": "2020-09-14T14:55:22.989136Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = [i[0] for i in X_train.values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:55:42.894669Z",
     "start_time": "2020-09-14T14:55:27.445527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.:0\n",
      "sentence: participate sure candidate argi commissioner understand concept answers nothing modernization precision farming innovation broadband rural areas\n",
      "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3137, 512, 2036, 17, 617, 3141, 6913, 1111, 2963, 4666, 805, 24041, 13228, 9153, 7767, 13361, 3184, 689, 4, 3, 4, 3]\n",
      "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
      "\n",
      "\n",
      "No.:1\n",
      "sentence: far set new special committee every tax scandal created permanent structures permanent committee work regularly focused issue tax justice future\n",
      "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 420, 257, 109, 632, 1694, 300, 860, 5398, 927, 3243, 5278, 3243, 1694, 154, 3955, 2661, 671, 860, 2644, 623, 4, 3, 4, 3]\n",
      "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
      "\n",
      "\n",
      "No.:2\n",
      "sentence: ahead today letter call stronger economic measures must avoid austerity measures time common eurobond would best way funding genuinely response read\n",
      "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1165, 494, 1571, 547, 4175, 531, 1858, 272, 1685, 23916, 1858, 92, 880, 2926, 4769, 66, 74, 252, 162, 2576, 17874, 1196, 828, 4, 3, 4, 3]\n",
      "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_len  = 64\n",
    "\n",
    "full_input_ids = []\n",
    "full_input_masks = []\n",
    "full_segment_ids = []\n",
    "\n",
    "SEG_ID_A   = 0\n",
    "SEG_ID_B   = 1\n",
    "SEG_ID_CLS = 2\n",
    "SEG_ID_SEP = 3\n",
    "SEG_ID_PAD = 4\n",
    "\n",
    "UNK_ID = tokenizer.encode(\"<unk>\")[0]\n",
    "CLS_ID = tokenizer.encode(\"<cls>\")[0]\n",
    "SEP_ID = tokenizer.encode(\"<sep>\")[0]\n",
    "MASK_ID = tokenizer.encode(\"<mask>\")[0]\n",
    "EOD_ID = tokenizer.encode(\"<eod>\")[0]\n",
    "\n",
    "for i,sentence in enumerate(sentences):\n",
    "    # Tokenize sentence to token id list\n",
    "    tokens_a = tokenizer.encode(sentence)\n",
    "    \n",
    "    # Trim the len of text\n",
    "    if(len(tokens_a)>max_len-2):\n",
    "        tokens_a = tokens_a[:max_len-2]\n",
    "        \n",
    "        \n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    \n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(SEG_ID_A)\n",
    "        \n",
    "    # Add <sep> token \n",
    "    tokens.append(SEP_ID)\n",
    "    segment_ids.append(SEG_ID_A)\n",
    "    \n",
    "    \n",
    "    # Add <cls> token\n",
    "    tokens.append(CLS_ID)\n",
    "    segment_ids.append(SEG_ID_CLS)\n",
    "    \n",
    "    input_ids = tokens\n",
    "    \n",
    "    # The mask has 0 for real tokens and 1 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [0] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length at fornt\n",
    "    if len(input_ids) < max_len:\n",
    "        delta_len = max_len - len(input_ids)\n",
    "        input_ids = [0] * delta_len + input_ids\n",
    "        input_mask = [1] * delta_len + input_mask\n",
    "        segment_ids = [SEG_ID_PAD] * delta_len + segment_ids\n",
    "\n",
    "    assert len(input_ids) == max_len\n",
    "    assert len(input_mask) == max_len\n",
    "    assert len(segment_ids) == max_len\n",
    "    \n",
    "    full_input_ids.append(input_ids)\n",
    "    full_input_masks.append(input_mask)\n",
    "    full_segment_ids.append(segment_ids)\n",
    "    \n",
    "    if 3 > i:\n",
    "        print(\"No.:%d\"%(i))\n",
    "        print(\"sentence: %s\"%(sentence))\n",
    "        print(\"input_ids:%s\"%(input_ids))\n",
    "        print(\"attention_masks:%s\"%(input_mask))\n",
    "        print(\"segment_ids:%s\"%(segment_ids))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T14:56:54.693394Z",
     "start_time": "2020-09-14T14:56:53.423281Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francoismizrahi/.pyenv/versions/3.7.7/envs/delphes/lib/python3.7/site-packages/transformers/configuration_xlnet.py:211: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFXLNetForSequenceClassification\n",
    "\n",
    "\n",
    "# # It's highly recommended to download bert prtrained model first, then save them into local file \n",
    "# # In this document, contain confg(txt) and weight(bin) files\n",
    "model_file_address = 'xlnet-base-cased'\n",
    "\n",
    "# # Will load config and weight with from_pretrained()\n",
    "# # Recommand download the model before using\n",
    "# # Download model from \"https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin\"\n",
    "# # Download model from \"https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json\" \n",
    "model = TFXLNetForSequenceClassification.from_pretrained(model_file_address,num_labels=len(tag2idx))\n",
    "\n",
    "\n",
    "# model = TFXLNetForSequenceClassification.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T15:59:28.609181Z",
     "start_time": "2020-09-14T15:59:26.468843Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francoismizrahi/.pyenv/versions/3.7.7/envs/delphes/lib/python3.7/site-packages/transformers/configuration_xlnet.py:211: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
      "  FutureWarning,\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "model_name = 'xlnet-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
